<!DOCTYPE html>
<html lang="en"><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>

    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                
                
                delimiters: [
                    {left: '$$', right: '$$', display: true},
                    {left: '$', right: '$', display: false},
                    {left: '\\(', right: '\\)', display: false},
                    {left: '\\[', right: '\\]', display: true}
                ],
                
                throwOnError : false
            });
        });
    </script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Isabel Dahlgren">
    
    <link rel="shortcut icon" href="http://localhost:1313/favicon.ico">
    
    <link rel="stylesheet" href="/css/style.min.css">

    <link rel="canonical" href="http://localhost:1313/ai-companies-are-companies/" />
    <title>AI companies are companies</title>
</head>
<body><header id="banner">
    <h2><a href="http://localhost:1313/">Isabel Dahlgren</a></h2>
    <nav>
        <ul>
            <li>
                <a href="/library/" title="library">library</a>
            </li><li>
                <a href="/resources/" title="resources">resources</a>
            </li><li>
                <a href="/tags/" title="">Tags</a>
            </li>
        </ul>
    </nav>
</header>

<main id="content">
<article>
    <header id="post-header">
        <h1>AI companies are companies</h1>
        <div>
                <time>August 31, 2025</time>
            </div>
    </header><p>AI companies are companies. The leading AI companies also don&rsquo;t want to be seen as companies, though. They call themselves AI labs. They have researchy names, like DeepMind and Meta AI. The best name: OpenAI. Almost sounds like a non-profit.</p>
<p>Most AI companies are products of Silicon Valley, so they&rsquo;re heavily influenced by start-up culture. Their leaders aren&rsquo;t professors, but seasoned business executives. Moreover, unlike normal research labs, AI companies need to make money.</p>
<p>To justify their growth, AI companies need to tell narratives about themselves. And they are pretty good at it &ndash; these companies attract top talent, so their marketing teams can basically hire the world&rsquo;s best story-tellers. I&rsquo;ll list five narratives being aware of.</p>
<p>Before we begin, an apology. I&rsquo;m deliberately exaggerating these narratives, just to make them clearer<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Concretely, I&rsquo;ll be cherry-picking quotes from company leaders and generalise, like a lot. Overall, I think these companies bring huge consumer value and have the potential to radically improve the future.</p>
<h3 id="well-build-agi-soon">&ldquo;We&rsquo;ll build AGI soon&rdquo;</h3>
<p>AI company CEOs have famously <a href="https://80000hours.org/agi/guide/when-will-agi-arrive/">short AI timelines</a>. For example, in January this year, Sam Altman declared that &ldquo;We are now confident we know how to build AGI as we have traditionally understood it.&rdquo; Dario Amodei, in the same month: &ldquo;I’m more confident than I’ve ever been that we’re close to powerful capabilities… in the next 2-3 years&rdquo;.</p>
<p>Of course, no one would invest in your company if you needed two decades to develop your product.</p>
<p>But the term AGI and is fuzzy<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, and it keeps on changing as models evolve. Funny because it&rsquo;s kinda true: &ldquo;AGI is whatever machines can&rsquo;t do now&rdquo;<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. So in the end, these statements about future model capabilities are pretty uninformative<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<h3 id="agi-is-inevitable">&ldquo;AGI is inevitable&rdquo;</h3>
<p>The AI companies also want technological progress to seem inevitable. If you cannot guarantee AGI, why would you fund them?</p>
<p>But this narrative isn&rsquo;t just for outsiders. Ilya Sutskever, former chief scientist at OpenAI, used to &ldquo;Feel the AGI&rdquo; at company parties, presumably to build a better company culture<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<p>Similarly, if AGI is inevitable, an AI company can justify advancing model capabilities as quickly as possible &ndash; possibly at the cost of safety &ndash; so that none of the bad guys build it first.</p>
<h3 id="were-the-good-guys">&ldquo;We&rsquo;re the good guys&rdquo;</h3>
<p>Indeed, as highlighted in <a href="https://en.wikipedia.org/wiki/Empire_of_AI">Empire of AI</a>, some AI companies seem to think of themselves as &ldquo;the good guys&rdquo; and other AI companies as &ldquo;the bad guys&rdquo;. For example, OpenAI was founded was because Musk was concerned about the ethical implications of Google&rsquo;s acquisition of DeepMind. Anthropic was founded by former OpenAI employees who were dissatisfied with the safety work at OpenAI.</p>
<p>Moreover, the US-China tensions lead to a divide between the American AI companies and the Chinese ones.</p>
<p>This narrative provides a powerful argument for minimal AI regulations.</p>
<h3 id="our-tools-empower-all-of-humanity">&ldquo;Our tools empower all of humanity&rdquo;</h3>
<p>DeepMind&rsquo;s mission is to &ldquo;build AI responsibly to benefit humanity&rdquo;, while OpenAI&rsquo;s mission is to &ldquo;ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity&rdquo;.</p>
<p>The democratisation bit of the mission isn&rsquo;t specific to AI companies; it&rsquo;s a tech company cliché. Remember Facebook was supposed to connect you with friends and the rest of the world, all for free.</p>
<p>AI will empower all of humanity, but only if everyone can afford a laptop, has stable internet connection and knows how to use LLMs efficiently. Moreover, prices for premium subscription plans are relatively high. OpenAI&rsquo;s cheapest paid plan comes at 20 dollars per month. For Anthropic, the figure is 17 dollars.</p>
<p>The point about using LLMs efficiently is subtle. To have an LLM perform more advanced tasks, which is what would be empowering for real, you&rsquo;d need to be good at prompt-engineering. Becoming good at prompt-engineer takes time.</p>
<h3 id="agi-will-solve-all-humanitys-problems">&ldquo;AGI will solve all humanity&rsquo;s problems&rdquo;</h3>
<p>Another reason they need to build AGI as soon as possible is their belief that AGI can solve most of humanity&rsquo;s problems. In short, techno-optimism. In <a href="https://www.penguin.co.uk/books/437020/genius-makers-by-metz-cade/9781847942159">Genius Makers</a>, Cade Metz likens the belief in AGI to a religion. And a religion needs a promise of salvation.</p>
<p>From <a href="https://www.darioamodei.com/essay/machines-of-loving-grace">Machines of Loving Grace</a> by Dario Amodei: &ldquo;it’s my guess that powerful AI could at least 10x the rate of these discoveries, giving us the next 50-100 years of biological progress in 5-10 years&rdquo;.</p>
<p>The idea of AGI radically accelerating scientific progress is pretty mainstream. For example, <a href="https://www.forethought.org/research/preparing-for-the-intelligence-explosion#the-accelerated-decade">this report</a> from Forethought argues that we might very well see a century&rsquo;s worth of technological progress in a decade.</p>
<p>But human progress isn&rsquo;t the same as scientific progress. We need cultural and moral progress too.</p>
<h3 id="the-end">The end</h3>
<p>Whom are these stories meant for?</p>
<p>In short, for everyone. Some stories serve as sales pitches for investors and customers. Others are meant to improve employee morale and create a sense of unity. Regulators learn that they shouldn&rsquo;t regulate the deployment of new AI models, just so their nation won&rsquo;t fall behind in the AI arms race.</p>
<p>We now find ourselves in a technological race, much like the Apollo program. If you build AGI first, you&rsquo;ll become Neil Armstrong. You don&rsquo;t want to be &ndash; I had to Google his name &ndash; Buzz Aldrin. However, this doesn&rsquo;t seem like an race between nations, but more like a race between tech CEOs who don&rsquo;t &ldquo;just&rdquo; want to be average tech CEOs.</p>
<p>Perhaps these narratives are mostly meant for posterity.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>It&rsquo;s a bit like using the extremal principle from mathematics.&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Everyone seems to agree the term &ldquo;AGI&rdquo; is problematic, even the AI company CEOs. See e.g. <a href="https://www.darioamodei.com/essay/machines-of-loving-grace#basic-assumptions-and-framework">here</a>.&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p>As highlighted in <em>AI Snake Oil</em>, we used to call spell checkers and image-generating AIs &ldquo;AGI&rdquo; before we had them.&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p>For research-backed forecasts about AI progress, see the work of <a href="https://epoch.ai/">Epoch</a>.&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p>As an outsider, I cannot help but think that this damages company culture, though.&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

    <p>Tags:
        <a href="/tags/ai">ai</a>
    </p>
    
</article>

        </main><footer id="footer">
    Copyright © 2025 Isabel Dahlgren
</footer>
</body>
</html>
