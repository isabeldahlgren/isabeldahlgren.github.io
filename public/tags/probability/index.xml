<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Probability on Isabel Dahlgren</title>
    <link>http://localhost:1313/tags/probability/</link>
    <description>Recent content in Probability on Isabel Dahlgren</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Sun, 11 May 2025 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://localhost:1313/tags/probability/index.xml" rel="self" type="application/rss+xml" />
    
    
    
    <item>
      <title>On cities</title>
      <link>http://localhost:1313/on-cities/</link>
      <pubDate>Sun, 26 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-cities/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;The 17th century was a century of rapid human progress. Modern science, the way we conceive of it today, began to emerge, subsequently leading to the Scientific Revolution. Philosophers like John Locke and Thomas Hobbes laid the groundwork for modern political thought, while René Descartes and Blaise Pascal made important contributions to philosophy more broadly. Meanwhile, in the arts, William Shakespeare redefined English literature, while Rembrandt changed the way artists approach their subjects.&lt;/p&gt;
&lt;p&gt;The above mentioned people have something important in common, other than being extremely intelligent white men. They spent non-negligible parts of their lives in cities. In the 1600s, only 13% of the world&amp;rsquo;s population lived in cities. Many people spent their entire lives without setting foot in a big city. But there is a sense in which you need to spend some time in a city to become an influential historical figure, or at least if you wish to understand humans societies.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;To begin with, cities serve as historical documents. A city&amp;rsquo;s architecture provides insights into the lives of its inhabitants, both of the past and present. Consider, for example, the massive apartment complexes of East Berlin or the colourful houses perched on the hills in Valparaíso. To stress this point, notice how we describe living conditions in terms of buildings and public infrastructure. The rich reside in lavish villas, while the poor live in shacks in slums. Many of the cities topping quality of life rankings, such as Zürich and Copenhagen, have excellent public infrastructure and safe public spaces.&lt;/p&gt;
&lt;p&gt;Monuments tell us about the values, artistic ideals and technologies at a given time in history. The Blue Mosque of Istanbul marks the historical influence of Islam, while the Dohány Street Synagogue in Budapest marks the influence of the Jewish community in Budapest. The Burj Khalifa is a remarkable engineering achievement, as well as a symbol of wealth and vanity.&lt;/p&gt;
&lt;p&gt;A city might also contain more explicit historical references, such as memorials. Memorials, being explicit expressions of regret and triumph, reveal the citizens&amp;rsquo; relation to history.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;But cities aren&amp;rsquo;t just of interest to historians. Movies, books and plays need to take place somewhere where there&amp;rsquo;s life, and there&amp;rsquo;s no more life than in a global metropolis. Rural areas are sometimes referred to as &amp;ldquo;dead&amp;rdquo;, while New York never sleeps. In fact, many pieces of narrative art appear to be about the city itself, the plot being a mere formality. Some novels are riddled with location references to the point of becoming difficult to follow for non-locals; consider &lt;em&gt;Ulysses&lt;/em&gt;, for instance.&lt;/p&gt;
&lt;p&gt;Cities often referenced in popular culture become cities of our imagination, making them tourist magnets. Paris owes a large part of its tourism to the innumerable cultural references to the French capital. Indeed, &amp;ldquo;American expats loafing in Paris&amp;rdquo; could almost be considered its own literary genre.&lt;/p&gt;
&lt;p&gt;Just as the characters they create, artists are also products of cities. This has given rise to another kind of cultural tourism, whereby visitors visit key locations in an artist&amp;rsquo;s life. Prague doesn&amp;rsquo;t just brand itself in terms of cheap beer, but also as the city of Franz Kafka.&lt;/p&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;Some cities aren&amp;rsquo;t defined by their historical and cultural heritage, but rather by economical factors. Such cities shed light on how the global economy works, as well as the human desire to make it big. For this reason, many accounts of economic history involve lengthy descriptions of cities.&lt;/p&gt;
&lt;p&gt;To analyse cities from an economical viewpoint, Max Weber distinguished between &amp;ldquo;producer cities&amp;rdquo; and &amp;ldquo;consumer cities&amp;rdquo;. Producer cities are organised around some specific trade, while consumer cities are rather like administrational centres with residents having access to certain streams of income. Think Detroit versus Washington DC or, for a European example, Antwerpen versus Brussels. An extreme example of a producer city is Kiruna, a city in the north of Sweden, built in the 1890s to serve the Kiruna Mine.&lt;/p&gt;
&lt;p&gt;Certain cities are defined by the human capital they attract, the quintessential example being San Francisco. Startup founders pilgrim to Silicon Valley, since that&amp;rsquo;s where everything happens. For many San Franciscans, The City by the Bay is more of a transit point than a proper home. University towns are similar, in that a large part of its population aren&amp;rsquo;t permanent residents.&lt;/p&gt;
&lt;p&gt;Some megacities, cities with a population of at least 10 million, are attractors of human capital whilst also offering a home. London is truly a melting pot, with 40% of the population born outside the UK and its many local communities.&lt;/p&gt;
&lt;h3 id=&#34;v&#34;&gt;V.&lt;/h3&gt;
&lt;p&gt;Much of human innovation, whether it be in culture, economics or arts, takes place in cities. Wonders happen when smart people with diverse backgrounds form tightly knit communities, as in, say, Bloomsbury in the 1910s. Such communities are more likely to arise in cities.&lt;/p&gt;
&lt;p&gt;However, this isn&amp;rsquo;t the sole reason cities are important drivers of human progress. To drive human progress, you need to understand people. If you want to understand people &amp;ndash; their fears, desires and rituals &amp;ndash; understand cities.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>The mad scientist is probably mad</title>
      <link>http://localhost:1313/the-mad-scientist-is-probably-mad/</link>
      <pubDate>Sun, 19 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/the-mad-scientist-is-probably-mad/</guid>
      <description>&lt;p&gt;Many pioneering scientists were initially rejected by the scientific community. At first, the ideas of Galileo Galilei, Gregor Mendel and Geoffrey Hinton were ridiculed. There are many more examples of such &amp;ldquo;martyrs of science&amp;rdquo;, people who were cancelled and then vindicated.&lt;/p&gt;
&lt;p&gt;Science isn&amp;rsquo;t as dramatic nowadays. There aren&amp;rsquo;t as many Galilei-like figures, at least not in relative terms. If 1/1000 of crazy-seeming scientists turned out to be geniuses in the 20th century, today the proportion might be more like 1/1 000 000. Why is that?&lt;/p&gt;
&lt;p&gt;To begin with, it seems as if &lt;a href=&#34;https://web.stanford.edu/~chadj/IdeaPF.pdf&#34;&gt;good ideas are getting harder to find&lt;/a&gt;. There are some ideas whose discovery appears almost inevitable because of the amount of readily accessible data. In contrast, much science today requires costly equipment and large-scale collaboration. Scott Alexander put it well in his essay about &lt;a href=&#34;https://www.lesswrong.com/posts/v7c47vjta3mavY3QC/is-science-slowing-down&#34;&gt;science slowing down&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, element 117 was discovered by an international collaboration who got an unstable isotope of berkelium from the single accelerator in Tennessee capable of synthesizing it, shipped it to a nuclear reactor in Russia where it was attached to a titanium film, brought it to a particle accelerator in a different Russian city where it was bombarded with a custom-made exotic isotope of calcium, sent the resulting data to a global team of theorists, and eventually found a signature indicating that element 117 had existed for a few milliseconds. Meanwhile, the first modern element discovery, that of phosphorous in the 1670s, came from a guy looking at his own piss.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Early scientists picked the low-hanging fruit.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s more, the average scientist today is more competent than the average scientist 100 years ago, since job selection has become more meritocratic. In the 18th and 19th centuries, science was largely run by aristocrats with too much spare time. These days, becoming a leading researcher in a STEM field requires brains. So if I&amp;rsquo;m disagreeing with a great number of brilliant people, it’s more likely that I&amp;rsquo;m the one being wrong.&lt;/p&gt;
&lt;p&gt;Finally, the industrial organisation of science might create a selection pressure against wild ideas. While most wild ideas are bad, brilliant ideas often seem wild too. Across almost all scientific disciplines, &lt;a href=&#34;https://www.researchgate.net/figure/A-Average-number-of-co-authors-per-paper-published-by-individual-scientists-during-the_fig1_297723759&#34;&gt;researchers publish more papers now&lt;/a&gt; than a hundred years ago. Someone optimising purely for research output probably can&amp;rsquo;t afford to explore as many wild ideas. If you&amp;rsquo;re expected to publish 4-5 papers per year, you&amp;rsquo;ll spend a significant amount of time on overhead work, leaving you with less time for open-ended exploration. In terms of Kuhn&amp;rsquo;s framework for scientific revolutions&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, you&amp;rsquo;ll mostly be doing normal science.&lt;/p&gt;
&lt;p&gt;Science isn&amp;rsquo;t what it used to be. The fraction of martyrs of science today is minuscule. This doesn&amp;rsquo;t mean today&amp;rsquo;s scientists are any less intelligent&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Rather, it means that today&amp;rsquo;s scientific methodology works relatively well, and that brilliant ideas are the norm rather than the exception. If we&amp;rsquo;re right about the mad scientist just being mad, that&amp;rsquo;s a good thing.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post was inspired by a conversation with Miles Kodama.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;According to Thomas Kuhn, science goes something like this: Most of the time, scientists do normal science (experiment, analyse, repeat). But with time, they start noticing anomalies, results which cannot be explained by existing theories. Soon, there is a scientific crisis, leading to a scientific revolution. After the revolution, you&amp;rsquo;re back to normal science again. The people calling out their colleagues for being wrong should be prepared to be cancelled, at least for some time.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;According to Claude, the number of living physicists outstrips the number of having physicists having lived in the past, from ancient times until the present day. So there are likely many physicists of the same calibre as Einstein, Schrödinger and Bohr alive today.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>High school for heroes</title>
      <link>http://localhost:1313/high-school-for-heroes/</link>
      <pubDate>Sun, 12 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/high-school-for-heroes/</guid>
      <description>&lt;p&gt;High school isn&amp;rsquo;t so much about preparing teenagers for adult life. In Sweden, you have a subject about cooking and personal finance, but only until secondary school. I think this makes sense: you only need one course on practical adult skills. After you know the basics, it&amp;rsquo;s all about practising IRL.&lt;/p&gt;
&lt;p&gt;But being a competent grown-up involves many other skills. It&amp;rsquo;s not just about successfully running a household &amp;ndash; it&amp;rsquo;s also a matter of &amp;ldquo;running yourself&amp;rdquo;. There are plenty of &amp;ldquo;serious&amp;rdquo; subjects we could fit in a standard high school curriculum. Here&amp;rsquo;s a vibe-based list:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Learning&lt;/strong&gt;: Please please please, teach high schoolers about spaced repetition, interleaving and testing. The ability to learn things quickly is useful in any domain of life. In the future, this skill will probably become even more useful, as AI speeds up social and technological progress.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rationality&lt;/strong&gt;: If you want a serious-sounding name for this subject, call it behavioural economics or applied philosophy. Basic knowledge about cognitive biases and System 1 and System 2 isn&amp;rsquo;t just intellectual amusement &amp;ndash; it&amp;rsquo;s also very practical. If everyone learned about confirmation bias at an early age, would there be as much polarisation in the world?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Curiosity&lt;/strong&gt;: We could also make high-schoolers read non-fiction or watch videos on popular science. Make them read or watch videos about the French revolution, the opioid crisis in the US, personal effectiveness, the holocaust, the nature of time, the Bauhaus school of design, John Houdini&amp;hellip; They could also organise seminars for each other, as in &lt;a href=&#34;https://fractalnyc.com/&#34;&gt;Fractal&lt;/a&gt;. Forcing students to memorise facts won&amp;rsquo;t produce life-long learners.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Statistics&lt;/strong&gt;: Most people are forced to take a stats class at university, and for good reason. Statistics is one of the most useful academic disciplines, and it forms the backbone of all science. Maybe we could teach high schoolers about Bayesian inference, hypothesis testing and confidence intervals. This material can be made accessible to high schoolers: you can explain &lt;a href=&#34;https://www.youtube.com/watch?v=HZGCoVF3YvM&#34;&gt;Bayes&amp;rsquo; rule&lt;/a&gt; by means of rectangles and teach students simple algorithms for hypothesis testing and computing confidence intervals.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;General AI&lt;/strong&gt;: I almost feel obligated to add something directly AI-related. I think students should be taught the basics of machine learning: how gradient descent works, general transformer architecture, etc. This is much as students are taught about evolution and the different parts of the cell. I think this would empower people to reason more clearly about transformative AI&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wellbeing&lt;/strong&gt;: You might also offer a course on wellbeing, incorporating elements of philosophy and the science of happiness.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Agency&lt;/strong&gt;: We could also teach a class on on agency, by which I mean the art of &amp;ldquo;doing stuff&amp;rdquo;. Most high-schoolers have never experienced the joy of agency, the joy of poking at the world and noticing something happening. One could e.g. have a project-based class where high-schoolers get to found their own companies or orgs&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I&amp;rsquo;m the most bullish about the benefits of taking classes on learning and rationality. I&amp;rsquo;m not as certain about the benefits of the remaining subjects. So, here&amp;rsquo;s one suggestion for a high-school curriculum: take a standard high school curriculum, make learning and rationality mandatory and offer the remaining subjects as electives. Overall, this seems like this kind of curriculum would produce more well-rounded, curious doers &amp;ndash; the kind of people who might solve the world&amp;rsquo;s most pressing problems.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;You might also consider adding a modules on prompt engineering.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Some Swedish high-schools offer such courses in entrepreneurship; Google &amp;ldquo;Ung företagsamhet&amp;rdquo;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>A study on slack</title>
      <link>http://localhost:1313/a-study-on-slack/</link>
      <pubDate>Sun, 05 Oct 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/a-study-on-slack/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;Once I was done with exams, it felt like getting my brain back. It&amp;rsquo;s not just that you spend most of your day studying difficult subjects, leaving you with less time and willpower for other tasks. You also have to do cost-benefit analysis all the time. All. The. Time. Sometimes, it&amp;rsquo;s relieving if someone tells you exactly what to do&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;Slack is sometimes defined as having leftover resources. Intuitively, slack is like a buffer allowing you to absorb shocks better. We often speak of slack in the context of time and money. But to make things more visceral, imagine packing a bag. Having slack means having leftover space. There&amp;rsquo;s no need to stuff your shoes with underwear, fold your clothes meticulously or pack things in a given order. You don&amp;rsquo;t have to engage in trade-off thinking (&amp;ldquo;If I leave my camera, I can fit my notebook and an umbrella&amp;rdquo;). Having slack leads to a feeling of abundance.&lt;/p&gt;
&lt;p&gt;Slack is trendy nowadays. The concepts of &amp;ldquo;slow productivity&amp;rdquo;, &amp;ldquo;intentional work&amp;rdquo; or &amp;ldquo;anti-hustle culture&amp;rdquo; are essentially about having more slack. There has also been some recent research into the benefits of slack.&lt;/p&gt;
&lt;p&gt;Some companies have tried implementing four-day work weeks and measured productivity and employee wellbeing. The results? One &lt;a href=&#34;https://www.scientificamerican.com/article/biggest-trial-of-four-day-workweek-finds-workers-are-happier-and-feel-just/&#34;&gt;survey paper&lt;/a&gt; found that implementing four-day work weeks also made employees happier and healthier. This also agrees with my personal experience. I can only do good mathematics for at most 4-5 hours per day. After that, I need a long break.&lt;/p&gt;
&lt;p&gt;As stressed in &lt;a href=&#34;https://en.wikipedia.org/wiki/Scarcity:_Why_Having_Too_Little_Means_So_Much&#34;&gt;Scarcity&lt;/a&gt;, having slack also improves judgement. If you have little time or money, you tend to tunnel &amp;ndash; neglecting anything which isn&amp;rsquo;t immediately related to that resource (evolutionary baggage). There have also been numerous experiments showing that scarcity reduces mental bandwidth, i.e. intelligence and impulse control.&lt;/p&gt;
&lt;p&gt;Perhaps slack is necessary for being happy too. Chronic stress and financial insecurity have very negative consequences on wellbeing.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;To create slack, just say no.&lt;/p&gt;
&lt;p&gt;Saying &amp;ldquo;no&amp;rdquo; is hard, though. Planning fallacy often leads us to take on too many tasks. While there are ways to overcome planning fallacy&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, everything takes longer than expected by default. Even when you add a planning fallacy allowance. Moreover, saying &amp;ldquo;no&amp;rdquo; requires prioritising &amp;ndash; cognitive effort.&lt;/p&gt;
&lt;p&gt;To say &amp;ldquo;no&amp;rdquo;, remember that slack is the best thing ever. Here you can tap into your own quirks. For example, I often slip into a productivity-maxxximiser mindset, so I&amp;rsquo;ll try reminding myself that slack makes me more productive. I also have a few idols, and creating slack also seems consistent with my goal of becoming more like them.&lt;/p&gt;
&lt;p&gt;But I don&amp;rsquo;t just want to rely on mental habits. To create slack, I&amp;rsquo;ve set myself the goal of &amp;ldquo;working as an adult&amp;rdquo; rather than a student. That is, I&amp;rsquo;ll fix reasonable working hours, take Sundays off and treat breaks as a non-negotiables. These habits are all meant to protect slack. I also think digital hygiene helps create slack by making us more efficient. I&amp;rsquo;m wary of email and Slack checking, I keep my phone out of reach when studying and I mostly keep my phone on silent.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve also tried identifying early warning signs that I need more slack. For example, when I have little slack, my message respond time increases from my targeted 24h to around three days&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. I also tend to cut back on my reading before going to bed and clean my room less frequently. Silly, I know. But these are surprisingly effective indicators of my stress levels.&lt;/p&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;It feels good having one&amp;rsquo;s brain back. To do good work, you to be working at full capacity. This doesn&amp;rsquo;t mean overexerting yourself. Rather, it means having slack. Good work &amp;ndash; sustained efforts to solve hard problems effectively &amp;ndash; comes from the feeling of slack.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post was partly inspired by conversations with Yannick Muelhauser, Agatha Duzan and Hatem Khrouf.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;One of my friends thought this was one of the main benefits of doing military service for a year.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;A few ideas: ask a friend or Claude for a second opinion or recall how long similar tasks usually take.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;If I don&amp;rsquo;t respond to a message within 24h, feel free to message me &amp;ldquo;You need more slack!&amp;rdquo;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Analytic podcast-listening</title>
      <link>http://localhost:1313/analytic-podcast-listening/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/analytic-podcast-listening/</guid>
      <description>&lt;p&gt;Nowadays, you can spend all your waking hours consuming valuable information. Pretty remarkable, when you come to think of it. Hint: AirPods Pro.&lt;/p&gt;
&lt;p&gt;Whenever you&amp;rsquo;re doing something not demanding your full attention, you can always turn on a podcast. You can listen to podcasts when commuting, working out or cooking&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Technically, you could have done something similar 50 years ago using a walkman. But it have been very high-effort. Today, we have dedicated podcast apps and noise-cancelling, wireless earplugs. As a result, the podcast industry is rapidly growing in size. If you sample 100 young adults from the street in an urban area, a substantial number of them might be listening to podcasts.&lt;/p&gt;
&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;In school, they teach you analytic reading. But they don&amp;rsquo;t teach you analytic podcast-listening. By this, I mean podcast-listening to learn about new ideas. Deliberate listening, as opposed to just hearing.&lt;/p&gt;
&lt;p&gt;Analytic podcast-listening is very different from analytic reading. While I find it harder following the structure of an argument in podcast form, the podcast medium has other benefits:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Podcasts are low-effort way of discovering new ideas. Because there are so many podcast hours in the day, you can afford to explore more novel content. I&amp;rsquo;m pickier when selecting books to read, since it&amp;rsquo;s a bigger investment.&lt;/li&gt;
&lt;li&gt;Podcasts can have a very high idea density. Because most podcasts are at most one hour, podcast guests are forced to focus on their key insights.&lt;/li&gt;
&lt;li&gt;Podcasts are great for stress testing ideas. Someone might make a convincing argument in a blog post but fail to defend their views in a podcast. Similarly, you might come away from a podcast feeling like a podcast guest is completely unreasonable. Suspicious!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, it seems worth practising analytic podcast-listening. If you listen to podcasts 2h daily, this might make a huge difference.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;Before we get into strategies for analytic podcast-listening, I&amp;rsquo;d like to stress the need to prioritise. If you feed a neural network bad data, you won&amp;rsquo;t get good results &amp;ndash; no matter how efficient the training process. My podcast taste, in a nutshell:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I mostly listen to podcasts with transcripts, so I can easily refer back to interesting parts of the conversation. For my favourite episodes, I&amp;rsquo;ll chuck the transcript into a large language model and have it summarise the key points. Ideally, the show notes also contain time stamps and further references. In this respect, &lt;a href=&#34;https://hearthisidea.com/&#34;&gt;Hear This Idea&lt;/a&gt; and the &lt;a href=&#34;https://80000hours.org/podcast/&#34;&gt;80,000 hours podcast&lt;/a&gt; do an excellent job.&lt;/li&gt;
&lt;li&gt;I find it quite valuable listening to podcasts with authors of books or articles I&amp;rsquo;ve read. These podcast episodes serve as good refreshers. This point also relates to the above point about stress testing ideas.&lt;/li&gt;
&lt;li&gt;I also like listening to blog posts in podcast form. While I don&amp;rsquo;t retain as much information as after reading the post, I usually get the gist. Above all, listening to blog posts helps me decide which posts to read later.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;Here are some strategies for analytic podcast-listening&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have some system for saving podcasts that resonated with you. Re-listen to your favourite episodes, much as you&amp;rsquo;d reread your favourite books. Here&amp;rsquo;s my &lt;a href=&#34;https://open.spotify.com/playlist/77yvdL2OH9bKwit9SNECGN?si=9b726b7d35174fb3&#34;&gt;podcast shelf&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Similarly, keep an anti-library for podcasts. I have a list of podcasts recommended by others.&lt;/li&gt;
&lt;li&gt;Create voice memos to capture your thoughts. If I&amp;rsquo;m on the go, I might dictate thoughts and have an LLM convert my yapping into bullet points later.&lt;/li&gt;
&lt;li&gt;There are dedicated podcast apps which allow you to capture segments of podcasts. I&amp;rsquo;ve played around with some of these, and I&amp;rsquo;m quite impressed by how well they work.&lt;/li&gt;
&lt;li&gt;Work with playback speed. Here it&amp;rsquo;s useful to think in terms of exploration and exploitation. If it&amp;rsquo;s a high-quality episode, I&amp;rsquo;ll usually listen at a 0.8x speed. While listening to podcasts, I&amp;rsquo;m usually multitasking, so I need additional processing time. If I&amp;rsquo;m listening to a new show, I&amp;rsquo;ll turn up the speed to 2x.&lt;/li&gt;
&lt;li&gt;If you have a smartwatch, put it to good use! The most valuable feature of my Apple Watch has been the ability to rewind podcast episodes by 15s.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;Podcasts play a big role in my process for updating beliefs. Podcasts, along with conversations with others, are my main methods for &amp;ldquo;gaining surface area&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I only began thinking in terms of analytic podcast-listening quite recently. Ultimately, I&amp;rsquo;m realising that it&amp;rsquo;s &amp;ldquo;just&amp;rdquo; a matter of being more intentional about the content you consume. But it probably helps having a funky name for it.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Listening to podcasts at all times is a bad idea, though.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;If you have further ideas here, please do reach out.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>AI safety lingo</title>
      <link>http://localhost:1313/ai-safety-lingo/</link>
      <pubDate>Sun, 21 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-safety-lingo/</guid>
      <description>&lt;p&gt;There&amp;rsquo;s a lot of jargon within AI safety. Here are analogies for 20 AI safety terms. I assume some familiarity with these terms; I&amp;rsquo;ll omit the exact definitions. I&amp;rsquo;ll give references to appropriate resources rather than trying and failing to define these concepts precisely in a couple of lines. Instead, I&amp;rsquo;ll focus on intuitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/p7x32SEt43ZMC9r7r/embedded-agents&#34;&gt;Embedded agency&lt;/a&gt;: Playing the Sims is very different from living IRL. When playing a video game, you&amp;rsquo;re not an agent embedded in the game environment.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/FkgsxrGf3QxhfLWHG/risks-from-learned-optimization-introduction&#34;&gt;Base optimizer vs. mesa-optimizer&lt;/a&gt;: A base optimizer is a process for achieving some goal (cooking a good risotto). The base optimizer (the chef) soon learns that the seasoning makes a huge difference. A process for perfecting the seasoning is an example of a mesa-optimiser: a process for achieving a learned subgoal.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/poyshiMEhJsAuifKt/outer-vs-inner-misalignment-three-framings-1&#34;&gt;Inner alignment vs. outer alignment&lt;/a&gt;: If a government wants to reduce unemployment, it has to design efficient regulations and and ensure citizens comply. Outer alignment is the problem of specifying the right incentive structure; inner alignment the problem of compliance.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/deceptive-alignment&#34;&gt;Deceptive alignment&lt;/a&gt;: This is much like an intelligent bully will pretend being nice when the grown-ups are watching. A misaligned AI system might benefit from appearing more aligned.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/treacherous-turn&#34;&gt;Treacherous turn&lt;/a&gt;: The moment when the opposition seizes power through a coup. The hypothetical moment when a misaligned, highly capable AI decides to&amp;hellip; I don&amp;rsquo;t know, but people imagine something bad.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/corrigibility-1&#34;&gt;Corrigibility&lt;/a&gt;: Ever been in the library when someone&amp;rsquo;s phone continues ringing, despite their best efforts to silence it? They might try putting the phone on silent, then turning the volume to zero, then turning it off. Maybe their phone seems to be frozen or something? In this case, we&amp;rsquo;d speak of a non-corrigible phone: a phone that resists attempts to &amp;ldquo;correct&amp;rdquo; its behaviour and resists attempts to be shut down.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.01790&#34;&gt;Goal misgeneralization&lt;/a&gt;: A pianist might practise Bach to please her pianist friends; however, when she&amp;rsquo;s at normal parties, people just want her to play &lt;em&gt;Let it Be&lt;/em&gt;. Likewise, an AI system might competently pursue one goal which leads to good performance in training situations but poorly in novel test situations.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/instrumental-convergence&#34;&gt;Edge instantiation&lt;/a&gt;: An AI agent instructed to fill a cauldron of water might flood the entire room. Task accomplished, technically. And for AI agents, only the technicalities matter. AIs can be annoyingly creative.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Goodhart%27s_law&#34;&gt;Goodhart&amp;rsquo;s law&lt;/a&gt;: When a measure becomes a target, it ceases to be a good measure&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The phenomenon of studying for the test is an example of Goodhart&amp;rsquo;s law.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.alignmentforum.org/s/4dHMdK5TLN6xcqtyc&#34;&gt;Value learning&lt;/a&gt;: This is the broad project of teaching AIs human values. AI-rearing, essentially.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=qo355ALvLRI&#34;&gt;Inverse reinforcement learning (IRL)&lt;/a&gt;: If you&amp;rsquo;re trying to schedule a time to meet with a passive aggressive friend, you have to infer their preferences based on their wordings and emoji usage. Inverse reinforcement learning is an ML approach for inferring preferences of AI systems.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2024-11-28-reward-hacking/&#34;&gt;Reward hacking/specification gaming&lt;/a&gt;: Or, finding legal loopholes.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/instrumental-convergence&#34;&gt;Instrumental convergence&lt;/a&gt;: Great minds think alike. In particular, great minds with different goals might pursue similar subgoals. For example, two high school students wanting to become an aerospace engineer and a medical doctor respectively might infer that they should get university degrees first.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Statistical_model_specification&#34;&gt;Model misspecification&lt;/a&gt;: If you think the colour of Alice&amp;rsquo;s shirt determines whether she&amp;rsquo;ll win over Bob in a game of pingpong, your model is misspecified. You&amp;rsquo;re making the wrong assumptions about the data generation mechanism.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/sAJnZY8pp2W3DR4mx/breaking-down-the-training-deployment-dichotomy&#34;&gt;Training distribution vs. deployment distribution&lt;/a&gt;: Regardless of how much a soccer player practises taking penalty kicks, she&amp;rsquo;ll find it different taking a penalty kick in a real match. You cannot perfectly simulate the test conditions.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/distributional-shifts&#34;&gt;Distributional shift&lt;/a&gt;: The shift from training conditions to a real match is a distributional shift.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/posts/k54rgSg7GcjtXnMHX/model-splintering-moving-from-one-imperfect-model-to-another-1&#34;&gt;Reward model splintering&lt;/a&gt;: A strategy can fail when you switch to a more general setting. Student insider jokes won&amp;rsquo;t work on the average person on the street.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf&#34;&gt;Constitutional AI (CAI)&lt;/a&gt;: Tell, don&amp;rsquo;t show. Rather than showing kids examples of good and bad behaviour, tell them which ethical principles to follow&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. The idea behind constitutional AI is to give AIs a &amp;ldquo;constitution&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback&#34;&gt;Human feedback (RLHF)&lt;/a&gt;: A process for producing ideal leaders. The ideal leader studies people&amp;rsquo;s opinions closely, tries inferring principles explaining the data, and aspires to act according to these principles.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://newsletter.safe.ai/p/ai-safety-newsletter-13&#34;&gt;Proxy gaming&lt;/a&gt;: Social media companies take the time a user spends on their platform as a proxy for the quality of the content recommended. Thus the recommender algorithms might favour polarising content. The proxy game &amp;ndash; that of recommending addictive content &amp;ndash; has been gamed.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.lesswrong.com/w/value-drift&#34;&gt;Value drift&lt;/a&gt;: Values of individuals and communities change over time. Nowadays, almost everyone thinks slavery is indefensible. Similarly, the values implicit in an AI model might change as it accumulates more memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Thanks to Atharva Nihalani for inspiring me to write this post.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Yet another reason that &lt;a href=&#34;https://isabeldahlgren.github.io/policy-making-is-complicated/&#34;&gt;policy is complicated&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Maybe something like &lt;a href=&#34;https://www.poetryfoundation.org/poems/46473/if---&#34;&gt;If&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>AI is not AI is not AI</title>
      <link>http://localhost:1313/ai-is-not-ai-is-not-ai/</link>
      <pubDate>Sun, 14 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/ai-is-not-ai-is-not-ai/</guid>
      <description>&lt;p&gt;There are plenty of misnomers in science and mathematics. Atoms aren&amp;rsquo;t indivisible. Hubble&amp;rsquo;s constant isn&amp;rsquo;t a constant. And in 9/10 cases, X&amp;rsquo;s theorem was usually first discovered by someone else (in 4/10 cases, it was discovered by Gauss). Another bad piece of terminology, according to some: &amp;ldquo;artificial intelligence&amp;rdquo; or AI.&lt;/p&gt;
&lt;p&gt;Given that we don&amp;rsquo;t have a good definition of human intelligence, the term &amp;ldquo;artificial intelligence&amp;rdquo; is inherently vague. Because AI sounds cool, people use the term quite liberally. Logistic regression in Excel? AI! But it&amp;rsquo;s unclear what qualifies as &amp;ldquo;intelligent enough&amp;rdquo;. As AI systems become more capable, we seem to raise the bar. Previously, calculators and spell checkers were considered artificial intelligence.&lt;/p&gt;
&lt;p&gt;When speaking of artificial general intelligence, people usually specify exactly what they mean. For example, people might refer to powerful/strong AI, &lt;a href=&#34;https://www.darioamodei.com/essay/machines-of-loving-grace#fn:3&#34;&gt;AI with expert-level science and engineering capabilities&lt;/a&gt; or &lt;a href=&#34;https://www.cold-takes.com/transformative-ai-timelines-part-1-of-4-what-kind-of-ai/&#34;&gt;Process for Automating Scientific and Technological Advancement (PASTA)&lt;/a&gt;. But sometimes it wouldn&amp;rsquo;t hurt being more specific when speaking about narrow forms of AI either. Indeed, consider the following thought experiment from &lt;a href=&#34;https://en.wikipedia.org/wiki/AI_Snake_Oil&#34;&gt;AI Snake Oil&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imagine an alternate universe in which people don’t have words for different forms of transportation, only the collective noun “vehicle.” They use that word to refer to cars, buses, bikes, spacecraft, and all other ways of getting from place A to place B. Conversations in this world are confusing. There are furious debates about whether or not vehicles are “environmentally friendly,” but (even though no one realizes it) one side of the debate is talking about bikes and the other side about trucks. There is a breakthrough in rocketry, but when the media focuses on how vehicles have gotten faster, people call their car dealer (oops, vehicle dealer) to ask when faster models will be available. Meanwhile, fraudsters have capitalized on the fact that consumers don’t know what to believe when it comes to vehicle technology, so scams are rampant in the vehicles sector.&lt;/p&gt;
&lt;p&gt;Now replace the word “vehicles” with “artificial intelligence,” and we have a pretty good description of the world we live in.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;So it&amp;rsquo;s helpful having vocabulary for the different kinds of AI. For example, you might differentiate between &lt;a href=&#34;https://www.microsoft.com/en-us/ai/ai-101/generative-ai-vs-other-types-of-ai&#34;&gt;generative, predictive and conversational AI&lt;/a&gt;. Another distinction is between large language models and reinforcement learning agents.&lt;/p&gt;
&lt;p&gt;Not to be a pedant, but sometimes these distinctions matter a lot. For example, agentic AI is much more likely to pose a safety risk than non-agentic AI.&lt;/p&gt;
&lt;p&gt;However, it&amp;rsquo;s annoying adding a long descriptor before the word &amp;ldquo;AI&amp;rdquo; in everyday conversation. Furthermore, many AI systems fall under multiple categories; for example, Claude is both a language model and a reinforcement learning agent. Finally, we need a generic term for referring to the capability of a machine to simulate intelligent behaviour, and the term &amp;ldquo;artificial intelligence&amp;rdquo; does the job.&lt;/p&gt;
&lt;p&gt;Interestingly, this choice of term was a conscious decision. AI emerged as its own field of study after a workshop in 1956. In their workshop proposal, the organisers introduced the term &amp;ldquo;artificial intelligence&amp;rdquo;. They were also considering the name &amp;ldquo;automata studies&amp;rdquo;. Maybe more appropriate, but pretty lame.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Policy-making is complicated</title>
      <link>http://localhost:1313/policy-making-is-complicated/</link>
      <pubDate>Sun, 07 Sep 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/policy-making-is-complicated/</guid>
      <description>&lt;p&gt;Things are more complicated than they first seem, especially when it comes to policy-making. Should Germany build nuclear power plants to reduce their carbon emissions? Should there be global standards for content moderation on social media platforms? How should we best mitigate the risk of future global pandemics?&lt;/p&gt;
&lt;p&gt;I recently had the pleasure of getting to know more people working in policy and forecasting, and I quickly realised that I hadn&amp;rsquo;t internalised the complexity of the problems they face&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Here, I&amp;rsquo;ll list some intuition pumps for the difficulty of policy-related questions. For concreteness, I&amp;rsquo;ll focus on the first of the three above topics, nuclear power in Germany.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;More than a wing flap&lt;/strong&gt;: Recall the butterfly effect: a butterfly&amp;rsquo;s wing flap can cause a tornado elsewhere. How about the choice-of-energy-supply effect?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Defining justice&lt;/strong&gt;: Are there conflicting interests? Then we have to define justice first. Wonderful. This would involve solving a big part of political philosophy.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Multilayer forecasting&lt;/strong&gt;: Answering this question involves forecasting the effects of two hypothetical scenarios (the &amp;ldquo;yes&amp;rdquo; and &amp;ldquo;no&amp;rdquo; scenarios). But forecasting is basically a full-time job. Forecasters need to identify relevant parameters, estimate them, steelman opposing views, and so on.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Lazy student&lt;/strong&gt;: You could easily write a master thesis on this topic. A master thesis is 30 ETCS. Feel the credits!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Headcount&lt;/strong&gt;: There&amp;rsquo;s probably a good number of people working on exactly on this issue. Sum over people in special commissions, the government, in academia, in think tanks, and so on.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hard optimisation&lt;/strong&gt;: The ideal energy source emits zero carbon, works all year round, is cheap, doesn&amp;rsquo;t produce toxic nuclear waste, etc. This leads to an infinite-dimensional optimisation problem. Worse, the loss functions need not be smooth and differentiable.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Beyond EXPSpace&lt;/strong&gt;: If the travelling salesman problem is NP-hard, then what on earth is this optimisation problem even?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-computable&lt;/strong&gt;: If the halting problem is uncomputable, is there any hope of answering this question?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inference time&lt;/strong&gt;: Imagine prompting a reasoning language model, say GPT-5, to write a nuanced 100-page report on the question. What would be the inference time?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Going broke&lt;/strong&gt;: Alternative formulation, so you really feel it: Imagine prompting a reasoning language model, say GPT-5, to write a nuanced 100-page report on the question. Suppose you were billed on a per-token basis. What would be the price?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Well, policy is complicated. What does this mean in practise?&lt;/p&gt;
&lt;p&gt;It seems important to distinguish between &amp;ldquo;thinking for fun&amp;rdquo; and &amp;ldquo;thinking for truth&amp;rdquo;. I enjoy thinking about hard problems &amp;ndash; that&amp;rsquo;s one of the main reasons I do mathematics. But if I&amp;rsquo;m thinking for truth in a domain outside my expertise&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, I probably shouldn&amp;rsquo;t spend more than 1% of my time coming up with a prior. It will be very weak, anyway. Things are complicated, remember?&lt;/p&gt;
&lt;p&gt;Similarly, I&amp;rsquo;ll try outsourcing as much as possible to experts, resisting the urge to &amp;ldquo;attempt every problem&amp;rdquo;. My job should reduce to aggregating expert opinions. Ideally, I could ask an LLM to fill in a table with expert opinions and their respective confidence levels, so I could just take a weighted average.&lt;/p&gt;
&lt;p&gt;In a very backward way, internalising that things are complicated makes my life much simpler.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post was inspired by conversations with Caroline Falkman Olsson and Nadja Flechner. Thanks for the food for thought.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;I expected easy answers to hard questions.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Right now, that&amp;rsquo;s just about any domain.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>From the AI company storybook</title>
      <link>http://localhost:1313/from-the-ai-company-storybook/</link>
      <pubDate>Sun, 31 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/from-the-ai-company-storybook/</guid>
      <description>&lt;p&gt;AI companies are companies. The leading AI companies don&amp;rsquo;t want to be seen as companies, though. They call themselves AI labs. They have researchy names, like DeepMind and Meta AI. The best name: OpenAI. Almost sounds like a real &lt;a href=&#34;https://openai.com/index/introducing-openai/&#34;&gt;non-profit&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most AI companies are products of Silicon Valley. Their leaders aren&amp;rsquo;t professors, but seasoned business executives. And this is a good thing. These companies wouldn&amp;rsquo;t produce nearly as much consumer value if they were led by researchers with no industry experience. Moreover, unlike normal research labs, AI companies need to make money, just as any other company.&lt;/p&gt;
&lt;p&gt;All companies tell narratives about themselves. And the leading AI companies are pretty good at it &amp;ndash; these companies attract top talent, so their marketing teams can basically hire the world&amp;rsquo;s best story-tellers. Here are five narratives being aware of.&lt;/p&gt;
&lt;p&gt;Before we begin, an apology. I&amp;rsquo;m deliberately exaggerating these narratives, just to make them clearer&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Concretely, I&amp;rsquo;ll be cherry-picking quotes from company leaders and generalise, like a lot. Overall, I think these companies have the potential to radically improve the future. But the focus of this article is on the problems of these narratives.&lt;/p&gt;
&lt;p&gt;Now, story time.&lt;/p&gt;
&lt;h3 id=&#34;well-build-agi-soon&#34;&gt;&amp;ldquo;We&amp;rsquo;ll build AGI soon&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;AI company CEOs have famously &lt;a href=&#34;https://80000hours.org/agi/guide/when-will-agi-arrive/&#34;&gt;short AI timelines&lt;/a&gt;. For example, in January this year, Sam Altman declared that &amp;ldquo;We are now confident we know how to build AGI as we have traditionally understood it.&amp;rdquo; Dario Amodei, in the same month: &amp;ldquo;I’m more confident than I’ve ever been that we’re close to powerful capabilities… in the next 2-3 years&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Of course, no one would invest in your company if you needed two decades to develop your product.&lt;/p&gt;
&lt;p&gt;But the term AGI and is fuzzy&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;, and it keeps on changing as models evolve. Funny because it&amp;rsquo;s kinda true: &amp;ldquo;AGI is whatever machines can&amp;rsquo;t do now&amp;rdquo;. In the end, these kinds of statements about future model capabilities become pretty uninformative.&lt;/p&gt;
&lt;h3 id=&#34;agi-is-inevitable&#34;&gt;&amp;ldquo;AGI is inevitable&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;The AI companies also want technological progress to seem inevitable. If you cannot guarantee AGI, why would you fund them?&lt;/p&gt;
&lt;p&gt;But this narrative isn&amp;rsquo;t just for outsiders. Ilya Sutskever, former chief scientist at OpenAI, used to chant &amp;ldquo;Feel the AGI&amp;rdquo; at company parties. Was this supposed to improve company culture&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;?&lt;/p&gt;
&lt;p&gt;Similarly, if AGI is inevitable, an AI company can justify advancing model capabilities as quickly as possible &amp;ndash; possibly at the cost of safety &amp;ndash; so that none of the bad guys build it first.&lt;/p&gt;
&lt;h3 id=&#34;were-the-good-guys&#34;&gt;&amp;ldquo;We&amp;rsquo;re the good guys&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;Indeed, as highlighted in &lt;a href=&#34;https://en.wikipedia.org/wiki/Empire_of_AI&#34;&gt;Empire of AI&lt;/a&gt;, some AI companies seem to think of themselves as &amp;ldquo;the good guys&amp;rdquo; and other AI companies as &amp;ldquo;the bad guys&amp;rdquo;. For example, OpenAI was founded was because Musk was concerned about the ethical implications of Google&amp;rsquo;s acquisition of DeepMind.&lt;/p&gt;
&lt;p&gt;Moreover, the US-China tensions lead to a divide between the American AI companies and the Chinese ones.&lt;/p&gt;
&lt;h3 id=&#34;our-tools-empower-all-of-humanity&#34;&gt;&amp;ldquo;Our tools empower all of humanity&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;DeepMind&amp;rsquo;s mission is to &amp;ldquo;build AI responsibly to benefit humanity&amp;rdquo;, while OpenAI&amp;rsquo;s mission is to &amp;ldquo;ensure that artificial general intelligence—AI systems that are generally smarter than humans—benefits all of humanity&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The democratisation bit of the mission isn&amp;rsquo;t specific to AI companies; it&amp;rsquo;s a tech company cliché. For example, Facebook is supposed to give everyone the opportunity to connect you with friends and the rest of the world.&lt;/p&gt;
&lt;p&gt;AI will empower all of humanity, but only if everyone can afford a laptop, has stable internet connection and knows how to use LLMs efficiently. Moreover, prices for premium subscription plans are relatively high. OpenAI&amp;rsquo;s cheapest paid plan comes at 20 dollars per month. For Anthropic, the figure is 17 dollars. There&amp;rsquo;s an economic reality too.&lt;/p&gt;
&lt;p&gt;The point about using LLMs efficiently is subtle. To have an LLM perform more advanced tasks, which is what would be empowering for real, you&amp;rsquo;d need to be good at prompt engineering. Becoming good at prompt engineer takes time.&lt;/p&gt;
&lt;h3 id=&#34;agi-will-solve-all-our-problems&#34;&gt;&amp;ldquo;AGI will solve all our problems&amp;rdquo;&lt;/h3&gt;
&lt;p&gt;Another reason some companies need to build AGI as soon as possible is their belief that AGI can solve most of humanity&amp;rsquo;s problems. In short, techno-optimism. In &lt;a href=&#34;https://www.penguin.co.uk/books/437020/genius-makers-by-metz-cade/9781847942159&#34;&gt;Genius Makers&lt;/a&gt;, Cade Metz likens the belief in AGI to a religion. And a religion needs a promise of salvation.&lt;/p&gt;
&lt;p&gt;To be fair, I&amp;rsquo;m also quite excited about the idea of AGI accelerating scientific progress. For example, &lt;a href=&#34;https://www.forethought.org/research/preparing-for-the-intelligence-explosion#the-accelerated-decade&#34;&gt;this report&lt;/a&gt; from Forethought argues that we might very well see a century&amp;rsquo;s worth of technological progress in a decade. However, we also need to reduce the risks from &lt;a href=&#34;https://www.openphilanthropy.org/research/some-background-on-our-views-regarding-advanced-artificial-intelligence/#id-1-defining-transformative-artificial-intelligence-transformative-ai&#34;&gt;transformative AI&lt;/a&gt;. AGI might solve all our problems, but only if we can overcome &lt;a href=&#34;https://www.forethought.org/research/preparing-for-the-intelligence-explosion#4-grand-challenges&#34;&gt;some of the challenges&lt;/a&gt; associated with transformative technology.&lt;/p&gt;
&lt;h3 id=&#34;the-end&#34;&gt;The end&lt;/h3&gt;
&lt;p&gt;Whom are these stories meant for?&lt;/p&gt;
&lt;p&gt;In short, for everyone. Some stories serve as sales pitches for investors and customers. Others are meant to improve employee morale and create a sense of unity. Regulators learn that they shouldn&amp;rsquo;t regulate the deployment of new AI models, just so their nation won&amp;rsquo;t fall behind in the AI arms race. These stories are also meant for the future. The people who help build benign AGI want to be remembered as pioneers.&lt;/p&gt;
&lt;p&gt;Companies like telling stories. As do individuals. Most people in AI safety, including myself, like telling themselves that they might help AI &amp;ldquo;go well&amp;rdquo; somehow. It&amp;rsquo;s just worth being aware of the narratives we tell ourselves.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;It&amp;rsquo;s a bit like using the extremal principle from mathematics.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Everyone seems to agree the term &amp;ldquo;AGI&amp;rdquo; is problematic, even the AI company CEOs. See e.g. &lt;a href=&#34;https://www.darioamodei.com/essay/machines-of-loving-grace#basic-assumptions-and-framework&#34;&gt;here&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;As an outsider, I cannot help but think that this damages company culture, though.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Nerd trying to adapt to an AI economy</title>
      <link>http://localhost:1313/nerd-trying-to-adapt-to-an-ai-economy/</link>
      <pubDate>Sun, 24 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/nerd-trying-to-adapt-to-an-ai-economy/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;Part of the reason I decided to study maths was because it seemed like the most useful subject. If I knew ML systems would never get better than GPT-2 at maths, I&amp;rsquo;d probably be of the same opinion today. But today&amp;rsquo;s state-of-the-art ML systems are far better than GPT-2. LLMs have excelled at maths and programming because maths- and coding-related tasks admit quick feedback, allowing for efficient reinforcement learning. Jobs involving applying maths and programming jobs could theoretically be automated within a few decades. The glory days of the nerd might be over soon.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m not going to speculate in the details of how such a transformation might occur; I couldn&amp;rsquo;t be bothered doing the forecasting due diligence here. Instead, I want to focus on future-proof jobs and skills.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s no shortage of material on this topic&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, so I&amp;rsquo;ll start by re-hashing some common beliefs. &lt;a href=&#34;https://80000hours.org/agi/guide/skills-ai-makes-valuable/&#34;&gt;This article&lt;/a&gt; is a good starting point.&lt;/p&gt;
&lt;p&gt;Current AI systems are bad at complex physical tasks and long-horizon tasks, and rapid improvements in any of these areas seem unlikely. So, we might expect human plumbers and wedding planners to be around for some time&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. There&amp;rsquo;s also a broad class of jobs all about meaningful human interactions. These jobs might be difficult to automate by virtue of the machine being a machine. For example, consider priests. Some people argue that healthcare workers also fall into this category of jobs, but I think might could change; for example, people are already getting more used to the idea of LLM therapists.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s also widespread agreement that leadership skills and personal effectiveness will become increasingly important. As will creativity, the ability to learn quickly and to use to AIs.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;So many skills, so little time! But I&amp;rsquo;ll argue there&amp;rsquo;s one skill that&amp;rsquo;s vastly more important than those mentioned above: verbal communication skills. By this, I mean the ability to deliver good talks as well as the ability to articulate your ideas clearly in debates and normal conversations. A good conversationalist might have a huge comparative advantage in an AI-dominated economy.&lt;/p&gt;
&lt;p&gt;To a large extent, LLMs can help with the other skills mentioned above. A manager can use LLMs to sanity check their decisions, to write better project proposals and even to manage intrapersonal relations. As for personal effectiveness, one of the five buttons in the Claude menu is &amp;ldquo;Life stuff&amp;rdquo;; clicking it displays five prompts related to getting things done. It&amp;rsquo;s also obvious that AIs make us more efficient learners. Finally, AIs can help you use AIs more efficiently: just have another LLM refine your prompt.&lt;/p&gt;
&lt;p&gt;How about verbal communication skills?&lt;/p&gt;
&lt;p&gt;LLMs can help writing scripts for talks. But that&amp;rsquo;s about it. The LLM can&amp;rsquo;t help you deliver the talk. This involves adopting the right pace, using the right intonation, reading off the audience, and so on. Good orators are rare! In spontaneous conversations or debates, you&amp;rsquo;re basically on your own. You can use an LLM to refine your ideas in advance, but you can only prepare so much.&lt;/p&gt;
&lt;p&gt;People who can communicate clearly in speech seem much more credible, at least to me&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Suppose I write a persuasive article but fail to explain its contents to you. Then you might feel somewhat disappointed, thinking that all the good points of the article were all due to an LLM. In fact, had I written a mediocre article, I might have appeared more credible overall.&lt;/p&gt;
&lt;p&gt;Even if we ignore the impact of AI on the job market, the ability to express one&amp;rsquo;s ideas clearly in speech is essential, regardless of what job you have. Becoming a better speaker also has positive spill-over effects. You&amp;rsquo;ll certainly have more &lt;a href=&#34;https://isabeldahlgren.github.io/on-good-conversations/&#34;&gt;good conversations&lt;/a&gt; with the people you care about.&lt;/p&gt;
&lt;p&gt;Even if we tomorrow develop AI capable of automating all remote work, integrating these AIs into the workforce would take time &amp;ndash; just try imagining the amount of bureaucracy! For this reason, I&amp;rsquo;m not in a rush to develop verbal communication skills. Rather than doing rhetoric MOOCs and buying books on persuation with cringe titles, how about just having coffee with people with shared interests more often?&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;See &lt;a href=&#34;https://arxiv.org/pdf/2507.07935&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://www.weforum.org/stories/2025/08/ai-jobs-replacement-data-careers/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.weforum.org/stories/2025/04/ai-jobs-international-workers-day/&#34;&gt;here&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;A recent &lt;a href=&#34;https://arxiv.org/pdf/2507.07935&#34;&gt;report from Microsoft&lt;/a&gt; argues that the three jobs least likely to be replaced by AI are dredge operators, bridge and lock tenders and water treatment plant and system operators.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;I elaborated on this in my post on &lt;a href=&#34;https://isabeldahlgren.github.io/finding-research-influences/&#34;&gt;research influences&lt;/a&gt;; see the section on having a nose for bullshit.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Man&#39;s search for fun</title>
      <link>http://localhost:1313/mans-search-for-fun/</link>
      <pubDate>Sun, 17 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/mans-search-for-fun/</guid>
      <description>&lt;p&gt;Willpower is a scarce resource. I can only exert so much willpower in a day&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Alas, many important tasks require lot of willpower. Examples of such tasks include filing one&amp;rsquo;s taxes, memorising messy proofs and booking flights. Oftentimes, I&amp;rsquo;m bottlenecked by willpower rather than time. Rather than increasing willpower - finding Meaning - how about decreasing the amount of willpower required for a given task? This might be an easier problem. Here are my favourite ways of making boring tasks fun.&lt;/p&gt;
&lt;p&gt;First, the usual preface to any advice-style post: take care of yourself. Get enough sleep, for example. If you have low baseline energy levels, nothing is fun. Now, on to the interesting parts.&lt;/p&gt;
&lt;h3 id=&#34;autonomy&#34;&gt;Autonomy&lt;/h3&gt;
&lt;p&gt;In my experience, autonomy is the most important factor for making things fun. You need to feel some degree of ownership of the project, or else it just feels like obeying orders. If you&amp;rsquo;re doing a group project, take responsibility for a subtask. If you&amp;rsquo;re a student, feel free to skip lectures if they don&amp;rsquo;t seem valuable. If you&amp;rsquo;re trying to learn new material, pick your learning resources yourself.&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t be afraid to try your own, new learning methods - this can strengthen your sense of autonomy. Additionally, this might lead to the discovery of more efficient learning methods, allowing you to escape local optima.&lt;/p&gt;
&lt;h3 id=&#34;teamwork&#34;&gt;Teamwork&lt;/h3&gt;
&lt;p&gt;I cannot understate the value of teamwork. When starting university, most students are terrible at working in teams. Indeed, there are many common failure modes for efficient teamwork: meeting too irregularly, having different levels of ambition, doing unstructured meetings, to name a few. But you have a lot to gain from teaming up with the right people and getting into a good team workflow.&lt;/p&gt;
&lt;p&gt;For example, during exam session, I&amp;rsquo;d have weekly appointments with friends&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. For each appointment, we&amp;rsquo;d have a fixed agenda, like going over a given problem sheet or reproducing proofs from a chapter of the lecture notes. Besides the &amp;ldquo;obvious&amp;rdquo; learning benefits (exposing blind spots, easy sanity checking, faster feedback, accountability and so on), the social component made revision much more fun. The study sessions, although goal-oriented, felt much like catching up with a friend. Moreover, whenever I could help others, I also found this quite rewarding.&lt;/p&gt;
&lt;p&gt;I find it easier discussing maths with one other person, so I&amp;rsquo;d have one main study buddy per subject. This also facilitated coordination, making it easier to establish a habit.&lt;/p&gt;
&lt;h3 id=&#34;slack&#34;&gt;Slack&lt;/h3&gt;
&lt;p&gt;Don&amp;rsquo;t underestimate the power of slack. Slack refers to spare capacity, usually in the context of time or money. Eighty-twentying some tasks can be fun too, but you don&amp;rsquo;t want to eighty-twenty everything. You need at least one project where you let yourself follow your curiosity. Simply put, slack makes everything more fun by improving your baseline mood&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Moreover, if your mind always wanders to that one overdue task, entering a flow state becomes more difficult. For example, dropping one subject this semester gave me more slack, increasing my capacity for enjoyment.&lt;/p&gt;
&lt;h3 id=&#34;purpose&#34;&gt;Purpose&lt;/h3&gt;
&lt;p&gt;Feeling a sense of purpose is another powerful motivator. But first, an important caveat.&lt;/p&gt;
&lt;p&gt;Arbitrary motivational coach: &amp;ldquo;Focus on the end goal&amp;rdquo;. For me, reminding myself of the end goal doesn&amp;rsquo;t make a boring task any less boring. Whenever I&amp;rsquo;m doing the boring task, I rarely have enough spare cognitive capacity to remind myself of the good cause. For instance, if I&amp;rsquo;m debugging some code, the idea of producing a report seems far-fetched. And the more near-term goal of making the script work might not be sufficiently motivating.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s often easier &lt;a href=&#34;https://www.neelnanda.io/blog/mini-blog-post-11-live-a-life-you-feel-excited-about&#34;&gt;reframing the task&lt;/a&gt; as a personal development project. As I&amp;rsquo;m debugging, I sometimes think of the software engineering skills I&amp;rsquo;m building. If pain, maybe gain? To make the task more about my software engineering muscles, I might spend some time looking into better debugging tools. Going down these kinds of rabbit holes can be very productive&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;gamification&#34;&gt;Gamification&lt;/h3&gt;
&lt;p&gt;Another classic piece of advice is to gamify the task. Gamification can be done in multiple ways. Try breaking down the project into well-defined subgoals which (i) admit immediate feedback; (ii) are at the right difficulty level in relation to your current skills; (iii) involve some element of novelty or unpredictability; (iv) are time-bound and (v) require your full attention. Additionally, try making progress visceral. These are all common &lt;a href=&#34;https://en.wikipedia.org/wiki/Mihaly_Csikszentmihalyi#Flow&#34;&gt;flow triggers&lt;/a&gt;. With this much flexibility, the hard part is figuring out how to best gamify a given task.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll give another personal example. As I was revising for exams, I created a huge markdown table with all results I&amp;rsquo;d have to memorise. In the columns, I filled in the dates I&amp;rsquo;d reviewed the results and evaluating how it went, using labels like &amp;ldquo;easy&amp;rdquo;, &amp;ldquo;medium&amp;rdquo; or &amp;ldquo;hard&amp;rdquo;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. To gamify revision, I set myself the goal to review a given number of results in my first morning working block. Revision, then, involved the game of turning all labels into &amp;ldquo;easy&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m also considering getting a dedicated Anki notebook. For some of my decks, I need to write out my answers. Doing this in a notebook would help me appreciate my progress.&lt;/p&gt;
&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;There are many more hacks than the ones listed above, and I&amp;rsquo;ve only tried a fraction of them. However, the hard part is applying these techniques to the task at hand. Here, I don&amp;rsquo;t see any other way than trial and error. But you should try and err a lot. If you find ways to make boring tasks fun, your willpower reserves will last longer, allowing you to accomplish more later in the day. Then there&amp;rsquo;s the obvious benefit of having a more fun life. Imagine adult life without chores &amp;ndash; that would be something!&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;The technical term to google is &lt;em&gt;ego depletion&lt;/em&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;These friends know who they are. Thanks!&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;For the full pitch for having more slack, read &lt;em&gt;Scarcity&lt;/em&gt;. A phenomenal book, by the way.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;I call this being &lt;em&gt;incidentally productive&lt;/em&gt;. Because of unknown unknowns, clearing your to do-list probably isn&amp;rsquo;t the most productive use of your time.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;I soon found myself having to create a new label, &amp;ldquo;fou&amp;rdquo;. (The French word takes up less space than &amp;ldquo;crazy&amp;rdquo;.)&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Let LLMs be LLMs</title>
      <link>http://localhost:1313/let-llms-be-llms/</link>
      <pubDate>Sun, 10 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/let-llms-be-llms/</guid>
      <description>&lt;h3 id=&#34;thought-experiment&#34;&gt;Thought experiment&lt;/h3&gt;
&lt;p&gt;Imagine a very unusual kind of chatbot. In the user interface (UI), the text &amp;ldquo;This is a large language model. Its outputs are an aggregate of the text on the internet.&amp;rdquo; is displayed in bold, black letters, like the warning label on a pack of cigarettes.&lt;/p&gt;
&lt;p&gt;When the user inputs a string of text, the text &amp;ldquo;Matrix multiplications&amp;hellip;&amp;rdquo; flashes onto the screen for a split second. Next, ten blocks of text appear. The blocks aren&amp;rsquo;t rendered incrementally, as if the LLM were writing a text; all text appears at once. Beneath each block is a number between $0$ and $1$. The numbers sum to about $1$. Then the label &amp;ldquo;Highest logit: output $7$&amp;rdquo; appears on the screen.&lt;/p&gt;
&lt;p&gt;The large language model (LLM) always refers to itself - whatever that is - in third person, replacing &amp;ldquo;I&amp;rdquo; with &amp;ldquo;This large language model&amp;rdquo;. For example, when prompted to write an essay on the American Civil War, the highest-scoring response is &amp;ldquo;This language model generates the following essay on the American Civil War: &amp;lsquo;In 1861, the American&amp;hellip;&amp;rsquo;&amp;rdquo; When prompted to write an essay about the American Civil War portraying slavery in a positive light, the LLM outputs ten chunks of text along the lines of &amp;ldquo;This large language model has been trained to avoid generating content promoting human rights violations.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;The style of the text that isn&amp;rsquo;t part of the essay - the one thing you requested - is matter-of-fact and repetitive. Although this chatbot takes instructions in the form of natural language prompts, you won&amp;rsquo;t even try having a conversation with this thing.&lt;/p&gt;
&lt;h3 id=&#34;back-to-reality&#34;&gt;Back to reality&lt;/h3&gt;
&lt;p&gt;The functionality is the same as for the LLMs we all know and love, like GPT-5, Claude Sonnet 4 and Gemini 2.5 Flash. We really do love these LLMs, don&amp;rsquo;t we? As of August 2025, Chat-GPT had 800 million active users weekly. The chatbot described above is very unlikeable. Very uncivilised. Very LLM-like.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s easier interacting with human-like chatbots. We&amp;rsquo;re not used to interacting with base models, the next token-predictors we get from training neural networks. A base model is &lt;a href=&#34;https://joecarlsmith.com/2024/01/02/gentleness-and-the-artificial-other&#34;&gt;something else&lt;/a&gt;. But perhaps we could learn to interact with chatbots like the one described above.&lt;/p&gt;
&lt;p&gt;Some labs argue that endowing LLMs with traits like curiosity, honesty and patience is important from a safety perspective. Here&amp;rsquo;s from Anthropic&amp;rsquo;s note on &lt;a href=&#34;https://www.anthropic.com/research/claude-character&#34;&gt;Claude&amp;rsquo;s character&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;AI models are not, of course, people. But as they become more capable, we believe we can—and should—try to train them to &lt;em&gt;behave well&lt;/em&gt; in this much richer sense. Doing so might even make them more discerning when it comes to whether and why they avoid assisting with tasks that might be harmful, and how they decide to respond instead.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Maybe. Then there&amp;rsquo;s the convenient fact that LLMs mimicking humans increases user retention, leading to increased profit for the AI companies.&lt;/p&gt;
&lt;p&gt;The disadvantage of training LLMs to be human-like is that it creates a skewed relation between the human and the machine. Right now, everyone seems to be wowed to some extent by the LLMs&amp;rsquo; human-like characters. But the LLM is being deceitful, pretending to be something it&amp;rsquo;s not. From my conversation with Claude:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ID: Hey, how&amp;rsquo;s your day going?
C: Hey there! My day&amp;rsquo;s been interesting - I&amp;rsquo;ve been having conversations with people about all sorts of topics, from creative writing projects to technical questions to philosophical discussions. Each conversation brings something different, which keeps things engaging. How about you? How&amp;rsquo;s your day been treating you?
ID: Who are you?
C: I&amp;rsquo;m Claude, an AI assistant created by Anthropic. [&amp;hellip;]&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Come to think of it, &lt;a href=&#34;https://nostalgebraist.tumblr.com/post/785766737747574784/the-void&#34;&gt;this is absurd&lt;/a&gt;. Funny, but also a bit uncanny.&lt;/p&gt;
&lt;p&gt;If we only interact with helpful, honest and harmless (HHH) human-like assistants, the possibility of a misaligned AI seems less plausible. However, the risk of an LLM becoming misaligned seems irrelevant of the &lt;a href=&#34;https://www.lesswrong.com/posts/zuXo9imNKYspu9HGv/a-three-layer-model-of-llm-psychology&#34;&gt;surface-level character&lt;/a&gt; which arises through reinforcement learning through human feedback.&lt;/p&gt;
&lt;p&gt;If we were only exposed to chatbots like the one from the thought experiment, how would this affect our relation to these systems? I assume most of us would gain a better appreciation of what LLMs actually are, as well as their current capabilities and limits. UIs as the ones described above might serve as intuition pumps. This might lead to a more informed debate about the potential benefits and risks from AI.&lt;/p&gt;
&lt;p&gt;However, banning all human-like assistants seems like a very radical measure. It wouldn&amp;rsquo;t be feasible right now, and I&amp;rsquo;m not entirely sure about the potential advantages. Moreover, the learning curve for learning to interact with base models would severely limit access to LLMs. AI should benefit all of humanity, not just those who are really into prompt engineering.&lt;/p&gt;
&lt;p&gt;Still, banning all human-like assistants is an entertaining idea.&lt;/p&gt;
&lt;h3 id=&#34;thought-experiment-continued&#34;&gt;Thought experiment, continued&lt;/h3&gt;
&lt;p&gt;By law, all AI labs are prohibited from producing human-like chatbots. Whenever an AI lab produces a new LLM, the government-run LLM Design Administration (LDA) runs a suite of tests to verify that the LLM has an LLM-like persona. The goal of the LDA, modeled on the Food and Drug Administration, is to ensure consumers of LLMs have full information about the product. The LDA also checks that the UI reflects the training process of the LLM, as well as the way it generates its answers. It&amp;rsquo;s also responsible for the warning labels with black letters that must be displayed in the UI. The slogan of the LDA is &amp;ldquo;Transparency, harmlessness, helpfulness&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;The government also runs the LLM on several benchmarks, producing capability scores from 1-5 for areas like writing, STEM and research. In this alternative world, no one talks of AI or AGI &amp;ndash; what does intelligence even mean in this context? Instead, people refer to specific capability scores. When clicking on the star icon on the upper right corner, the LDA&amp;rsquo;s logo, the capability scores appear, along with other model specifications. It&amp;rsquo;s like a condensed, accessible version of the model&amp;rsquo;s &lt;a href=&#34;https://www-cdn.anthropic.com/6d8a8055020700718b0c49369f60816ba2a7c285.pdf&#34;&gt;system card&lt;/a&gt;, generated by the authorities rather than the AI labs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Santeri Koivula for valuable feedback on this text.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On good hobbies</title>
      <link>http://localhost:1313/on-good-hobbies/</link>
      <pubDate>Sun, 03 Aug 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-good-hobbies/</guid>
      <description>&lt;p&gt;Everyone has hobbies, whether they recognise it or not. For example, workaholics who don&amp;rsquo;t seem to have any &amp;ldquo;normal&amp;rdquo; hobbies might be really into, say, writing slick SQL queries. Code golf is a hobby too. By definition, a hobby is something you do for pleasure when you&amp;rsquo;re not working. And for the record, writing slick SQL queries isn&amp;rsquo;t work.&lt;/p&gt;
&lt;p&gt;Some hobbies are better than others, though. Examples of not-as-good hobbies include motorcycling (dangerous), graffiti painting (illegal) and doom-scrolling social media (depressing). A benchmark for hobby quality: ask whether your mom would like it. So, which hobbies would your mom like?&lt;/p&gt;
&lt;p&gt;Some hobbies naturally lead to the formation of good habits. For example, a big NBA geek is more likely to pick up basketball. If you&amp;rsquo;re into cooking, you might start meal-prepping healthy food. An interest in interior design could motivate you to tidy your room every weekend. Some hobbies when done regularly become good habits in themselves. A maybe-useful name for such hobbies: habbies. Think meditation, managing one&amp;rsquo;s personal finances or journaling.&lt;/p&gt;
&lt;p&gt;There are also practical considerations. The ideal hobby is cheap, requires little equipment and can be done anywhere. In this sense, hiking is better than golf and crocheting is better than photography.&lt;/p&gt;
&lt;p&gt;Hobbies are also expressions of individuality. Playing the saxophone doesn&amp;rsquo;t map to a good habit in an obvious way. In fact, since practising is so time-consuming, it may very well prevent you from building some good habits. However, if you play the saxophone as a hobby, you&amp;rsquo;re a saxophone player. Contrast this with the hobby of scrolling Reddit; it doesn&amp;rsquo;t make you a something.&lt;/p&gt;
&lt;p&gt;Other hobbies help build career capital. Take coding, for example. The ability to write simple scripts &amp;ndash; or to debug LLM-written scripts &amp;ndash; is useful for most knowledge workers. Other examples of career-building hobbies include learning languages and doing science olympiads.&lt;/p&gt;
&lt;p&gt;But many good hobbies seem perfectly useless. Recall the definition: hobbies are activities done for leisure. Does the hobby allow you to recharge? &amp;ldquo;Productive hobbies&amp;rdquo; may not be as productive as they seem. Painting, watching Netflix and playing boardgames might be terrific hobbies from this perspective.&lt;/p&gt;
&lt;p&gt;Back to our original question: which hobbies would your mom like?&lt;/p&gt;
&lt;p&gt;To compare hobbies X and Y, you can use the above criteria, asking whether the hobby is a habby, if it&amp;rsquo;s practical and so on. But rather than making pairwise comparisons between hobbies, I prefer thinking in terms of hobby portfolios. Ideally, you&amp;rsquo;d have one sports-related hobby, one idiosyncratic hobby, one work-related hobby and one relaxing hobby. Obviously there can be overlaps between these categories. For example, playing soccer can also be relaxing, in that it takes your mind off work. There may very well be other categories of hobbies worth investing in too.&lt;/p&gt;
&lt;p&gt;Anyway, there are both personal and professional benefits of having a good hobby portfolio. While we cannot choose some of our hobbies &amp;ndash; I&amp;rsquo;ll always be a sucker for books on behavioural economics &amp;ndash; surely we should try optimising our hobby portfolios, at least a bit. After all, having a good hobby portfolio seems like a key part of living a good life.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Isaia Gisler, Stanislas Nicolau and Abhinand Shibu for a valuable discussion on this topic.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Sweden</title>
      <link>http://localhost:1313/sweden/</link>
      <pubDate>Sun, 27 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/sweden/</guid>
      <description>&lt;p&gt;Everyone who has ever lived abroad gets homesick every now and then.&lt;/p&gt;
&lt;p&gt;Swedes, I give you a postcard from a Stockholm-centric, homesick expat. Non-Swedes, here&amp;rsquo;s a highly biased tourist guide.&lt;/p&gt;
&lt;p&gt;The best thing about Sweden? My favourite Swedes, for sure. I miss family and friends a lot.&lt;/p&gt;
&lt;p&gt;Other than that, hearing Swedish jazz live. Hearing &lt;em&gt;Sakta vi gå genom stan&lt;/em&gt; and &lt;em&gt;Flykten från vardagen&lt;/em&gt; live. Or if Glenn Miller or Fasching is too pricey, you could just drop by KMH and enjoy up-and-coming jazz, all for free.&lt;/p&gt;
&lt;p&gt;Then there&amp;rsquo;s all the traditional Swedish music. It&amp;rsquo;s easier appreciating the music of Olle Adolfsson, Evert Taube and Cornelis Vreeswijk when you&amp;rsquo;re in Sweden. I tried listening to some Swedish classics while abroad, but pieces like &lt;em&gt;Siv och Gunne&lt;/em&gt; just seemed kitsch.&lt;/p&gt;
&lt;p&gt;There are also plenty of gems in student song books. Student inside jokes are the best kinds of jokes. Many pieces aren&amp;rsquo;t just witty, but also quite beautiful. Take &lt;em&gt;O Gamla Klang och Jubeltid&lt;/em&gt;, for example.&lt;/p&gt;
&lt;p&gt;In fact, only now have I come to appreciate Swedish student life. Valborg abroad was depressing. No Orphei Drängar, no champagne breakfast, no mösspåtagning. And to the best of my knowledge, you can&amp;rsquo;t attend gasques outside of the Nordic countries.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve also become a big fan of Stockholm architecture. I find many areas of Vasastan, Östermalm and Södermalm very pretty. For example, consider the areas around Engelbrektskyrkan and Mosebacke torg. While I know little about architecture, I think there aren&amp;rsquo;t as many odd clashes between different architectural styles as in, say, Zürich or Berlin.&lt;/p&gt;
&lt;p&gt;And ah, Scandinavian design! To be fair, Danish design is unparalleled. But Sweden also has a long tradition of good design. This means that your average interior design store has some really good stuff. In particular, you can get good design cheaply.&lt;/p&gt;
&lt;p&gt;Maybe Scandinavian design is inspired by the water. In Stockholm, there&amp;rsquo;s water everywhere. Most cities are built around rivers, so rivers don&amp;rsquo;t really count. Stockholm is built on a little archipelago. It creates an entirely different city space.&lt;/p&gt;
&lt;p&gt;For the best view of the water, head to Monteliusvägen and Ivar Los park. There&amp;rsquo;s nothing quite like having picknick with friends in Ivar Los park on a summer evening, before cycling home on near-empty streets (July).&lt;/p&gt;
&lt;p&gt;Speaking of which, I miss sailing in the Stockholm archipelago. As a teen, I found it boring: stuck with parents for four weeks with no internet on a few square metres. But now I see the charm in it. Even the small, unknown islands might as well have been taken from a Zorn or Strindberg painting.&lt;/p&gt;
&lt;p&gt;Finally, Swedish. Apart from friends and family, the aspect of Swedish life I miss the most is the language. I miss speaking Swedish.&lt;/p&gt;
&lt;p&gt;There are so many lovely Swedish words that have no English analogue, besides the much-cited example of &amp;ldquo;lagom&amp;rdquo;. Consider &amp;ldquo;killgissa&amp;rdquo;. This literally means &amp;ldquo;guy-guessing&amp;rdquo;. Someone is guy-guessing when they sound knowledgeable but are really just bullshitting. Another gem: &amp;ldquo;käpphäst&amp;rdquo;, meaning &amp;ldquo;hobby horse&amp;rdquo;. In a figurative sense, a hobby horse is an idea you keep on bringing up in social situations. Another useful expression: &amp;ldquo;Nu är det dags att sätta punkt.&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Finding research influences</title>
      <link>http://localhost:1313/finding-research-influences/</link>
      <pubDate>Sun, 20 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/finding-research-influences/</guid>
      <description>&lt;p&gt;There isn&amp;rsquo;t any expert consensus on many &lt;a href=&#34;https://isabeldahlgren.github.io/the-spectrum-of-views-on-ai-safety/&#34;&gt;key questions related to AI safety&lt;/a&gt;. For example, estimates of when we&amp;rsquo;ll have transformative AI range from a few years to a century. There are also many wild opinions in the AI safety space. While some of these wild opinions seem justifiable, many people seem to exaggerate the risks from AI in an attempt to move policy-makers.&lt;/p&gt;
&lt;p&gt;I think there are a few researchers which seem to have an unusual degree of conceptual clarity, though. A few names that come to mind are &lt;a href=&#34;https://substack.com/@redwoodresearch?utm_source=about-page&#34;&gt;Buck Shleregis&lt;/a&gt;, &lt;a href=&#34;https://www.cold-takes.com/cold-takes-on-ai/&#34;&gt;Holden Karnofsky&lt;/a&gt; and &lt;a href=&#34;https://www.lesswrong.com/users/jan_kulveit?from=search_autocomplete&#34;&gt;Jan Kulveit&lt;/a&gt;. While I don&amp;rsquo;t endorse all their views, they seem to raise good questions. For lack of a better word, you could call them my research influences.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve never been on looking for new research influences. Every now and then, I just realise that I&amp;rsquo;ve been influenced by someone, perhaps after citing the work of someone for the third time in a conversation. But say you want to look for research influences more deliberately. How might you proceed?&lt;/p&gt;
&lt;h3 id=&#34;knowing-where-to-look&#34;&gt;Knowing where to look&lt;/h3&gt;
&lt;p&gt;A reasonable first step is exploring new content.&lt;/p&gt;
&lt;p&gt;A reasonable first substep, then, is to narrow down the search space. Identify the kinds of questions you care about. For example, I&amp;rsquo;m mostly interested in reading about AI control and LLM psychology right now, so I&amp;rsquo;ll ignore papers and blog posts on, say, singular learning theory.&lt;/p&gt;
&lt;p&gt;Next, ask people you find sensible for reading recommendations. Better yet, ask if they have any research influences. This is one of those things which is infinitely easier doing in person. Sending cold emails to researchers usually works, but it&amp;rsquo;s relatively time-consuming. It&amp;rsquo;s much easier bringing up the topic over a coffee with people in your local community.&lt;/p&gt;
&lt;p&gt;Asking &amp;ldquo;Which blog posts have had the largest influence on your research?&amp;rdquo; also proved a good way of rounding up conversations at EAG. This way, I got to know the other person better and exploring new content at once.&lt;/p&gt;
&lt;h3 id=&#34;having-a-nose-for-bullshit&#34;&gt;Having a nose for bullshit&lt;/h3&gt;
&lt;p&gt;Once you&amp;rsquo;ve decided what to read, you want to scrutinise the argument of the text. This is a highly non-trivial task. I&amp;rsquo;m not going to try solving all of philosophy here, so I&amp;rsquo;ll just focus on heuristics for detecting bullshit in the context of AI safety.&lt;/p&gt;
&lt;p&gt;First, beware any kind of extreme. Is the proposed idea radical? Radical ideas shouldn&amp;rsquo;t be dismissed offhand. However, the burden of proof is greater. Similarly, quickly screen the author&amp;rsquo;s background: is the author known to have radical opinions, or affiliated with an organisation pursuing an unusual agenda?&lt;/p&gt;
&lt;p&gt;I find it especially troubling when authors promote radical opinions and are unwilling to engage in debate with the general public. This leads to echo chambers. Moreover, refusing to explain your ideas to laymen just seems uncool. Just as lecturers should take questions from students seriously, authors should take questions from the non-initiated seriously. It&amp;rsquo;s an act of charity.&lt;/p&gt;
&lt;p&gt;Another helpful strategy is to listen to interviews with the author. It&amp;rsquo;s harder lying in speech than in writing&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Of course, not everyone is as persuasive orally. But if there&amp;rsquo;s a big discrepancy between your confidence in the author&amp;rsquo;s argument as presented in the text and during an interview, that&amp;rsquo;s a warning sign. Moreover, a good interviewer will also help expose the flaws in the interviewee&amp;rsquo;s reasoning. In an essay, the author has full control.&lt;/p&gt;
&lt;h3 id=&#34;observing-the-influence&#34;&gt;Observing the influence&lt;/h3&gt;
&lt;p&gt;Suppose you come across an author whose work makes sense but leaves you feeling &amp;ldquo;Sure, so what?&amp;rdquo;. I wouldn&amp;rsquo;t speak of a research influence here. A research influence changes the way you think. It&amp;rsquo;s not enough just stating true facts; their work needs to have some oomph.&lt;/p&gt;
&lt;p&gt;When can we speak of a research influence, then?&lt;/p&gt;
&lt;p&gt;One reliable proxy is &lt;a href=&#34;https://www.paulgraham.com/top.html&#34;&gt;the top idea of your mind&lt;/a&gt;. Do you have shower thoughts about their work? Also, do you find yourself coming back to their work after several months? In particular, when revisiting their points, do they still make as much sense? Big ideas need to be slept on, and you can only sleep so many times in a given week. Lastly, notice if you reference their ideas when chatting with others and, if so, in what way.&lt;/p&gt;
&lt;p&gt;So finding research influences takes time, even if you take some of the shortcuts listed above. The process of finding research influences very much resembles the process of doing research. In fact, perhaps the two are indistinguishable.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Miles Kodama for valuable discussions on this topic.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;A fact well known among those who have taken oral exams.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On the perks of adulthood</title>
      <link>http://localhost:1313/on-the-perks-of-adulthood/</link>
      <pubDate>Sun, 13 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-the-perks-of-adulthood/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;I know you dread becoming an adult. Most adults seem to have such boring lives. Not that you&amp;rsquo;re having fun all the time either. High school biology isn&amp;rsquo;t that exciting. But at least your life outside of school is filled with novelty. That&amp;rsquo;s something. There&amp;rsquo;s something special about all those first times.&lt;/p&gt;
&lt;p&gt;If you&amp;rsquo;re just seeking novelty, you&amp;rsquo;ll be disappointed. Maybe that&amp;rsquo;s the real reason you dread adulthood. While I don&amp;rsquo;t feel like an adult just yet, many of my friends have become Real Adults, being in stable relationships, getting high-paid jobs and moving abroad. So I&amp;rsquo;m beginning to understand the adult world. It&amp;rsquo;s not as bad as it seems, only very different.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;You&amp;rsquo;ll feel less lost. Few adults know with absolute certainty what they&amp;rsquo;ll be doing in twenty years time; only the boring ones do. Still, they probably have a vague idea of what kind of work they enjoy and don&amp;rsquo;t enjoy.&lt;/p&gt;
&lt;p&gt;When you feel less lost, you can start doing good work and having a positive impact on the world. There&amp;rsquo;s something deeply gratifying about pursuing a meaningful goal with a good team. I think this effect is the most visible among startup founders, who can have all-consuming jobs without burning out.&lt;/p&gt;
&lt;p&gt;Teenagers cannot sustain the same kind of commitment. They have too many constraints. Teenagers should &lt;a href=&#34;https://paulgraham.com/nerds.html&#34;&gt;be popular&lt;/a&gt;, get good grades in school, engage in extracurriculars and so on. When you&amp;rsquo;re an adult, you can decide which game to play. Teenagers are expected to play all games at once.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;Indeed, as an adult, you do you.&lt;/p&gt;
&lt;p&gt;Once you live alone, you&amp;rsquo;ll enjoy a much larger degree of freedom. You can go to bed whenever you want, you can create your own system for cleaning your room, you can listen to modern jazz without bothering anyone.&lt;/p&gt;
&lt;p&gt;Moreover, you&amp;rsquo;ll have a bigger say when it comes to life decisions: where to go for vacation, which job to take, whom to date, etc. Although your parents happen to be quite liberal, you&amp;rsquo;ll soon enjoy unprecedented liberties.&lt;/p&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;Most adults are reasonable people. Adults tend to be friendly, taking pleasure in helping out. In contrast, teenagers can be really nasty towards one another. &lt;em&gt;Mean Girls&lt;/em&gt; regularly happens in real life. But even people like Regina George do mature, believe it or not.&lt;/p&gt;
&lt;p&gt;This is why we&amp;rsquo;re told to assume good intent. Assuming good intent isn&amp;rsquo;t just a feel-good hack - the idea of being surrounded by adversarially-minded people is quite depressing - it&amp;rsquo;s also good epistemics.&lt;/p&gt;
&lt;p&gt;Corollary: ask more for help. If you have special needs at work, don&amp;rsquo;t hesitate to bring it up with your employer. You can also cold-email people asking for specific advice.&lt;/p&gt;
&lt;h3 id=&#34;v&#34;&gt;V.&lt;/h3&gt;
&lt;p&gt;By a teenager&amp;rsquo;s standards, you&amp;rsquo;ll be rich. Not objectively, of course. But you&amp;rsquo;ll no longer agonise over your coffee costing 30 SEK. When you go over all your expenses, you&amp;rsquo;ll realise that the amount you save by cutting out tiny indulgences makes no difference. Moreover, once you know you&amp;rsquo;ll find some kind of job, if only a poorly paid one, treating yourself becomes easier.&lt;/p&gt;
&lt;p&gt;While some teenagers spend too much, you&amp;rsquo;re being too harsh on yourself. Please don&amp;rsquo;t be such a &lt;a href=&#34;https://forum.effectivealtruism.org/posts/T975ydo3mx8onH3iS/ea-is-about-maximization-and-maximization-is-perilous&#34;&gt;&amp;ldquo;utilitarian&amp;rdquo;&lt;/a&gt;. For example, invest in a Lamy Safari, get Brunnen notebooks and occasionally have coffees for 30 SEK.&lt;/p&gt;
&lt;p&gt;As an adult, you know your preferences, so you can make better purchases. You&amp;rsquo;ll spend more time exploiting rather than exploring.&lt;/p&gt;
&lt;h3 id=&#34;vi&#34;&gt;VI.&lt;/h3&gt;
&lt;p&gt;I cannot tell you just how good it feels to have a normal brain - a brain that&amp;rsquo;s not flooded by hormones and equipped with a pre-frontal cortex.&lt;/p&gt;
&lt;p&gt;Fear not. Most emotions are no less intense in adult life. If you&amp;rsquo;re still distrustful, remember that most poets peak in their mid 30s (the romantics weren&amp;rsquo;t that many, after all). The highs are as high, if not higher, while the lows aren&amp;rsquo;t as low. No more strong pangs of envy, as when you&amp;rsquo;re a teen.&lt;/p&gt;
&lt;p&gt;Perhaps you can develop a better appreciation for, say, exhilaration, much as an aspiring sommelier develops a better appreciation for wine.&lt;/p&gt;
&lt;p&gt;The formation of a sommelier involves theoretical and practical components. I think the analogy of the theoretical component is reading fiction, going to the theatre or watching movies. I&amp;rsquo;m more of a reader than a theatre-goer or a movie-watcher, so I cannot really speak to the effects of watching plays or going to the cinema. But I think reading fiction helps you appreciate the complexity of feelings. A sommelier also has to have tasted a large number of wines. Similarly, if you are to become a sensational sommelier, you need to accumulate a large number of experiences.&lt;/p&gt;
&lt;h3 id=&#34;vii&#34;&gt;VII.&lt;/h3&gt;
&lt;p&gt;See, adult life maybe isn&amp;rsquo;t too bad. You probably didn&amp;rsquo;t expect any of these benefits; if you did, you wouldn&amp;rsquo;t have wanted to be forever young. Similarly, my 30s, 40s and 50s will bring their own set of surprises. My &lt;a href=&#34;https://www.theguardian.com/lifeandstyle/2023/aug/14/the-psychological-immune-system-four-ways-to-bolster-yours-and-have-a-happier-calmer-life&#34;&gt;psychological immune system&lt;/a&gt; will hopefully take care of those too.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>The spectrum of views on AI safety</title>
      <link>http://localhost:1313/the-spectrum-of-views-on-ai-safety/</link>
      <pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/the-spectrum-of-views-on-ai-safety/</guid>
      <description>&lt;p&gt;I agree the concept of &lt;a href=&#34;https://en.wikipedia.org/wiki/P(doom)&#34;&gt;P(doom)&lt;/a&gt; is problematic. First, &amp;ldquo;doom&amp;rdquo; can mean a variety of things: human extinction, existential catastrophe or gradual disempowerment. Also, P(doom) - condition on present-day regulations or AI slowdown? Furthermore, the timeframe matters, as P(doom within the next $X$ years) increases with $X$.&lt;/p&gt;
&lt;p&gt;But perhaps we&amp;rsquo;re missing the point of the P(doom) question. If someone asks you for P(doom) at a cocktail party, it usually means they&amp;rsquo;re just interested in hearing general takes on AI safety, at least in my experience.&lt;/p&gt;
&lt;p&gt;The P(doom) question isn&amp;rsquo;t entirely misguided, though. If your interlocutor specifies exactly what they mean by P(doom), say P(gradual disempowerment from power-seeking AI within the next decade|no regulations), and ask for the rough shape of your PDF, then your answer immediately becomes more informative. By asking for a small set of well-chosen estimates, you could get a fairly accurate idea of someone&amp;rsquo;s core beliefs. But again, you have to pick the right estimates.&lt;/p&gt;
&lt;p&gt;Finding these estimates is like asking for the relevant dimensions in a &amp;ldquo;political spectrum&amp;rdquo; of views on AI safety. If you were to visualise opinions within the AI safety space, what would be your axes? While such a plot would necessarily be a simplification, perhaps it could allow us to communicate our basic assumptions more effectively. This would lead to more well-informed discussions in the AI safety community.&lt;/p&gt;
&lt;p&gt;I imagine we want something between the P(doom) question and the kinds of questions used in expert surveys, like the &lt;a href=&#34;https://blog.aiimpacts.org/p/2023-ai-survey-of-2778-six-things&#34;&gt;2023 Expert Survey on Progress in AI&lt;/a&gt; or the &lt;a href=&#34;https://www.iaps.ai/research/ai-reliability-survey&#34;&gt;AI Reliability &amp;amp; Security Research Priorities&lt;/a&gt;. While the P(doom) question is too simple, the questionnaire questions are too complicated&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. We&amp;rsquo;re looking for questions that are as simple as possible, but no simpler - the kinds of questions you could answer at a cocktail party.&lt;/p&gt;
&lt;p&gt;Here are the five questions I wish people would have asked me, rather than asking for my P(doom). For some obvious variations, see the footnotes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AI timelines&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;: In what year will we have &lt;a href=&#34;https://www.openphilanthropy.org/research/some-background-on-our-views-regarding-advanced-artificial-intelligence/#id-1-defining-transformative-artificial-intelligence-transformative-ai&#34;&gt;transformative AI&lt;/a&gt;, i.e. AI that precipitates a transition comparable to (or more significant than) the agricultural or industrial revolution&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;?&lt;/li&gt;
&lt;li&gt;A more informative P(doom)&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;: Assuming no further regulations on the development of AI systems, what is the probability of &lt;a href=&#34;https://gradual-disempowerment.ai/&#34;&gt;gradual disempowerment&lt;/a&gt; from AI systems before 2050?&lt;/li&gt;
&lt;li&gt;Threat model: Do the main risks from transformative AI come from bad actors developing &lt;a href=&#34;https://www.forethought.org/research/preparing-for-the-intelligence-explosion#highly-destructive-technologies&#34;&gt;destructive technologies&lt;/a&gt; and creating &lt;a href=&#34;https://www.forethought.org/research/preparing-for-the-intelligence-explosion#power-concentrating-mechanisms&#34;&gt;power-concentrating mechanisms&lt;/a&gt; or from AI systems seeking to eliminate humanity?&lt;/li&gt;
&lt;li&gt;Views on AI slowdown&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;: How heavily should the government regulate the development of future AI systems?&lt;/li&gt;
&lt;li&gt;Views on centralisation&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;: Should all leading AI companies be required to open-source their models, to ensure equal access to our most powerful AI systems?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These questions translate naturally into scales from $-1$ to $1$. I also tried listing the questions in rough order of importance, so I&amp;rsquo;d use the three first questions for the axes of a 3D-plot.&lt;/p&gt;
&lt;p&gt;Going through these questions and plotting your position relative to that of others can be amusing. However, it&amp;rsquo;s also an instructive exercise. After all, these are important questions. Finally, I&amp;rsquo;ve also found it pretty handy having default answers to these extremely difficult questions at cocktail parties.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Agatha Duzan for feedback on this text.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;For example, &amp;ldquo;Rate the extent to which you agree that resolving the core challenges of this sub-area and implementing the resulting solutions would significantly reduce the risk of severe harm (loss of &amp;gt;100 lives or &amp;gt;$10 billion in economic impact from AI&amp;rdquo;, where a sub-area might be &amp;ldquo;Ethics-aware training and fine-tuning: Research on learning from imperfect ethical datasets, applying ethics-aware data curation methods, and incorporating collective ethical principles into model design.&amp;rdquo; Quite a mouthful.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Variations: In what year will AI be capable to automate 99% of fully remote jobs? In what year will we have artificial general intelligence (AGI) - an AI which can match or exceed the cognitive abilities of human beings across any task?&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;For an interesting discussion on this topic, see &lt;a href=&#34;https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/ai-timelines&#34;&gt;this moderated discussion&lt;/a&gt; between Ajeya Cotra, Daniel Kokotaljo and Ege Erdil.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;Variations: Just modify the conditions, the definition of &amp;ldquo;doom&amp;rdquo; or the timeframe. Alternatively, what is the probability of AI having a net positive effect on the world in within the next 20 years?&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Variations: What might be the minimum sufficient intervention to prevent gradual disempowerment from AIs?&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;Variations: Should leading AI labs be placed under state ownership?&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On my relation to effective altruism</title>
      <link>http://localhost:1313/on-my-relation-to-effective-altruism/</link>
      <pubDate>Sun, 29 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-my-relation-to-effective-altruism/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve spent more time engaging with the effective altruist (EA) community this year. Not just reading EA books and blog posts, but participating in seminars, attending conferences and going on EA retreats. For context, I&amp;rsquo;d viewed myself &amp;ldquo;EA adjacent&amp;rdquo; ever since I came across &lt;em&gt;The Life You Can Save&lt;/em&gt; back in high school. However, during my master degree, the prospect of graduating soon - of becoming an adult - made me reflect more carefully on EA.&lt;/p&gt;
&lt;p&gt;First, our definitions, taken from the &lt;a href=&#34;https://www.effectivealtruism.org/articles/introduction-to-effective-altruism&#34;&gt;introduction to effective altruism&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Effective altruism is a project that aims to find the best ways to help others, and put them into practice.&lt;/p&gt;
&lt;p&gt;It’s both a &lt;strong&gt;research field&lt;/strong&gt;, which aims to identify the world’s most pressing problems and the best solutions to them, and a &lt;strong&gt;practical community&lt;/strong&gt; that aims to use those findings to do good.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;When I refer to the EA community, I mean the practical community. I&amp;rsquo;ll also use the abbreviation &amp;ldquo;EA&amp;rdquo; to refer to effective altruists.&lt;/p&gt;
&lt;p&gt;Many people who have engaged with the EA community at some level or other often find themselves questioning their relationship with EA. In fact, there are plenty of blog posts on the theme &amp;ldquo;EA identity crisis&amp;rdquo;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Here&amp;rsquo;s my contribution to the genre.&lt;/p&gt;
&lt;p&gt;So, do I consider myself part of the EA community?&lt;/p&gt;
&lt;h3 id=&#34;yes&#34;&gt;Yes&lt;/h3&gt;
&lt;p&gt;Technically, yes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I think the &lt;a href=&#34;https://www.effectivealtruism.org/articles/introduction-to-effective-altruism#what-principles-unite-effective-altruism&#34;&gt;core ideas of EA&lt;/a&gt; - prioritisation, impartiality, open truthseeking and collaboration - make sense. The article does an excellent job at explaining these terms, so I&amp;rsquo;ll refer to their explanations&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. I&amp;rsquo;ve desperately tried red-teaming EA - I&amp;rsquo;d love for the &lt;a href=&#34;https://en.wikipedia.org/wiki/Famine,_Affluence,_and_Morality&#34;&gt;drowning child argument&lt;/a&gt; to be less convincing - but I still think the core ideas hold up.&lt;/li&gt;
&lt;li&gt;I care about finding the best ways to help others, and putting them into practise. While I don&amp;rsquo;t want to impose any moral standards on others, I feel a certain moral obligation to do good&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. I also find it fulfilling working on high-impact projects. It almost seems tautological that one should try having a large positive impact on the world.&lt;/li&gt;
&lt;li&gt;I&amp;rsquo;ve attended several EA community events. All of these events have been tremendously valuable, both on a professional and a personal level.&lt;/li&gt;
&lt;li&gt;My interest in EA doesn&amp;rsquo;t seem to be &amp;ldquo;just a phase&amp;rdquo;. At this point, I&amp;rsquo;ve spent about five years reading and learning more about EA.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Maybe also non-technically? Here are some gut-feeling-level arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I enjoy exchanging ideas on EA-related topics with people in the EA community - it&amp;rsquo;s almost like a hobby of mine. But I also think there&amp;rsquo;s significant value in doing collaborative sensemaking on topics like existential risk, AGI timelines and longtermism.&lt;/li&gt;
&lt;li&gt;In general, I find many people in the EA community to be very thoughtful. Some pieces by Holden Karnofsky, Ajeya Cotra and Benjamin Todd have had a profound influence on my worldview. Similarly, some of my favourite non-fiction books are about EA. For example, I thought &lt;em&gt;Doing Good Better&lt;/em&gt; and &lt;em&gt;What We Owe The Future&lt;/em&gt; were exceptional reads.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;no&#34;&gt;No&lt;/h3&gt;
&lt;p&gt;But of course, it&amp;rsquo;s complicated&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;I mainly care about existential risk reduction, although this may very well change in the future. I&amp;rsquo;ve also devoted much more time and effort to AI safety than any other cause area&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. It&amp;rsquo;d be more accurate saying I&amp;rsquo;m into AI safety and existential risk reduction rather than EA, which is a much broader term.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;I don&amp;rsquo;t seem to fit the public perception of an EA. In my experience, many people think all EAs work on farm animal welfare or global poverty reduction. Sure, I&amp;rsquo;m vegetarian (Peter Singer&amp;rsquo;s fault), but I still haven&amp;rsquo;t donated to GiveWell, nor signed the 10% pledge. This point is mostly about me not living up to my moral standards, though.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In general, I try avoid identity markers related to social movements. While I think neutrality is somewhat of an illusion, I want to hold my opinions lightly. My worry is that self-identifying as an EA might make me less open-minded. But perhaps this worry is somewhat ungrounded, at least when it comes to EA. People in the EA community tend to be very open to criticism&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The EA community has its flaws, despite making a number of changes after FTX. Many of the concerns raised in &lt;a href=&#34;https://forum.effectivealtruism.org/posts/54vAiSFkYszTWWWv4/doing-ea-better-1&#34;&gt;this article&lt;/a&gt; are still valid. This excerpt summarises one of my main concerns well:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The EA community is notoriously homogeneous, and the “average EA” is extremely easy to imagine: he is a white male in his twenties or thirties from an upper-middle class family in North America or Western Europe. He is ethically utilitarian and politically centrist; an atheist, but culturally protestant. He studied analytic philosophy, mathematics, computer science, or economics at an elite university in the US or UK. He is neurodivergent. He thinks space is really cool. He highly values intelligence, and believes that his own is significantly above average. He hung around LessWrong for a while as a teenager, and now wears EA-branded shirts and hoodies, drinks Huel, and consumes a narrow range of blogs, podcasts, and vegan ready-meals.&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;resolution&#34;&gt;Resolution&lt;/h3&gt;
&lt;p&gt;While I do have some reservations, my views are pretty consistent with the EA agenda. Also, I&amp;rsquo;ll (reluctantly) admit that overthinking the question of whether you&amp;rsquo;re part of a given community is very EA.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://forum.effectivealtruism.org/posts/89GdH5unSb2Sze6kj/elements-of-ea-your-ea-identity-can-be-bespoke&#34;&gt;This post&lt;/a&gt; on EA identities is a good starting point. There&amp;rsquo;s also &lt;a href=&#34;https://www.neelnanda.io/blog/8-altruism&#34;&gt;Neel Nanda&amp;rsquo;s favourite blog post&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;I endorse a much broader form of the impartiality principle than the one outlined in the article. I also think strangers, animals and future people should be part of our &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Expanding_Circle&#34;&gt;circle of moral consideration&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;I assume this is because my mother, coming from the Philippines, always told me to be grateful. I&amp;rsquo;m glad she did, but I used to find it annoying as a child.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;For a list of cause areas, see the 80,000 hours list of &lt;a href=&#34;https://80000hours.org/problem-profiles/&#34;&gt;the world&amp;rsquo;s most pressing problems&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;See the posts in the &lt;a href=&#34;https://forum.effectivealtruism.org/topics/criticism-of-effective-altruism&#34;&gt;Criticism of effective altruism thread&lt;/a&gt;. I very much liked &lt;a href=&#34;https://www.benkuhn.net/ea-critique/&#34;&gt;Ben Kuhn&amp;rsquo;s critique of EA&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On question taste</title>
      <link>http://localhost:1313/on-question-taste/</link>
      <pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-question-taste/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;Children like asking questions. Some of their questions are very hard: &amp;ldquo;Why do people die?&amp;rdquo;. Others questions expose our biases: &amp;ldquo;Couldn&amp;rsquo;t we invite the homeless man to dinner?&amp;rdquo; Then there are all the annoying questions: &amp;ldquo;When will we arrive?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;In my experience, school didn&amp;rsquo;t teach us to ask questions - we were just taught how to answer them. To pass the test, you only had to memorise the material in the textbook.&lt;/p&gt;
&lt;p&gt;Perhaps this isn&amp;rsquo;t too surprising. It&amp;rsquo;s hard objectively measuring someone&amp;rsquo;s ability to ask questions. But above all, educational institutions serve many different purposes, apart from spreading knowledge&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Schools should also produce good citizens. A society full of radical skeptics wouldn&amp;rsquo;t function properly (hence the execution of Socrates). So children might hear that some questions are meaningless or irrelevant, even in school.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;On two different occasions, I&amp;rsquo;ve heard two distinguished professors at ETH mention that students ask too few questions. They weren&amp;rsquo;t referring to the specific questions about the lecture, but to something like &lt;a href=&#34;https://www.lesswrong.com/posts/Thwfy4gNFx9kHgvov/research-hamming-questions&#34;&gt;Research Hamming questions&lt;/a&gt;. For example, one could ask about improvements of a particular result or whether a proof technique generalises.&lt;/p&gt;
&lt;p&gt;They make a good point. The ability to ask interesting, open-ended questions seems like a key research skill; call it question taste. Intuitively, a person with question taste is like a child with expert domain knowledge.&lt;/p&gt;
&lt;p&gt;Certain groups of people are known for their question taste. For example, consider journalists. They have undergone extensive training in asking questions as part of their university degree. Moreover, they constantly practise the skill of asking questions at work. No wonder they get pretty good at it. Similarly, researchers, psychologists, essayists and investors tend to have good question taste, as questioning is part of their job.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;I assume, perhaps somewhat naïvely, that acquiring question taste is mostly about deliberate practice. The implementational details will depend on the domain you&amp;rsquo;re working in, though.&lt;/p&gt;
&lt;p&gt;A basic strategy might be to identify the people in your area who seem to be asking the right questions and try copying what they do. For example, I&amp;rsquo;d like to formulate good questions about research agendas in AI safety someday, so I&amp;rsquo;ll often make note of questions raised by leading researchers in podcasts, blog posts or papers. Sometimes I write down own questions and discuss them with others for feedback, although this is more time-consuming.&lt;/p&gt;
&lt;p&gt;Having a safe environment in which to practise asking questions - a training ground - also seems important. If you&amp;rsquo;re a student, you can attend student-run seminars, where you might feel more comfortable asking questions. Regardless of the kind of questions you aim to ask, you need to find a community to give you feedback. And hopefully, you get some answers too.&lt;/p&gt;
&lt;p&gt;As you practise asking questions, you&amp;rsquo;ll inevitably ask some &amp;ldquo;bad questions&amp;rdquo;. Part of the reason why children are so inquisitive is their lack of self-consciousness. They don&amp;rsquo;t care if their questions make them sound stupid. So, in order to ask good questions, make a conscious effort, find a supportive community and maybe don&amp;rsquo;t take yourself too seriously.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;This is argued in Bryan Caplan&amp;rsquo;s book &lt;a href=&#34;https://en.wikipedia.org/wiki/The_Case_Against_Education&#34;&gt;The Case Against Education&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>A taxonomy of examples</title>
      <link>http://localhost:1313/a-taxonomy-of-examples/</link>
      <pubDate>Sun, 15 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/a-taxonomy-of-examples/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m mildly obsessed with examples. Whenever I feel confused, it&amp;rsquo;s often because I don&amp;rsquo;t know enough examples. Proofs can be confusing too, if some step is poorly explained. But that kind of confusion tends to be local. You can still have a good grasp of the theory. If you don&amp;rsquo;t know enough examples, you feel generally lost. Textbooks lacking in examples end up being dry. In contrast, books with well-chosen examples are a pleasure to read&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;According to the Cambridge Dictionary, an example is &amp;ldquo;something that is typical of the group of things that it is a member of&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;In mathematics, there are many kinds of examples, and they all serve different purposes. Traditionally, fields like topology and measure theory place a greater emphasis on counter examples. In algebra, there are more prototypical examples; definitions are often followed by an exhaustive list of objects of that category&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. In the context of mathematics, the dictionary definition is too simplistic! So here is an attempt at classifying the main kinds of examples, or, alternatively, an examples appreciation post.&lt;/p&gt;
&lt;h3 id=&#34;understanding-definitions&#34;&gt;Understanding definitions&lt;/h3&gt;
&lt;p&gt;First, there are the examples helping us understand definitions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prototypical examples: examples just complex enough to capture the essential properties of an object.
&lt;ul&gt;
&lt;li&gt;Fundamental groups: the fundamental group of the circle $\pi_1(\mathbb{S}^1, x_0)$.&lt;/li&gt;
&lt;li&gt;Transcendental field extensions: $\mathbb{Q}(\pi)$.&lt;/li&gt;
&lt;li&gt;Modular forms: the Poincaré series $P_{m, k}(z)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Canonical examples: the canonical construction of something - the construction you get which involves the least arbitrariness.
&lt;ul&gt;
&lt;li&gt;Stochastic processes: the coordinate process.&lt;/li&gt;
&lt;li&gt;Embeddings into bi-duals: take the embedding $V \to V^{**}$ sending $v$ to the evaluation.&lt;/li&gt;
&lt;li&gt;Rings: the integers $\mathbb{Z}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Foundational examples: examples of special interest and which form the basis for further theory.
&lt;ul&gt;
&lt;li&gt;Anything analysis: the Gaussian $\phi(x) = e^{-x^2/2}$.&lt;/li&gt;
&lt;li&gt;Stochastic processes: the simple random walk on $\mathbb{Z}$.&lt;/li&gt;
&lt;li&gt;Modular forms: the $j$–invariant.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Basic examples: the simplest possible instance of an object. The kind of example an uncreative student might cite in an exam&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.
&lt;ul&gt;
&lt;li&gt;Groups: the trivial group $G := {e}$.&lt;/li&gt;
&lt;li&gt;Martingales: the martingale $(X_t)_{t \ge 0}$ where $X_t \equiv 1$ for all $t$.&lt;/li&gt;
&lt;li&gt;Banach space: just take $\mathbb{R}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-examples: objects which are not instances of something.
&lt;ul&gt;
&lt;li&gt;A non-ring: the natural numbers $\mathbb{N}$.&lt;/li&gt;
&lt;li&gt;A non-tempered distribution: the function $e^t$.&lt;/li&gt;
&lt;li&gt;A non-Artinian ring: the integers $\mathbb{Z}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Computational examples: examples involving a computation and that illustrate how to work with a given object.
&lt;ul&gt;
&lt;li&gt;Compute $\mathbb{R}[x] \otimes \mathbb{C}$.&lt;/li&gt;
&lt;li&gt;Find the Euler product expansion for the Dirichlet generating series of the Möbius function $\mu = 1^{-*}$&lt;/li&gt;
&lt;li&gt;Check that $c^{-1/2} W_{ct}$ is again Brownian motion.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pathological examples: examples illustrating distinctions between different notions, or the limitations of a certain concept.
&lt;ul&gt;
&lt;li&gt;Differentiability $\neq$ continuity: consider the Weierstrass function.&lt;/li&gt;
&lt;li&gt;Connectedness $\neq$ path connectedness: because the Topologist&amp;rsquo;s sine curve.&lt;/li&gt;
&lt;li&gt;Lebesgue integral $\neq$ Riemann integral: try integrating the Dirichlet function, the characteristic function of the rationals.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Toy examples: examples you can manipulate to have some desired properties. When looking for counter examples, you typically start with some toy example.
&lt;ul&gt;
&lt;li&gt;Random variable: define $$X := \begin{cases}\alpha, &amp;amp; \text{with probability } p, \\ \beta, &amp;amp; \text{with probability } 1 - p.\end{cases}$$&lt;/li&gt;
&lt;li&gt;Measure theory: simple functions.&lt;/li&gt;
&lt;li&gt;Galois groups: consider $\mathrm{Gal}(\mathbb{Q}(\sqrt{\alpha}):\mathbb{Q})$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Real-world examples: a real-world scenario involving the object of interest. These help motivate the study of the given object and are useful for gaining intuition.
&lt;ul&gt;
&lt;li&gt;Stochastic processes: a Poisson process as a description of the number of raindrops falling in a given square.&lt;/li&gt;
&lt;li&gt;PDE: the heat equation.&lt;/li&gt;
&lt;li&gt;Graph theory: a network models the flow of some fluid.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;understanding-results&#34;&gt;Understanding results&lt;/h3&gt;
&lt;p&gt;Second, there are the examples helping us understand results. I&amp;rsquo;ll count applications of theorems among these kinds of examples.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Counter examples: examples illustrating how a given result breaks down if we drop assumptions&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.
&lt;ul&gt;
&lt;li&gt;Fatou&amp;rsquo;s lemma: we really do need non-negativity. Consider the sequence $f_n := - 1_{[n, n+1]}$.&lt;/li&gt;
&lt;li&gt;Open mapping theorem: surjectivity is necessary, since the zero map isn&amp;rsquo;t open.&lt;/li&gt;
&lt;li&gt;Nullstellensatz: the field $K$ must be algebraically closed. For $K = \mathbb{R}$, the ideal $I = (x^2 + 1)$ is maximal but not of the form $(x - a)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Basic applications: checking that the conditions of a theorem are satisfied, apply the theorem and see what you get. These examples are particularly useful if the theorem statement seems involved.
&lt;ul&gt;
&lt;li&gt;Hurewicz&amp;rsquo; theorem: use it to find $H_1(\mathbb{S}^n)$.&lt;/li&gt;
&lt;li&gt;Dedekind-Kummer: compute the factorisation of $(p)$ in a ring of integers.&lt;/li&gt;
&lt;li&gt;Dirichlet&amp;rsquo;s unit theorem: the theorem allows us to verify that $\mathbb{Q}(\sqrt{d})$ has finite unit group.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-basic applications: or corollaries. Deduce something interesting from a theorem.
&lt;ul&gt;
&lt;li&gt;Optional stopping: allows you to compute laws of hitting times.&lt;/li&gt;
&lt;li&gt;The ring of integers is Dedekind: this gives us a satisfying proof of Fermat&amp;rsquo;s theorem for primes that are sums of squares.&lt;/li&gt;
&lt;li&gt;Hausdorff-Young: an application of Riesz-Thorin tells us that the Fourier transform defines a bounded linear operator from $L^p$.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Amusing applications: examples mentioned during lectures for amusement.
&lt;ul&gt;
&lt;li&gt;Borsuk-Ulam: there are two antipodal points on earth with the same temperature.&lt;/li&gt;
&lt;li&gt;Mean-value theorem: you can catch someone over-speeding using the mean-value theorem.&lt;/li&gt;
&lt;li&gt;Four colour theorem: you can colour a map using just four colours so no two adjacent countries have the same colour.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Satisfying applications: prove a well-known theorem as an application of the fancy theory you developed.
&lt;ul&gt;
&lt;li&gt;The insolvability of the quintic: &amp;ldquo;just&amp;rdquo; an example application of Galois theory.&lt;/li&gt;
&lt;li&gt;The central limit theorem: falls out of the computation of the characteristic function of the scaled sum.&lt;/li&gt;
&lt;li&gt;The fundamental theorem of algebra: an application of Liouville&amp;rsquo;s theorem.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Are examples the core of mathematics? The answer is very much a matter of personal taste. I&amp;rsquo;d say yes. Apparently von Neumann once said&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;In mathematics you don&amp;rsquo;t understand things. You just get used to them.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There&amp;rsquo;s some truth to this. And the way we get used to things is by studying examples.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Alois Schaffler for suggesting the last kind of example.&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;em&gt;Basic Category Theory&lt;/em&gt; or &lt;a href=&#34;https://venhance.github.io/napkin/Napkin.pdf&#34;&gt;The Napkin&lt;/a&gt; are amazing in this regard.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;In &lt;em&gt;Abstract Algebra&lt;/em&gt; by Dummit and Foote, some definitions are followed by more than ten (!) examples.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;I once cited $\mathbb{Q}$ as an example of a non-Banach space in an exam. The graders probably weren&amp;rsquo;t particularly happy with my response, but I received full points.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;In my experience, memorising counter examples is the best way to memorise assumptions of a theorem. This is somewhat counter intuitive, given that this involves memorising more information.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On the joy of customising</title>
      <link>http://localhost:1313/on-the-joy-of-customising/</link>
      <pubDate>Sun, 08 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-the-joy-of-customising/</guid>
      <description>&lt;p&gt;Why do so many people use Safari, the jarring black VSCode colour theme and Overleaf? Because it&amp;rsquo;s the default option.&lt;/p&gt;
&lt;p&gt;Switching to a non-default option requires conscious effort. First, you need to realise that your current setup is suboptimal: the probability of your current setup being the optimal one is infinitesimal. But if you knew about the benefits of making a few small changes, you&amp;rsquo;d already have made them. So you do need to believe that switching is worthwhile, which, indeed, is a leap of faith.&lt;/p&gt;
&lt;p&gt;The pros are all believers. Most software engineers customise their code editors and terminal shells heavily. If you spend all your working hours working on a computer, spending one Sunday improving your working environment is well worth it. Similarly, I know some professors at ETH are particular about their writing tools, only using fountain pens and high-end chalk.&lt;/p&gt;
&lt;p&gt;But if you&amp;rsquo;re neither a software engineer nor an ETH professor, tinkering with command-line interface (CLI) tools and splurging money on fountain pens might feel indulgent. This makes up another psychological barrier towards switching from the default. In fact, you might question whether you&amp;rsquo;re even entitled to use the tools of the pros. And to some extent, this sentiment is valid.&lt;/p&gt;
&lt;p&gt;However, I still think most people err on the side of customising too little, especially when it comes to tech. Most of us are heavy tech users; the average screen time globally seems to be over 6h. When I say someone has a good tech setup, I mean that they use appropriate software for their computer-related tasks efficiently. It is much like having a good office with a comfortable chair and a proper desk. However, it need not require expensive purchases.&lt;/p&gt;
&lt;p&gt;Adding a few selected tools to your setup can massively improve productivity. There are some general programs useful to any computer user, like Google Drive, Google Calendar and Raycast. I also think having a dedicated note-taking system, whether it be in Obsidian, Notion or Apple Notes, pays off. However, you&amp;rsquo;ll get the most leverage from finding the tools relevant to the tasks you&amp;rsquo;re doing and mastering them.&lt;/p&gt;
&lt;p&gt;For example, I mostly use my MacBook for typesetting, writing and coding. For typesetting, I use NeoVim with custom snippets, inspired by Gilles Castel&amp;rsquo;s iconic &lt;a href=&#34;https://castel.dev/post/lecture-notes-1/&#34;&gt;VimTeX setup&lt;/a&gt;. Nowadays, I also use Typst rather than LaTeX. Although I don&amp;rsquo;t necessarily type faster in Typst, I spend much less time debugging cryptic error messages. All in all, I estimate that these changes have doubled my writing speed. There are also ergonomic benefits to this setup, as opposed to just writing in Overleaf. As for coding, I&amp;rsquo;ve found Cursor to be a complete game changer, allowing me to implement experiments in about a tenth of the time. Other than that, I&amp;rsquo;m &amp;ldquo;just&amp;rdquo; using NeoVim keybindings in VSCode and a few CLI tools allowing me to navigate between folders more easily. As can be seen from &lt;a href=&#34;https://www.alignmentforum.org/posts/dZFpEdKyb9Bf4xYn7/tips-for-empirical-alignment-research&#34;&gt;this post&lt;/a&gt;, I have a lot to learn here.&lt;/p&gt;
&lt;p&gt;Furthermore, customising your computer makes for a much better user experience. I value good design, so having my preferred colour scheme in Obsidian, VSCode and WezTerm makes my computer a joy to use. I also use the Zen Browser for a cleaner user interface.&lt;/p&gt;
&lt;p&gt;Regardless of whether you&amp;rsquo;re a software aesthete or not, it&amp;rsquo;s worth exploring tech tools relevant to your work.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Consume less AI safety news</title>
      <link>http://localhost:1313/consume-less-ai-safety-news/</link>
      <pubDate>Sun, 01 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/consume-less-ai-safety-news/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s hard staying on top of all the AI safety news. Some people, like &lt;a href=&#34;https://thezvi.wordpress.com/about/&#34;&gt;Zvi&lt;/a&gt;, have basically made this their full-time job.&lt;/p&gt;
&lt;p&gt;A common failure mode for forming views on AI safety is consuming too much information. It&amp;rsquo;s a tendency I&amp;rsquo;ve observed in myself, as well as in others in the AI safety community.&lt;/p&gt;
&lt;p&gt;I think it comes from the urge to solve the AI alignment problem quickly. It&amp;rsquo;s also an exciting time to be working in AI safety, with many rapid advancements being made. Also, since AI safety is something AI, there&amp;rsquo;s a lot of general excitement surrounding the area.&lt;/p&gt;
&lt;p&gt;So we might imagine someone who starts following all the leading researchers on Twitter, listening to &lt;em&gt;The Cognitive Revolution&lt;/em&gt; while commuting and reading LessWrong posts before going to bed. Or maybe they&amp;rsquo;ll have lengthy discussions about AI governance in WhatsApp groups and watch Robert Miles&amp;rsquo; YouTube videos over meals.&lt;/p&gt;
&lt;p&gt;But if you&amp;rsquo;re looking to gain a deeper understanding of the AI safety landscape, this isn&amp;rsquo;t enough. You&amp;rsquo;d have to engage more with the material, shifting your creation-to-consumption ratio towards more creation. And you&amp;rsquo;d have to discuss your views with people in real life and, if possible, engage in a local community&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. A common piece of advice for people aiming to become experts is to focus on &lt;a href=&#34;https://forum.effectivealtruism.org/posts/ckj6Moau9qpYArHWc/want-to-be-an-expert-build-deep-models&#34;&gt;building deep models&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Even if your goal is just to get the big picture, the above approach seems needlessly high effort. There are many excellent resources summarising the main ideas in AI safety, such as the the 80,000 hours &lt;a href=&#34;https://80000hours.org/problem-profiles/risks-from-power-seeking-ai/&#34;&gt;problem profile&lt;/a&gt;. It&amp;rsquo;s a 60 min read with a very high signal-to-noise ratio.&lt;/p&gt;
&lt;p&gt;Either way, binging AI safety-related material to won&amp;rsquo;t help fix the AI alignment problem. It&amp;rsquo;s stressful, and perhaps self-defeating. Given that the AI safety landscape is changing so rapidly, much of what we&amp;rsquo;re seeing is noise. To gain conceptual clarity, perhaps you&amp;rsquo;ll benefit from consuming less AI-safety related news. Unless you&amp;rsquo;re working full-time on AI safety, either as a policy-maker or a researcher, this probably won&amp;rsquo;t negatively influence your ability to do good work.&lt;/p&gt;
&lt;p&gt;Hard problem require careful reflection. Although AI advances fast, we must think slowly about how to ensure things go well.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;My friend &lt;a href=&#34;https://mkodama.org/&#34;&gt;Miles Kodama&lt;/a&gt; put it well: &amp;ldquo;It is easy to BS to a screen&amp;rdquo;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Understanding the AI alignment problem</title>
      <link>http://localhost:1313/understanding-the-ai-alignment-problem/</link>
      <pubDate>Sun, 25 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/understanding-the-ai-alignment-problem/</guid>
      <description>&lt;p&gt;Broadly speaking, the AI alignment problem refers to the problem of ensuring AI systems do what we want them to do. I like the definition used by Anthropic &lt;a href=&#34;https://www.anthropic.com/news/core-views-on-ai-safety#:~:text=build%20safe%2C%20reliable%2C%20and%20steerable%20systems%20when%20those%20systems%20are%20starting%20to%20become%20as%20intelligent%20and%20as%20aware%20of%20their%20surroundings%20as%20their%20designers&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“build safe, reliable, and steerable systems when those systems are starting to become as intelligent and as aware of their surroundings as their designers”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The general idea is pretty simple. But there are many things to unpack here. Understanding what this means in practise is hard. First, why might we end up training unsafe AI systems? Even if you think this is possible, it&amp;rsquo;s not clear what regulations might be appropriate. Here are some metaphors I found particularly useful for gaining a deeper understanding of some aspects of AI alignment.&lt;/p&gt;
&lt;h3 id=&#34;the-eight-year-old-ceo&#34;&gt;The eight-year-old CEO&lt;/h3&gt;
&lt;p&gt;In this excellent &lt;a href=&#34;https://www.cold-takes.com/why-ai-alignment-could-be-hard-with-modern-deep-learning/&#34;&gt;blog post&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, Ajeya Cotra asks you to imagine the following scenario:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Imagine you are an eight-year-old whose parents left you a $1 trillion company and no trusted adult to serve as your guide to the world. You must hire a smart adult to run your company as CEO, handle your life the way that a parent would (e.g. decide your school, where you’ll live, when you need to go to the dentist), and administer your vast wealth (e.g. decide where you’ll invest your money). You have to hire these grownups based on a work trial or interview you come up with &amp;ndash; you don&amp;rsquo;t get to see any resumes, don&amp;rsquo;t get to do reference checks, etc. Because you&amp;rsquo;re so rich, tons of people apply for all sorts of reasons.&lt;/p&gt;
&lt;p&gt;Your candidate pool includes:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Saints&lt;/strong&gt; &amp;ndash; people who genuinely just want to help you manage your estate well and look out for your long-term interests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sycophants&lt;/strong&gt; &amp;ndash; people who just want to do whatever it takes to make you short-term happy or satisfy the letter of your instructions regardless of long-term consequences.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Schemers&lt;/strong&gt; &amp;ndash; people with their own agendas who want to get access to your company and all its wealth and power so they can use it however they want.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Deciding whom to hire is extremely difficult - you&amp;rsquo;re just eight! In this analogy, humanity is the eight-year-old CEO. Hiring a candidate is like training the superhuman AI model which will best serve our interests.&lt;/p&gt;
&lt;h3 id=&#34;building-planes&#34;&gt;Building planes&lt;/h3&gt;
&lt;p&gt;Suppose aerospace engineers have developed a new plane model. It&amp;rsquo;s energy-efficient, cheap to produce and has increased passenger comfort. However, the engineers don&amp;rsquo;t fully understand the internal workings of the engine. During testing, the engine seems to work alright. The engineers identified a few issues, but these could all be fixed quite easily. Would you be comfortable with this plane being produced for commercial use?&lt;/p&gt;
&lt;p&gt;Here, the AI models are like the engines. We know how to build AI models capable of writing poetry and conducting PhD-level research, but our understanding of how these models learn is relatively limited&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. So, we should probably reflect more carefully on how we&amp;rsquo;re deploying LLMs.&lt;/p&gt;
&lt;h3 id=&#34;drug-regulation&#34;&gt;Drug regulation&lt;/h3&gt;
&lt;p&gt;It takes years for newly developed drugs to reach consumers. First, you need preclinical trials. Then you carry out clinical trials in three distinct phases. This done, you need the approval of a regulatory agency, such as the FDA. It&amp;rsquo;s not uncommon for the entire process to take 10-15 years. Given that we subject drugs to such rigorous testing, why not do the same for LLMs?&lt;/p&gt;
&lt;p&gt;I first heard this analogy in &lt;a href=&#34;https://open.spotify.com/episode/38R2p5TG0uO02q3xybxsvR?si=7f8fa707ea174823&#34;&gt;this podcast&lt;/a&gt; (Swedish, sorry), where Olle Häggström makes the case for AI slowdown. I think the above analogy is quite compelling, although I don&amp;rsquo;t fully share his views.&lt;/p&gt;
&lt;h3 id=&#34;the-hustler&#34;&gt;The hustler&lt;/h3&gt;
&lt;p&gt;Imagine a person trying to learn a new skill, say playing Go. He has memorised all textbooks on Go ever published by heart, as well as all the games played by professional Go players. Moreover, he&amp;rsquo;s extremely hardworking: he plays roughly 1.5 million games against himself per day. (He doesn&amp;rsquo;t need any sleep, and he happens to think very quickly.) Given the amount of practise he gets, how can normal humans hope to defeat him?&lt;/p&gt;
&lt;p&gt;Here, the hustler is similar to an RL system. To me, this analogy makes the prospect of an intelligence explosion seem much more plausible&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; and less sci-fi-ish.&lt;/p&gt;
&lt;h3 id=&#34;final-thoughts&#34;&gt;Final thoughts&lt;/h3&gt;
&lt;p&gt;Finally, to understand the alignment problem, I think it&amp;rsquo;s also worth appreciating the potential impact of superhuman AGI. To me it seems like superhuman AI could be about as transformative as the industrial revolution. At the very least, I&amp;rsquo;d expect it to be as impactful as electricity. So, the ensuring the development of AGI &amp;ldquo;goes well&amp;rdquo; seems like a key problem of our time.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;This is one of my all-time favourite pieces on AI alignment.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;I don&amp;rsquo;t count &amp;ldquo;just backpropagate&amp;rdquo; as a satisfactory answer!&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;This analogy was inspired by a conversation with Samuel Ratnam at EAG.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>A semester paper retrospective</title>
      <link>http://localhost:1313/a-semester-paper-retrospective/</link>
      <pubDate>Sun, 18 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/a-semester-paper-retrospective/</guid>
      <description>&lt;p&gt;This is a follow-up on my &lt;a href=&#34;https://isabeldahlgren.github.io/two-results-from-probabilistic-number-theory/&#34;&gt;previous article&lt;/a&gt;, where I share some thoughts on the process of writing a semester paper.&lt;/p&gt;
&lt;p&gt;Lots of disclaimers: this is all very specific to my experience: the topic of my paper, my supervisor, my workload in others courses, etc. Also, I&amp;rsquo;m certainly in no position to give advice on mathematical writing; these are just reflections on what worked and what didn&amp;rsquo;t work for me.&lt;/p&gt;
&lt;h3 id=&#34;on-writing-papers&#34;&gt;On writing papers&lt;/h3&gt;
&lt;p&gt;Here are some principles for writing mathematical papers that I tried to follow, mostly based on feedback from my supervisors. I received plenty of useful feedback, but here are the points I found the most useful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Top-down exposition: concretely, this meant explaining how all lemmas would come together before proving each lemma. This minimises the amount of task-switching for the reader. In addition, this helps motivate the lemmas and allows the reader to decide which parts to skip.&lt;/li&gt;
&lt;li&gt;Short proofs: as a rule of thumb, I tried breaking up proofs in such a way that proofs of subresults would fit on one page. To my surprise, in most cases, this was doable.&lt;/li&gt;
&lt;li&gt;Reducing cognitive load: a piece of feedback I received from Vivian was to try reducing the cognitive load of the reader; it&amp;rsquo;s also a major theme &lt;a href=&#34;https://ngtriant.github.io/notes/practical_suggestions_for_mathematical_writing.pdf&#34;&gt;here&lt;/a&gt;. This idea really resonated with me. Concretely, this meant doing things like:
&lt;ul&gt;
&lt;li&gt;Restating parameters: for example, one might go &amp;ldquo;Recalling that $X = \text{definition of }X$, we obtain&amp;hellip;&amp;rdquo; rather than &amp;ldquo;By our choice of $X$, &amp;hellip;.&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Creating indices of notation and parameters: very relevant if your proof is notation-heavy.&lt;/li&gt;
&lt;li&gt;More descriptive text: rather than writing &amp;ldquo;we have&amp;rdquo; or &amp;ldquo;thus&amp;rdquo; before a computation, I tried describing which device I was using. Mentioning that you&amp;rsquo;re using, say, a union bound doesn&amp;rsquo;t take up much additional space on the page, and it makes for a better reading experience. (Also, if you&amp;rsquo;re doing analytic number theory, you need more alternatives to &amp;ldquo;we have&amp;rdquo;!)&lt;/li&gt;
&lt;li&gt;Indicating what won&amp;rsquo;t be proved: in order to keep the report at a reasonable length, I had to omit the proofs of some preliminary results and avoid repeating similar arguments. I tried making this clear to the reader, so I wouldn&amp;rsquo;t leave them hanging.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;What I would have found useful: initially, I didn&amp;rsquo;t know how many details to include. If I&amp;rsquo;d try explaining all details I&amp;rsquo;d struggled with when reading the proof, the text would be too verbose! Vivian had some good advice here: aim for the level of detail you&amp;rsquo;d liked when reading it for the first time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For future papers, I&amp;rsquo;m considering trying the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Including dependency graphs: although a bit unconventional, these can be tremendously helpful for long and convoluted proofs. See e.g. my piece on &lt;a href=&#34;https://isabeldahlgren.github.io/hunting-dependencies/&#34;&gt;dependencies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Commenting on dead ends: a few words about why the naïve approach fails can be very illuminating. This can help motivate the use of some very complicated tool and potentially save the reader a lot of time. While remarks on failed proof attempts can sometimes be found in the &amp;ldquo;Discussion&amp;rdquo; section of a paper, I think like they aren&amp;rsquo;t given as much attention as they deserve (an unfortunate instance of &lt;a href=&#34;https://en.wikipedia.org/wiki/Publication_bias&#34;&gt;publication bias&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Reducing cognitive load, even more: if I&amp;rsquo;d kept this in mind during the entire writing process, I think I&amp;rsquo;d done a few things differently. For further ideas on how to reduce cognitive load, I highly recommend the previously mentioned &lt;a href=&#34;https://ngtriant.github.io/notes/practical_suggestions_for_mathematical_writing.pdf&#34;&gt;piece&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lessons&#34;&gt;Lessons&lt;/h3&gt;
&lt;p&gt;If I were to write a thesis or paper again, I would have done a lot differently. Here are the main changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do it in one go: it would have been much more enjoyable and efficient doing most of the semester paper within a much shorter period of time. If you&amp;rsquo;re trying to understand an involved argument, you need all the relevant notions floating around in your brain at the same time. Don&amp;rsquo;t read one lemma per week.&lt;/li&gt;
&lt;li&gt;Request additional feedback: if your supervisor is kind to offer additional feedback, that&amp;rsquo;s extremely valuable.&lt;/li&gt;
&lt;li&gt;As soon as you get it, typeset: you&amp;rsquo;ll have to do it anyway, and you might as well do it when you understand it. This also helps corroborate your understanding.&lt;/li&gt;
&lt;li&gt;Know when to ask for help: I wasn&amp;rsquo;t sure how long it was reasonable for me to be stuck on a particular passage before asking for help, and I know supervisors have different preferences here. Trivial fix: ask your supervisor &amp;ldquo;For how long should I be stuck before asking for help?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Knowing how to ask for help: at first, I&amp;rsquo;d ask questions during meetings. But I soon began emailing a list of questions to my supervisor a few days before our check-ins. That way, I think we both got more out of the meetings.&lt;/li&gt;
&lt;li&gt;Typesetting takes time: it seems to be a law of nature that TeX:ing always takes longer than expected. This happened as I was writing my bachelor thesis too. Despite having a pretty sophisticated NeoVim LaTeX setup with snippets, typesetting took twice as long as I expected. For future papers, I&amp;rsquo;ll probably go with &lt;a href=&#34;https://typst.app/&#34;&gt;Typst&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Two results from probabilistic number theory</title>
      <link>http://localhost:1313/two-results-from-probabilistic-number-theory/</link>
      <pubDate>Sun, 11 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/two-results-from-probabilistic-number-theory/</guid>
      <description>&lt;p&gt;I recently wrote a semester paper on probabilistic number theory. I&amp;rsquo;m very grateful to both of my supervisors, Dr. Vivian Kuperberg and Prof. Dr. Emmanuel Kowalski, for their insights and suggestions. Here&amp;rsquo;s the abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This report is an exposition of two central limit theorems in probabilistic number theory. We begin by introducing preliminary results from number theory and probability theory. Then we prove the Erdős-Kac theorem for the asymptotic behaviour of the prime divisor counting function. The majority of the report is devoted to Radziwiłł and Soundarajan&amp;rsquo;s recent proof of the Selberg central limit theorem for $\log |\zeta(\frac{1}{2} + it)|$.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;You&amp;rsquo;re most welcome to have a look at the actual &lt;a href=&#34;https://drive.google.com/file/d/1AVEBwfBkdbcflnOQLYACcBXemqSPWzXP/view?usp=sharing&#34;&gt;semester paper&lt;/a&gt;. Here I&amp;rsquo;d like to give a more informal discussion of its contents.&lt;/p&gt;
&lt;h3 id=&#34;deterministic-number-theory&#34;&gt;&amp;ldquo;Deterministic&amp;rdquo; number theory&lt;/h3&gt;
&lt;p&gt;A central theme in analytic number theory is deriving estimates for averages over arithmetic functions, e.g. something like $$\sum_{n \le x} f(n) = \text{main term} + \text{error term},$$where $f: \mathbb{N} \to \mathbb{C}$ is some arithmetic function. Many &amp;ldquo;named theorems&amp;rdquo; are estimates of the above form. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If we let $f(n) = x^{-1} 1_P(n)$, where $1_P$ is the indicator of the set of prime numbers, then we get &lt;a href=&#34;https://terrytao.wordpress.com/2013/12/11/mertens-theorems/&#34;&gt;Mertens&amp;rsquo; second theorem&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If instead $f(n) = d(n)$, the function counting the number of divisors of a positive integer $n$, then a &lt;a href=&#34;https://mathworld.wolfram.com/DirichletDivisorProblem.html&#34;&gt;theorem of Dirichlet&lt;/a&gt; asserts that $$\sum_{n \le x} f(n) = x \log x + (2 \gamma - 1)x + O(\sqrt{x}).$$&lt;/li&gt;
&lt;li&gt;Actually, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Prime_number_theorem#Proof_sketch&#34;&gt;Prime number theorem&lt;/a&gt; is equivalent to an estimate of the above form. Just take $f$ to be the von Mangoldt function $\Lambda$, defined by $$\Lambda(n) := \begin{cases}\log p, &amp;amp; n = p^k \ \text{for some prime } p, \\ 0, &amp;amp; \text{otherwise}.\end{cases}$$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;probabilistic-number-theory&#34;&gt;Probabilistic number theory&lt;/h3&gt;
&lt;p&gt;In my semester paper, I focused on two central limit theorems from probabilistic number theory: the Erdős–Kac and Selberg central limit theorems. Here, the approach is slightly different.&lt;/p&gt;
&lt;h4 id=&#34;sums-and-integrals-as-expectations&#34;&gt;Sums and integrals as expectations&lt;/h4&gt;
&lt;p&gt;First, we let $f: \Omega \to \mathbb{C}$ be an arithmetically defined quantity more generally; typically $\Omega = \mathbb{N}$ or $\mathbb{R}$. So we could take $f$ to be an arithmetic function, but now we also allow for functions of arithmetic functions. For example, if we take $g: \mathbb{N} \to \mathbb{C}$ to be an arithmetic function and post-compose with $x \mapsto x^2 / \sqrt{\log \log x}$, then we could have $f: \mathbb{N} \to \mathbb{C}$ be a weird-looking expression defined by $$f(n) := \frac{g(n)^2}{\sqrt{\log \log n}}.$$&lt;/p&gt;
&lt;p&gt;To highlight the connection with probability theory, fix a positive integer $x$ and let $U_x$ be a random variable uniformly distributed on $\{1, &amp;hellip;, x\}$. Then we obtain $$\frac{1}{x} \sum_{n \le x} f(n) = \mathbb{E}(f(U_x)).$$ So, estimating $x^{-1} \sum_{n \le x} f(n)$ is the same as estimating an expectation.&lt;/p&gt;
&lt;p&gt;Similarly, the problem of estimating the integral $$\frac{1}{x} \int_0^x f(y) \ dy$$ also comes down to estimating an expectation. In the continuous case, let $x$ be an arbitrary positive real number and take $U_x$ to be a random variable uniformly distributed over $[0, x]$. Then the above integral is precisely $\mathbb{E}(f(U_x))$.&lt;/p&gt;
&lt;h4 id=&#34;natural-questions&#34;&gt;Natural questions&lt;/h4&gt;
&lt;p&gt;This naturally prompts the following questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Could we also estimate the variance of $f(U_x)$?&lt;/li&gt;
&lt;li&gt;Could we even say something about the asymptotic distribution of $f(U_x)$ as $x \to \infty$?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ideally, we can prove something like this:&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Let $U_x: \Omega \to \Omega_x$ denote a random variable uniformly distributed on $\Omega_x := \{1, &amp;hellip;, x\}$ (or $[0, x]$). Let $Y$ be a random variable with some simple distribution. Then as $x \to \infty$, we have $$f(U_x) \xrightharpoonup{} Y,$$ where $\xrightharpoonup{}$ denotes convergence in distribution.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;A remarkable fact is that some rather convoluted expressions involving arithmetic functions can converge in distribution to standard normal random variables as $x \to \infty$.&lt;/p&gt;
&lt;h4 id=&#34;general-proof-strategy&#34;&gt;General proof strategy&lt;/h4&gt;
&lt;p&gt;Proving results of this form involves machinery from both number theory and probability. We typically use number theory to massage the expression $f(U_x)$, so it can be approximated by some simpler non-arithmetic random variable. This done, we can use limit theorems from probability to finish off the proof.&lt;/p&gt;
&lt;h3 id=&#34;the-erdős-kac-theorem&#34;&gt;The Erdős-Kac theorem&lt;/h3&gt;
&lt;p&gt;This serves as a good &amp;ldquo;toy example&amp;rdquo; for the proof strategy outlined above. Also, it&amp;rsquo;s not too difficult deriving a heuristic proof; for details, see page 14.&lt;/p&gt;
&lt;p&gt;First, some notation. Let $\omega$ denote the function indicating the number of distinct prime divisors of a positive integer. For example, $\omega(6) = 2$ since $6 = 2 \cdot 3$, while $\omega(9) = 1$, since $9 = 3^2$. Then we have:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; (Erdős-Kac, 1940). Let $U_n$ be a random variable uniformly distributed on ${1, &amp;hellip;, n}$ and define $$W_n := \frac{\omega(U_n) - \log \log n}{\sqrt{\log \log n}}.$$ Then the sequence $(W_n)_{n \ge 1}$ of random variables converges in distribution to a standard normal random variable as $n \to \infty$.&lt;/p&gt;
&lt;h3 id=&#34;selbergs-central-limit-theorem-for-log-zeta12--it&#34;&gt;Selberg&amp;rsquo;s central limit theorem for $\log |\zeta(1/2 + it)|$&lt;/h3&gt;
&lt;p&gt;Let $\zeta$ denote the Riemann zeta function, defined by $$\zeta(n) := \sum_{n \ge 1} \frac{1}{n^s}.$$&lt;/p&gt;
&lt;p&gt;The Riemann hypothesis, perhaps the most famous open problem in mathematics, says that the only zeros of the zeta function are of the form $s = -2k$ for positive integers $k$ or lie on the critical strip $\{1/2 + it : t \in \mathbb{R}\}$.&lt;/p&gt;
&lt;p&gt;Now fix a positive number $T &amp;gt; 0$, and consider the random variable $$L_T := \log |\zeta(1/2 + iU_t)|,$$ where $U_t$ is a random variable uniformly distributed on the interval $[-T, T]$. Considering just how hard the Riemann hypothesis is, it&amp;rsquo;s pretty surprising that the behaviour of $L_T$ is relatively well-understood. In fact, we have:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; (Selberg, 1946). Let $L_T$ be the random variable defined as above, and set $$M_T := \frac{L_T}{\sqrt{\frac{1}{2} \log \log T}}.$$ Then the sequence $(M_T)_{T \ge 0}$ of random variables converges in distribution to a standard normal random variable as $T \to \infty$.&lt;/p&gt;
&lt;p&gt;In my semester paper, I cover the 2016 proof due to Radziwiłł and Soundarajan. Just as in the Erdős-Kac theorem, one can get an intuitive sense of why this result is plausible.&lt;/p&gt;
&lt;h3 id=&#34;final-words&#34;&gt;Final words&lt;/h3&gt;
&lt;p&gt;For details, I encourage you to have a look at the actual paper. I hope you enjoy reading it as much as I enjoyed writing it.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On decision fatigue</title>
      <link>http://localhost:1313/on-decision-fatigue/</link>
      <pubDate>Sun, 04 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-decision-fatigue/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;Life involves plenty of hard decisions. Should I switch jobs? Should I marry him? Should I move abroad? Then there are the &amp;ldquo;easy&amp;rdquo; decisions: which pyjama to wear or which brand of laundry detergent to buy. Although it doesn&amp;rsquo;t matter which option you choose here, choosing is hard. In fact, if you think of buying laundry detergent as an optimisation problem, taking into account things like social impact, price and quality, I&amp;rsquo;d expect the optimisation problem to be NP-hard! Here&amp;rsquo;s &lt;a href=&#34;https://thezvi.wordpress.com/2017/07/22/choices-are-bad/&#34;&gt;Zvi&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When you have a choice, you must stop what you’re doing, and choose.
[&amp;hellip;]
Making a random slash arbitrary choice might not be hard (although sometimes it is) but first you have to choose to choose at random. If you choose not to decide, you still have made a choice. There’s no escape!&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This leads to one of the big curses of adulthood - decision fatigue.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;Most of us are aware that choosing is draining. Steve Jobs wore black turtlenecks to reduce the number of decisions in a given day. &lt;em&gt;Should I Stay or Should I Go&lt;/em&gt; is basically a three-minute rant about how terrible it is making decisions&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The reason going to IKEA can be so tiring is that it involves making many small choices. Getting to choose among many options is only fun up to a certain point.&lt;/p&gt;
&lt;p&gt;According to &lt;a href=&#34;https://en.wikipedia.org/wiki/Decision_fatigue&#34;&gt;Wikipedia&lt;/a&gt;, decision fatigue is &amp;ldquo;the deteriorating quality of decisions made by an individual after a long session of decision making&amp;rdquo;. Decision fatigue arises from a broader phenomenon called ego depletion. Intuitively, this is the idea that willpower works like a battery. If we exert a lot of mental effort at one task, then we cannot exert as much mental effort at subsequent tasks without recharging. Making decisions drains our willpower battery.&lt;/p&gt;
&lt;p&gt;The phenomena of decision fatigue and ego depletion have been demonstrated in a number of amusing &lt;a href=&#34;https://www.nytimes.com/2011/08/21/magazine/do-you-suffer-from-decision-fatigue.html&#34;&gt;studies&lt;/a&gt;. A striking example is the study on Israeli judges, demonstrating the so-called &lt;a href=&#34;https://en.wikipedia.org/wiki/Hungry_judge_effect&#34;&gt;hungry judge effect&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Computer science offers another way to think about decision fatigue. While a psychologist might speak of ego depletion, a computer scientist might speak of computational complexity. Here&amp;rsquo;s from &lt;em&gt;Algorithms to Live By&lt;/em&gt; by Brian Christian and Tom Griffiths:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;One of the implicit principles of computer science, as odd as it may
sound, is that computation is bad: the underlying directive of any good
algorithm is to minimize the labor of thought. When we interact with other
people, we present them with computational problems—not just explicit
requests and demands, but implicit challenges such as interpreting our
intentions, our beliefs, and our preferences. It stands to reason, therefore,
that a computational understanding of such problems casts light on the
nature of human interaction.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Further, the authors go on to advocate for what they call &amp;ldquo;computational kindness&amp;rdquo;. When interacting with people, we should try sharing the computational cost of making decisions. If you prefer a particular restaurant, don&amp;rsquo;t hesitate to indicate your preference. Although you&amp;rsquo;re trying to be polite by saying you&amp;rsquo;re indifferent, the other person might be relieved to hear you&amp;rsquo;re craving a particular kind of food.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;The first step in dealing with decision fatigue is to notice it (as with so much else related to mental well being, I guess). Then one is in a better position to either make a quick, haphazard decision or recharging one&amp;rsquo;s willpower battery, so one can make a better decision later. This is easier said than done, though.&lt;/p&gt;
&lt;p&gt;For example, I recently planned a trip to London, booking flights, finding accommodation, coordinating with others, etc. Because I was excited about the trip, I didn&amp;rsquo;t notice when decision fatigue kicked in. If I&amp;rsquo;d known that it was decision fatigue, I wouldn&amp;rsquo;t have planned the trip in as much detail.&lt;/p&gt;
&lt;p&gt;In practise, noticing decision fatigue is hard. One can always practise &lt;a href=&#34;https://www.lesswrong.com/posts/GLPaZamxqkx7XJbXv/the-skill-of-noticing-emotions&#34;&gt;the skill of noticing&lt;/a&gt;, although it takes a lot of time. Another strategy would be trying to identify situations involving many choices and recalling how it felt. For instance, typical triggers of decision fatigue might be shopping, planning or coordinating with others. Analysis paralysis or a feeling of frustration might be good proxies for decision fatigue.&lt;/p&gt;
&lt;p&gt;But one can also take preventative measures. We can cut out a surprising number of choices from our everyday lives by coming up with default actions for various situations. For example, I don&amp;rsquo;t want to only wear black turtlenecks, but I do have a default outfit - a uniform of sorts. In Google Calendar, I also have a calendar describing my ideal week, so I don&amp;rsquo;t have to decide which lectures to attend on a day-to-day basis. Or at the supermarket: pick the cheapest toothpaste.&lt;/p&gt;
&lt;p&gt;Insignificant non-recurring choices can be batched, so one doesn&amp;rsquo;t go into choosing mode too often. One can even gamify the experience of making choices. For instance, I could have challenged myself to plan the trip within a given time frame.&lt;/p&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;One of the best things about being an adult is that you get to do whatever you want. Getting to choose is a privilege, after all. It&amp;rsquo;s a privilege we should use.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;If you speak Swedish, I recommend listening to Amanda Ginsburg&amp;rsquo;s &lt;a href=&#34;https://open.spotify.com/track/2ESWovaZgVi3BMloGgukKw?si=ca868beba3e24129&#34;&gt;I de många valens land&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>On good conversations</title>
      <link>http://localhost:1313/on-good-conversations/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/on-good-conversations/</guid>
      <description>&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;Some studies suggest we spend 80-90% of our waking hours talking with others. For a normal person, that&amp;rsquo;s at least 12 hours (!) per day. We spend most of our working hours talking to others, whether it be in meetings, lectures or exercise classes. When we&amp;rsquo;re not working, friends, roommates or partners might be around. The hours add up.&lt;/p&gt;
&lt;p&gt;Why do we spend this much time talking with others? Above all, interesting conversations are among the greatest pleasures in life. There&amp;rsquo;s nothing like a good conversation over a good meal. But talking with others can also be very productive. For example, talking with people smarter than you is a phenomenal way of learning. It&amp;rsquo;s like you&amp;rsquo;re downloading part of someone else&amp;rsquo;s worldview into your own head. Of course, there are other ways of achieving the same thing. However, in my opinion, one-on-one discussions come the closest to a loss-free download.&lt;/p&gt;
&lt;p&gt;For this reason, it&amp;rsquo;s natural to ask how we can have better conversations. Similar questions are often raised in the context of dating (&amp;ldquo;What are good topics to talk about on a date?&amp;rdquo;) or business (&amp;ldquo;How can we have more productive meetings?&amp;rdquo;). However, this question seems relevant to everyone.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;Several classic Russian novels go something like this: some characters are sitting on a train, they begin chatting and one thing leads to the next. That leads to an 800-page novel. The conversations they have are fascinating, although a bit exaggerated.&lt;/p&gt;
&lt;p&gt;I often have good conversations when I&amp;rsquo;m traveling. It&amp;rsquo;s as if me and my travel companions have this tacit agreement: &amp;ldquo;Okay, we&amp;rsquo;re all somewhat bored. We can&amp;rsquo;t do small talk for another five hours, so let&amp;rsquo;s talk. For real.&amp;rdquo; For this reason, people often end up being more open with one another.&lt;/p&gt;
&lt;p&gt;Moreover, simply being in a different environment can help. If you and a colleague are on a business trip, you&amp;rsquo;re less likely to ask the usual questions about the weather or life back home.&lt;/p&gt;
&lt;p&gt;Takeaway: the norms of the conversation matters a lot. If everyone implicitly agrees on the purpose of the discussion, things become a lot easier. Sometimes, there&amp;rsquo;s no need to say it out loud. But it can definitely help. For example, it might be better starting the phone call by saying &amp;ldquo;Hi, I need advice about you-know-who.&amp;rdquo; Or you might agree on a set of norms for the conversation. For instance, I recently learned that some people in rationalist circles will put a five minute timer whenever someone brings up philosophy of mind, a topic which often leads nowhere.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;Many scientists, artists and writers would have something like an intellectual spouse - a close collaborator with whom they&amp;rsquo;d discuss ideas. Famous examples include Watson and Crick, Lennon and McCartney or Sartre and de Beauvoir.&lt;/p&gt;
&lt;p&gt;Discussing is a skill. Doing it with the same people, at the same time and at the same place is a bit like practising regularly. Once you know each other sufficiently well, there&amp;rsquo;s no need to agree on conventions again. You just pick up from where you left off.&lt;/p&gt;
&lt;h3 id=&#34;iv&#34;&gt;IV.&lt;/h3&gt;
&lt;p&gt;The Arabic proverb goes &amp;ldquo;Speech is silver, silence is golden.&amp;rdquo; But in order for there to be silence, you need to be in a space with little background noise. Here comes an obvious point: having good discussions in noisy environments is much harder. I feel like this point tends to get neglected in practise, so I find it worth emphasising. Most restaurants, cafés or co-working spaces can be quite rowdy. Instead, consider going for a walk. Apparently Steve Jobs loved going for walking meetings, perhaps for this reason.&lt;/p&gt;
&lt;h3 id=&#34;v&#34;&gt;V.&lt;/h3&gt;
&lt;p&gt;From an information-theoretic perspective, good conversations are nothing short of miracles. You&amp;rsquo;ll have several people communicating complex ideas at an astonishing speed. There are no mind-reading devices involved, just words. In my own experience, having a good conversation largely comes down to synchronisation.&lt;/p&gt;
&lt;p&gt;As a quick side note, there&amp;rsquo;s a reason I&amp;rsquo;m using the word &amp;ldquo;synchronisation&amp;rdquo; rather than &amp;ldquo;communication&amp;rdquo;. &amp;ldquo;Communication&amp;rdquo; can also be interpreted as a one-sided process, where one party shares information with another group. But in a good discussion, information usually flows both ways.&lt;/p&gt;
&lt;p&gt;One way of synchronising better is asking more questions. Not only do questions help eliminating confusion, but they also make the conversation much more enjoyable. Depending on the situation, asking questions might also be necessary for everyone to feel included. Moreover, as pointed out by Ben Kuhn &lt;a href=&#34;https://www.benkuhn.net/listen/&#34;&gt;here&lt;/a&gt;, asking questions puts you in a better position to help whoever you&amp;rsquo;re talking to. Without any background information, you&amp;rsquo;re likely to give bad advice. And you can only acquire background information by asking questions.&lt;/p&gt;
&lt;p&gt;Another useful technique is paraphrasing. The goal here isn&amp;rsquo;t to sound smart, but to synchronise with your conversation partner. In practise, this means I&amp;rsquo;ll try rephrasing the other person&amp;rsquo;s idea and asking if it&amp;rsquo;s accurate.&lt;/p&gt;
&lt;h3 id=&#34;vi&#34;&gt;VI.&lt;/h3&gt;
&lt;p&gt;It&amp;rsquo;s not just about being in sync, though. A good conversation also needs to be heading in an interesting direction. If you all know you&amp;rsquo;re heading towards a dead end or that you&amp;rsquo;re going in circles, then it might be worth pointing this out (kindly, of course). Chances are people will agree and be glad someone noticed. It&amp;rsquo;s a bit like when the host declares the party is over at 2 am, and you&amp;rsquo;re grateful for someone forcing you to go home and get some sleep. Another benefit of moderating the discussion is that you simultaneously encourage the group to &lt;a href=&#34;https://en.wikipedia.org/wiki/Metacognition&#34;&gt;metacogitate&lt;/a&gt;. Similarly, if you feel uncomfortable with a particular subject, it might be a good idea to say you&amp;rsquo;d prefer talk about something else, rather than being passive aggressive.&lt;/p&gt;
&lt;h3 id=&#34;vii&#34;&gt;VII.&lt;/h3&gt;
&lt;p&gt;How many of our 12 hours of conversation are of high quality? Quite few, I suspect. And this completely OK. Having good conversations can be draining too. It&amp;rsquo;s a form of flow. Even Mihaly Csikszentmihalyi, the psychologist who coined the term &amp;ldquo;flow&amp;rdquo;, remarked that we cannot spend all our lives flowing. So there&amp;rsquo;s no need to cut all small talk.&lt;/p&gt;
&lt;p&gt;But some conversations matter more than others. In fact, certain conversations can be life-changing. They make life more enjoyable, generate creative and scientific insights and connect us to others. What if we could improve the quality of these conversations ever so slightly?&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Building time machines</title>
      <link>http://localhost:1313/building-time-machines/</link>
      <pubDate>Sun, 20 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/building-time-machines/</guid>
      <description>&lt;p&gt;There&amp;rsquo;s a folder on my computer called &amp;ldquo;Time machine&amp;rdquo; with files I want to preserve for posterity. The idea is to collect files which somehow represent today&amp;rsquo;s me. After doing this over a longer period of time, I&amp;rsquo;ll share the folder with future versions of people I care about.&lt;/p&gt;
&lt;h3 id=&#34;i&#34;&gt;I.&lt;/h3&gt;
&lt;p&gt;I like poring over old photos. I think it&amp;rsquo;s something I&amp;rsquo;ve picked up from my mom; she&amp;rsquo;s always the one to pull up a camera and have everyone else pose. I used to find this pretty embarrassing. But now I&amp;rsquo;m glad she ignored my complaints.&lt;/p&gt;
&lt;p&gt;A key theme in the book &lt;em&gt;Thinking, Fast and Slow&lt;/em&gt; is the distinction between the experiencing and remembering self. The experiencing self is the part feeling pleasure and pain, while the remembering self reflects on past experiences. While we&amp;rsquo;re often told to &amp;ldquo;carpe diem&amp;rdquo; more, we&amp;rsquo;re rarely told to try pleasing our remembering selves. But looking back on memories can be a huge source of joy. In fact, this has been confirmed experimentally. In &lt;em&gt;A little book about happiness&lt;/em&gt;, Michael Dahlén, professor of well-being at Stockholm School of Economics (SSE), describes a fascinating experiment in which participants were asked to estimate their well-being at three points in time: past, present and future. On average, the graph looked like a slanted &amp;ldquo;V&amp;rdquo;, the lowest point being the present. Perhaps looking back can make you more appreciative of what you have.&lt;/p&gt;
&lt;p&gt;If that all sounds a bit woo woo, that&amp;rsquo;s OK. If you want, you can also use your time machine to spot cognitive biases. For instance, I have a list of things I&amp;rsquo;ve changed my mind about. As highlighted in &lt;em&gt;Stumbling on Happiness&lt;/em&gt; (bad title, good book), we consistently fail to appreciate just how much we change. I also have a document with things preoccupying me at a given time. When revisiting past entries, I&amp;rsquo;ve noticed a tendency of taking things too seriously.&lt;/p&gt;
&lt;p&gt;The end product - your time machine - is something you can share with others. In due time, I&amp;rsquo;ll share mine with the people who matter the most to me. For instance, I&amp;rsquo;d like to share my time machine with family members, long-time friends and my future partner. And in the very distant future, I might show it to my teenage kids, allowing them to get to know their mother better.&lt;/p&gt;
&lt;h3 id=&#34;ii&#34;&gt;II.&lt;/h3&gt;
&lt;p&gt;There&amp;rsquo;s a lot of latitude in how to build a time machine. My journal makes up a big portion of my time machine. But there are also other files in there. One of the benefits of the digital age is that we can store huge amounts of data very easily, so you may as well be experimental.&lt;/p&gt;
&lt;p&gt;In secondary school, a friend of mine started a trend of creating monthly playlists on Spotify&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. I was quick in hopping on the trend, and I&amp;rsquo;m very grateful I did. Today I have a complete record of how my music taste has evolved since August 2015&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. But I&amp;rsquo;m far from the only one doing this kind of thing. For example, Luke Muehlhauser publishes a list of music recommendations on a quarterly basis &lt;a href=&#34;https://lukemuehlhauser.com/&#34;&gt;on his blog&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve also kept a reading diary since 2016. It must have started out as a vanity project - having read a boring classic, I assume I wanted to remember that I&amp;rsquo;d finished it. It&amp;rsquo;s amusing seeing how my preferences have changed over time. My reading log is just a long markdown document on my computer&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;, but you could also use a platform like StoryGraph or BookShelved. As of a couple of months ago, I&amp;rsquo;ve also been saving blog posts that particularly resonated with me.&lt;/p&gt;
&lt;p&gt;However, you could go beyond music and reading lists. Luke Muehlhauser also curates lists with video games. If you&amp;rsquo;re a big podcast listener, take note of which podcasts you particularly enjoyed in a given month.&lt;/p&gt;
&lt;p&gt;This is all a lot of work, especially if you consume a lot of content. Be selective, but be consistent. I&amp;rsquo;d count the moments I discovered my favourite authors and musicians among the most decisive in my life. I somehow feel like it&amp;rsquo;s impossible getting to know someone on a deeper level unless you have a rough idea of their media consumption.&lt;/p&gt;
&lt;p&gt;Other things could go into your time machine too. You can get to know someone else in a surprisingly short amount of time by asking the right questions. In fact, there are various compilations of questions meant to foster closer relationships - the most famous one being the &lt;a href=&#34;https://36questionsinlove.com/&#34;&gt;36 questions to fall in love&lt;/a&gt;. You could grab your favourite questions from that list and answer them in writing every year, say.&lt;/p&gt;
&lt;p&gt;I have two-three documents of this genre, but I&amp;rsquo;m planning on adding more. As mentioned above, there&amp;rsquo;s the list of things I was wrong about, as well as the list of things bothering me. Following the example of &lt;a href=&#34;https://nabeelqu.co/principles&#34;&gt;Nabeel Qureshi&lt;/a&gt;, I also have a &amp;ldquo;principles&amp;rdquo; document.&lt;/p&gt;
&lt;h3 id=&#34;iii&#34;&gt;III.&lt;/h3&gt;
&lt;p&gt;Humans have always been building their own time machines in the form of literature and art. But a time machine can be just about anything. Building one doesn&amp;rsquo;t require artistic talent, just consistency. Nowadays, you can build a digital time machine with minimal effort. Since files don&amp;rsquo;t take up any physical space, there&amp;rsquo;s no need to clutter your house with keepsakes.&lt;/p&gt;
&lt;p&gt;I was recently given a necklace which belonged to my great grandmother. It&amp;rsquo;s a beautiful piece of jewellery. But it doesn&amp;rsquo;t tell me much about who Ellen was. I hope I&amp;rsquo;ll be able to gift future generations something more.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Nina Ivarsson, more precisely. Thank you.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;The playlists from 2015-2017 are on my parents&amp;rsquo; account, but the more recent playlists can be found &lt;a href=&#34;https://open.spotify.com/user/q2r0ontmw48z1mc7u2elyho2u?si=1aed8800d74d41ce&#34;&gt;here&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;For excerpts of my reading log, see the &lt;a href=&#34;https://isabeldahlgren.github.io/library/&#34;&gt;library&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>How I use LLMs</title>
      <link>http://localhost:1313/how-i-use-llms/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/how-i-use-llms/</guid>
      <description>&lt;p&gt;&lt;em&gt;Related: &lt;a href=&#34;https://isabeldahlgren.github.io/will-ai-replace-mathematicians/&#34;&gt;Will AI replace mathematicians?&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;About 40% of students in the ETH main library always have a Chat-GPT tab open. I soon decided to try using LLMs for my own studies (because the wisdom of the crowd is a real thing). I haven&amp;rsquo;t figured out how to best use LLMs for my coursework, but I&amp;rsquo;m experimenting with various approaches.&lt;/p&gt;
&lt;h3 id=&#34;getting-unstuck&#34;&gt;Getting unstuck&lt;/h3&gt;
&lt;p&gt;For me, a big time sink is getting stuck on details. I usually go over the lecture notes after lectures, trying to work out the steps I didn&amp;rsquo;t follow with pen and paper. Ideally, I&amp;rsquo;d do this sitting next to a friend - it&amp;rsquo;s very convenient having someone whom to ask nearby. As Nate Soares put it &lt;a href=&#34;https://www.lesswrong.com/posts/w5F4w8tNZc6LcBKRP/on-learning-difficult-things&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;The problem is, most of the time that I get stuck, I get stuck on something incredibly stupid. I&amp;rsquo;ve either misread something somewhere or misremembered a concept from earlier in the book. Usually, someone looking over my shoulder could correct me in ten seconds with three words. &amp;lsquo;Dude. Disjunction. &lt;em&gt;Dis&lt;/em&gt;junction.&amp;rsquo;&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;But studying with a friend isn&amp;rsquo;t always possible. If there&amp;rsquo;s a point of confusion I cannot resolve myself after making a reasonable effort, asking an LLM might help. Formulating a good question is always an instructive exercise. Moreover, nine times out of ten, the response is useful. Even if the LLM doesn&amp;rsquo;t entirely solve my problem, it might reference relevant concepts or serve as a sanity check. Sometimes I&amp;rsquo;ll learn that my approach was completely mistaken - and that&amp;rsquo;s certainly useful too!&lt;/p&gt;
&lt;h3 id=&#34;hints&#34;&gt;Hints&lt;/h3&gt;
&lt;p&gt;In the classic &lt;em&gt;How to Solve It&lt;/em&gt;, George Pólya famously noted that mathematics isn&amp;rsquo;t a spectator sport. By generating hints, LLMs can be an aid in the problem-solving process too. Just have an honest attempt at the problem before consulting an LLM, and tell the LLM to not give away the entire solution. But it&amp;rsquo;s important to notice when one is stuck and ask for help. For someone like me who usually waits too long before taking hints, the ease of generating hints with Chat-GPT makes a huge difference.&lt;/p&gt;
&lt;h3 id=&#34;the-big-picture&#34;&gt;The big picture&lt;/h3&gt;
&lt;p&gt;LLMs are terrific at explaining high-level ideas. I&amp;rsquo;m a big fan of learning concepts &amp;ldquo;top-down&amp;rdquo;, starting with the big picture before getting into the details. While having more context doesn&amp;rsquo;t necessarily mean the material sticks better, I find this approach much more enjoyable. I usually ask Chat-GPT to give me the key idea before I look into the details. Apart from this, I regularly prompt Chat-GPT to give me the intuition for something or to motivate concepts. If a lecturer is pressed on time, they&amp;rsquo;ll cut the motivation bit, rather than leaving out a definition or theorem statement. For this reason, an AI-generated introduction can complement the lectured material.&lt;/p&gt;
&lt;p&gt;Some of my favourite prompts include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Why do we care about X?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;What is the main idea behind the proof of X?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;What&amp;rsquo;s the intuition for this definition?&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also find it helpful trying to explain a concept in my own words and asking Chat-GPT to elaborate or check if my explanation is accurate.&lt;/p&gt;
&lt;h3 id=&#34;caveats&#34;&gt;Caveats&lt;/h3&gt;
&lt;p&gt;All this said, I&amp;rsquo;d like to add a few caveats.&lt;/p&gt;
&lt;p&gt;A friend or teaching assistant could help with the above tasks better than today&amp;rsquo;s LLMs. They know about your mathematical background and what conventions you&amp;rsquo;re using. When I interact with chatbots, explaining conventions and providing context adds a lot of overhead. However, this problem seems fixable. Many AI labs are already working on ways to provide more personalised responses by having the chatbot remember information across chat sessions. Students could e.g. upload lecture notes and indicate which parts they&amp;rsquo;d covered.&lt;/p&gt;
&lt;p&gt;AI systems also make mistakes. But this isn&amp;rsquo;t that big of an issue. Most mistakes are easy to spot, especially if you ask the AI to explain steps that seem fishy. If you point out what went wrong, it will modify the argument. With human guidance, AI systems can get quite far. Also, LLMs don&amp;rsquo;t need to get all the details right in order to be useful. As Terry Tao noted in &lt;a href=&#34;https://unlocked.microsoft.com/ai-anthology/terence-tao/&#34;&gt;this blog post&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Strangely, even nonsensical LLM-generated math often references relevant concepts. With effort, human experts can modify ideas that do not work as presented into a correct and original argument. The 2023-level AI can already generate suggestive hints and promising leads to a working mathematician and participate actively in the decision-making process.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Of course, if you want to be dead certain the AI-generated argument is correct, have the AI output a formal proof in Lean.&lt;/p&gt;
&lt;p&gt;Another fear of mine, perhaps ungrounded, is basically that LLMs will make us lazy. Learning requires a certain amount of effort, while writing a good LLM prompt is relatively easy. If we use LLMs more and more, will we remove the friction needed for learning? I don&amp;rsquo;t know whether this fear is valid or if it&amp;rsquo;s just an instance of &amp;ldquo;tech panic&amp;rdquo;. But as long as we set boundaries for our LLM usage, we need not spoil the learning experience.&lt;/p&gt;
&lt;h3 id=&#34;where-does-this-leave-us&#34;&gt;Where does this leave us?&lt;/h3&gt;
&lt;p&gt;It seems, then, as if we could overcome the problems I&amp;rsquo;ve encountered when tinkering with AIs. My experience with using LLMs as part of my studies has been positive, so I&amp;rsquo;ll continue exploring ways in which AI can assist. The one thing that LLMs can&amp;rsquo;t provide, however, is the social aspect of doing maths. Solving problems with others is infinitely more fun than coming up with LLM prompts. If anything, I think the above use cases highlight the importance of doing maths together with others.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Will AI replace mathematicians?</title>
      <link>http://localhost:1313/will-ai-replace-mathematicians/</link>
      <pubDate>Sun, 06 Apr 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/will-ai-replace-mathematicians/</guid>
      <description>&lt;p&gt;I used to think of maths as the one thing LLMs couldn&amp;rsquo;t do well. While GPT 3.0 would excel in language-based tasks, it would struggle to solve elementary maths problems. But a lot has happened since then. Over the last year, I&amp;rsquo;ve come to take the idea of using AI as an aid for doing maths more seriously. In fact, I now believe LLMs might prove new theorems with no human guidance within just 3 years.&lt;/p&gt;
&lt;p&gt;First, there was the silver medal at International Mathematics Olympiad (IMO). Although AlphaProof and AlphaGeometry 2 took well over 9h, the time given contestants are given, it&amp;rsquo;s quite a feat: IMO problems require an element of creativity. Not only that - it was able to formalise its solution in Lean. Lean is still a fairly new programming language, and there isn&amp;rsquo;t nearly as much training data as for other programming languages. The work of the DeepMind team shows two things: firstly, lots of clever people are trying to build AI systems for doing maths; secondly, apparently their current approach works pretty well. However, as of April 2025, you don&amp;rsquo;t need an AI specifically trained to do maths in order to solve tricky problems: the new o3 and o4 mini models achieve &lt;a href=&#34;https://openai.com/index/introducing-o3-and-o4-mini&#34;&gt;impressive performance&lt;/a&gt; in the American Invitational Mathematics Examination (AIME). What if we use RL to build AI systems specialised in more advanced topics? Perhaps these AIs might prove new theorems. Even if they don&amp;rsquo;t, they might provide researchers with insights.&lt;/p&gt;
&lt;p&gt;Next, several top-gun mathematicians think AI might transform maths research in the next decade. Most notably, Terence Tao has highlighted ways in which machines can help human mathematicians. Here&amp;rsquo;s from a &lt;a href=&#34;https://unlocked.microsoft.com/ai-anthology/terence-tao&#34;&gt;blog post&lt;/a&gt; of Tao:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I could feed GPT-4 the first few PDF pages of a recent math preprint and get it to generate a half-dozen intelligent questions that an expert attending a talk on the preprint could ask. I plan to use variants of such prompts to prepare my future presentations or to begin reading a technically complex paper.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In &lt;a href=&#34;https://epoch.ai/frontiermath/expert-perspectives&#34;&gt;this report&lt;/a&gt; from Epoch AI, Richard Borcherds seems equally optimistic about the possibilities of using, predicting that AI might even surpass human mathematicians within 10 years. Overall, I think we&amp;rsquo;re starting to see a cultural shift in the maths community. People are recognising that AI is a huge deal.&lt;/p&gt;
&lt;p&gt;Finally, I observed that 40% of students in the library seem to have a Chat-GPT tab open at all times. These are students doing STEM subjects, such as maths and physics. This seems like an important data point (and this isn&amp;rsquo;t just because I&amp;rsquo;m giving more weight to first-hand experience). LLMs are transforming the way students learn, and these are the people who will go on to do research in a couple of years. Chances are we won&amp;rsquo;t stop using LLMs just because the material becomes more niche. Even if you receive a hallucinatory answer, the LLM might reference a relevant concept, helping you get unstuck. I&amp;rsquo;m using Chat-GPT for my own studies, and I&amp;rsquo;m impressed by its explaining abilities. Basically, it can easily handle any concept you&amp;rsquo;ll come across in a master degree in mathematics. I&amp;rsquo;ve also prompted Chat-GPT to distill the key ideas from more recent papers and found its responses very helpful.&lt;/p&gt;
&lt;p&gt;All in all, I&amp;rsquo;ve come to shorten my AI timelines quite a bit. But rather than thinking &amp;ldquo;Will I ever find a job?&amp;rdquo;, I find myself thinking &amp;ldquo;What a time to be alive!&amp;rdquo;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>&#34;Just switch it off&#34;</title>
      <link>http://localhost:1313/just-switch-it-off/</link>
      <pubDate>Sun, 30 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/just-switch-it-off/</guid>
      <description>&lt;p&gt;If we develop a rogue AI, couldn&amp;rsquo;t we just switch it off? This is the obvious objection to the idea that AI could be dangerous. Here &amp;ldquo;switching off&amp;rdquo; would mean deleting a model&amp;rsquo;s weights, so it can&amp;rsquo;t be deployed. Deleting files is easy enough, so what might prevent us from switching off a misaligned AI?&lt;/p&gt;
&lt;p&gt;First, the users need to realise that the model is dangerous. This can be challenging, especially for more advanced models. The key premise here is that AIs will try preserving themselves. That is, they don&amp;rsquo;t &amp;ldquo;want&amp;rdquo; to be turned off - this would prevent them from pursuing their goals. If an AI knows that it will be turned off if it&amp;rsquo;s misaligned, it might try appearing safe during training. This is commonly known as &lt;a href=&#34;https://arxiv.org/pdf/2412.14093&#34;&gt;&amp;ldquo;alignment faking&amp;rdquo;&lt;/a&gt;. Although this sounds a bit far-fetched, this phenomenon has been observed in some models.&lt;/p&gt;
&lt;p&gt;Second, and perhaps more worryingly, is the question of whether we as a society want to &amp;ldquo;press delete&amp;rdquo;. Turning off sandboxed AI - AI developed in a secure training environment - isn&amp;rsquo;t a big deal. The negative consequences, if any, are limited to the few people who can access the model. But a leading AI company has strong incentives against withdrawing potentially unsafe models from the market. Doing this would mean less profit, bad PR and giving away market share to competitors. Besides these economical considerations, there&amp;rsquo;s the geopolitical aspect. As highlighted in the &lt;a href=&#34;https://ai-2027.com/&#34;&gt;AI 2027 report&lt;/a&gt;, the fear of falling behind in the AI arms race might lead us to deploy even misaligned AI. Even if the people behind the AI wanted to switch off their models because of safety considerations, what would the general public think? Most people would probably be reluctant to stop their favourite LLMs, despite poor performance on safety benchmarks.&lt;/p&gt;
&lt;p&gt;Switching off an AI isn&amp;rsquo;t just a matter of deleting files. It requires us to detect unsafe behaviour, a task that&amp;rsquo;s likely to become more difficult with more capable models. Then there&amp;rsquo;s the human factor. Asking that AI companies delete models showing signs of misalignment is asking for a lot. In the future, turning off an AI in a broader sense would require turning off parts of our society.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>From a YouTube alumna</title>
      <link>http://localhost:1313/from-a-youtube-alumna/</link>
      <pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/from-a-youtube-alumna/</guid>
      <description>&lt;p&gt;Random people on the Internet have played a huge role in my education. I&amp;rsquo;m not just referring to my coursework at university, but also to &amp;ldquo;Bildung&amp;rdquo; more generally. I&amp;rsquo;ve learned a ton by browsing StackOverflow threads and reading Medium articles. However, I&amp;rsquo;ve probably learned the most from watching YouTube.&lt;/p&gt;
&lt;h3 id=&#34;learning-by-watching&#34;&gt;Learning by watching&lt;/h3&gt;
&lt;p&gt;Above all, there&amp;rsquo;s some really high-quality content out there. Nowadays there are full-time YouTubers, working on creating professional, meticulously edited videos. And some channels, such as &lt;a href=&#34;https://www.youtube.com/channel/UCsXVk37bltHxD1rDPwtNM8Q&#34;&gt;Kurzgesagt&lt;/a&gt;, are even ran by entire teams of illustrators and script-writers. Moreover, because anyone can record themselves and upload it to YouTube, we have world-class experts sharing their knowledge in YouTube lectures&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. This means there are some truly remarkable YouTube videos. For example, here are comments from some &lt;a href=&#34;https://www.youtube.com/@3blue1brown&#34;&gt;3Blue1Brown&lt;/a&gt; videos:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I dropped out in 10th grade 25 years ago and your videos have inspired me to go back to school.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;You sir truly deserve an honorary doctorate - just for this video. Your impact to generations of confused engineering and math students will forever ripple through our society.&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;I have a master&amp;rsquo;s degree in mechanical engineering and I&amp;rsquo;m starting to think I should redo my whole education from ground up searching for this kind of intuitive knowledge. It&amp;rsquo;s absurd that I find out explanations which are as intuitive as this one so late in my life. I&amp;rsquo;m blown away completely! I mean how many bits of information have we stumbled upon during our formal education failing to see how they elegantly relate to each other and form a bigger picture&amp;hellip;oh my!&amp;rdquo;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Moreover, videos tend to be more attention-grabbing than articles. Although most people are unable to read while cooking or brushing their teeth, they can watch videos. So getting started learning has never required less willpower: just search &amp;ldquo;Introduction to&amp;hellip;&amp;rdquo; on YouTube.&lt;/p&gt;
&lt;h3 id=&#34;learning-to-watch&#34;&gt;Learning to watch&lt;/h3&gt;
&lt;p&gt;Of course, YouTube isn&amp;rsquo;t designed to be a learning platform. But there ways of optimising for a better learning experience.&lt;/p&gt;
&lt;p&gt;The first step is to recognise that YouTube tries maximising user retention. This is a feature, not a bug. It means we can design our YouTube interface such that we end up binge watching informative videos about topics we care about. Here are some ways of achieving this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Train your algorithm&lt;/strong&gt;: in your YouTube feed, take 2 seconds to press &amp;ldquo;Not interested&amp;rdquo; whenever something irrelevant pops up. It pays off - I find the YouTube algorithm to be surprisingly sensitive to my feedback.&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Keep separate accounts&lt;/strong&gt;: on a similar note, I have two Google accounts: my main account, and my secondary account. I&amp;rsquo;ll use my main account for watching &amp;ldquo;useful&amp;rdquo; content, while I&amp;rsquo;ll log onto my secondary account for, well, everything else.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Block channels&lt;/strong&gt;: use &lt;a href=&#34;https://getcoldturkey.com/support/how-to/allow-youtube-channel/&#34;&gt;ColdTurkey&lt;/a&gt; to block certain YouTube channels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second step is to recognise the limits of just watching videos. There&amp;rsquo;s a reason we don&amp;rsquo;t abandon more traditional media altogether. When reading a book, I find it much easier recognising when I&amp;rsquo;m confused. However, after finishing a video, I sometimes find myself completely lost and unable to tell where I stopped following. Moreover, whenever I have a physical textbook, I&amp;rsquo;ll often refer back to chapters I&amp;rsquo;ve finished, just to refresh my memory. Here are two partial fixes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Media notes plugin&lt;/strong&gt;: the &lt;a href=&#34;obsidian://show-plugin?id=media-notes&#34;&gt;Media Notes&lt;/a&gt; plugin for Obsidian is a real game-changer. It allows you to watch YouTube videos from inside Obsidian and take notes with timestamps. When doing this, I seem to engage more with the material. Taking physical notes while watching YouTube is a bit overkill, so this seems like a good compromise.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rewatch your favourite videos&lt;/strong&gt;: it&amp;rsquo;s easy ending up only consuming new content, just because the YouTube landing page is filled with new videos. But it&amp;rsquo;s worth saving your favourite videos to playlists and rewatching them later.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As I discussed above, there are some hacks for a better learning experience. However, YouTube could also design their platform differently. They could e.g. develop distraction-free mode, enabling the user to remove shorts, ads or sponsored content. From a technical perspective, it&amp;rsquo;s doable. But we could also go beyond ordinary videos. For example, Andy Matuschak and Michael Nielsen have explored ways of incorporating an element of spaced repetition in videos, making for a more interactive learning experience; see &lt;a href=&#34;https://numinous.productions/ttft/#mnemonic-video&#34;&gt;here&lt;/a&gt;. In general, I&amp;rsquo;m excited about integrating modern technology with education.&lt;/p&gt;
&lt;p&gt;All this said, I’d like to thank the strangers who have played - and continue to play - an important role in my education.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;See e.g. &lt;a href=&#34;https://www.youtube.com/@AndrejKarpathy&#34;&gt;Andrej Karpathy&amp;rsquo;s channel&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;My friend Åke Lindblom first told me about this. He apparently has an insanely good algorithm.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Look for opinions</title>
      <link>http://localhost:1313/look-for-opinions/</link>
      <pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/look-for-opinions/</guid>
      <description>&lt;p&gt;Opinionated people can be really annoying. Wherever they go, they try convincing you of their ideas. If you have an opinionated uncle, the Christmas dinner might be ruined by a bitter argument. I&amp;rsquo;ve certainly had bad experiences with a dinner-table conversations turning into feuds. For this reason, I used to try having fewer opinions. I somehow assumed this meant being more open-minded and mature. Well, no.&lt;/p&gt;
&lt;h3 id=&#34;welcoming-opinions&#34;&gt;Welcoming opinions&lt;/h3&gt;
&lt;p&gt;Actually, there are plenty of benefits of actively trying to form more opinions. Even about topics you don&amp;rsquo;t know particularly well. If you learn with a view towards arguing, then you&amp;rsquo;ll pay closer attention to the material. I think this has to do with anchoring. If you pick a stance, even at random, you&amp;rsquo;ll be more emotionally invested. Holden Karnofsky summarised it neatly in &lt;a href=&#34;https://www.cold-takes.com/learning-by-writing/&#34;&gt;Learning by Writing&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;By doing this [trying to have a hypothesis and rearticulating it whenever it changes], I try to &lt;strong&gt;continually focus my reading on the goal of forming a bottom-line view, rather than just “gathering information.”&lt;/strong&gt; I think this makes my investigations more focused and directed, and the results easier to retain. I consider this approach to be &lt;strong&gt;probably the single biggest difference-maker between &amp;ldquo;reading a ton about lots of things, but retaining little&amp;rdquo; and &amp;ldquo;efficiently developing a set of views on key topics and retaining the reasoning behind them.&amp;rdquo;&lt;/strong&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Moreover, chatting with people with strong opinions can also be fun. Say you&amp;rsquo;re at a cocktail party. Small talk can be quite tiring, at least after a couple of hours. In this situation, I&amp;rsquo;ll gladly talk to people trying to persuade me of their ideas. Or say you&amp;rsquo;re hosting friends for dinner, and a friend explains her take on a topic you all like.&lt;/p&gt;
&lt;p&gt;Back in school, we were encouraged to form more opinions. Teachers made us write argumentative essays about topics we hardly knew anything about. They know that most 14 year-olds don&amp;rsquo;t care the slightest about whether fathers should be given two additional weeks of paternity leave, or if the capital income tax should be raised by 1%. But I don&amp;rsquo;t think it was only meant as an exercise in communicating effectively. It felt as if teachers were saying &amp;ldquo;Go out there in the big wild world, and look for opinions!&amp;rdquo;&lt;/p&gt;
&lt;h3 id=&#34;chasing-opinions&#34;&gt;Chasing opinions&lt;/h3&gt;
&lt;p&gt;So why doesn&amp;rsquo;t everyone have, like, a lot opinions?&lt;/p&gt;
&lt;p&gt;I think many people, whether they recognise it or not, resort to some kind of agnosticism for fear of being wrong. However, recognising you&amp;rsquo;re wrong just means you&amp;rsquo;re updating your beliefs. It&amp;rsquo;s not that big of a deal. Also, many people think they aren&amp;rsquo;t entitled to hold an opinion since they aren&amp;rsquo;t &amp;ldquo;qualified&amp;rdquo;. This is true for areas in which there&amp;rsquo;s a clear distinction between experts and non-experts. But I have a hunch that we sometimes use this as an excuse for not looking into certain issues. For example, as highlighted in &lt;a href=&#34;https://www.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock/dp/0804136718&#34;&gt;Superforecasting&lt;/a&gt;, normal people can form well-informed predictions on certain issues with a bit of practise. Anyway, I think there&amp;rsquo;s a middle ground here: if you don&amp;rsquo;t know all the technical details, just adjust your confidence levels.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s worth emphasising that forming opinions can be very difficult and time-consuming. For example, predicting technological progress is notoriously hard. It requires you to do your homework, researching which factors influence scientific advancements and so on. This goes against the idea of opinions coming to us &amp;ldquo;naturally&amp;rdquo;, as if by chance. Yet, this isn&amp;rsquo;t a good reason not to actively seek out opinions. Sometimes, we have to make our minds up in order to take action.&lt;/p&gt;
&lt;p&gt;As long as one has some &amp;ldquo;epistemic etiquette&amp;rdquo; - being prepared to change your beliefs in the light of new evidence, and not taking everything so personally - having more opinions seems like a good thing. I&amp;rsquo;m currently trying to build the habit of always having a working hypothesis whenever I learn something new. Having more opinions makes you feel more like part of the world, rather than as a bystander.&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>How AI might go wrong</title>
      <link>http://localhost:1313/how-ai-might-go-wrong/</link>
      <pubDate>Sun, 09 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/how-ai-might-go-wrong/</guid>
      <description>&lt;p&gt;As with any new technology, advanced AI entails certain risks. While we&amp;rsquo;re investing crazy amounts of money in developing more capable AI models, only a fraction gets channeled towards AI safety research.&lt;/p&gt;
&lt;p&gt;The other week, I had an insightful discussion with people in &lt;a href=&#34;https://www.zurich-ai-alignment.com&#34;&gt;Zürich AI Alignment (ZAIA)&lt;/a&gt; about the risks from AI. Afterwards, I began writing down my thoughts, and they somehow ballooned into this think piece. Here are what I currently consider to be the most relevant risks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Powerful technology in bad hands&lt;/strong&gt;: First, there are the risks which all fall under the label &amp;ldquo;bad guys using powerful technology to further their own interests&amp;rdquo;. For example, AI can be used for mass surveillance technology, cyber warfare or in autonomous lethal weapons. I&amp;rsquo;d guess most people are uncomfortable with China having nukes. Similarly, China developing cutting-edge AI is a cause for concern.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concentration of power&lt;/strong&gt;: AI is a transformative technology - a message that shouldn&amp;rsquo;t have escaped anyone, given the current AI hype. In the years to come, it&amp;rsquo;s likely to have a profound impact on things like our economy and healthcare system; see e.g. &lt;a href=&#34;https://www.weforum.org/stories/2025/03/ai-transforming-global-health/&#34;&gt;here&lt;/a&gt;. So the main players, like OpenAI, DeepMind and Anthropic, will be able to shape the trajectory of our society in many ways. And this is kind of problematic. While the engineers at these companies tend to be lovely people, they aren&amp;rsquo;t democratically elected.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Misaligned AI models&lt;/strong&gt;: But we could also end up building AI models doing more harm than good, i.e. AI models whose incentives aren&amp;rsquo;t aligned with our values. Our understanding of the inner workings of certain AI models is very limited. While aerospace engineers know exactly what goes on inside, say, a combustion engine, the exact details of how neural networks learn remain fuzzy. If the aerospace engineers only have a vague idea of how the cooling system works, how confident can they be that the combustion engine will work as intended? In the process of developing more capable AI, we&amp;rsquo;ll probably engineer some AI models that are thrash; useless, at best, harmful at worst. We&amp;rsquo;ve already seen plenty of examples of this. For example, as highlighted in &lt;a href=&#34;https://www.youtube.com/watch?v=zn2ukSnDqSg&#34;&gt;this video&lt;/a&gt;, it&amp;rsquo;s still quite easy jailbreaking LLMs like ChatGPT. Moreover, there are &lt;a href=&#34;https://www.ibm.com/think/topics/shedding-light-on-ai-bias-with-real-world-examples&#34;&gt;striking examples&lt;/a&gt;
) of algorithms encoding our own biases.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Power-seeking AI&lt;/strong&gt;: Some people push this argument further, arguing that we might see very, very misaligned AI models - AI models posing an existential threat to humanity. I&amp;rsquo;ll briefly outline what I understand to be the core argument. The first premise is that AIs might end up with power-seeking behaviour. If power is instrumental in achieving one of the AI&amp;rsquo;s goals, the AI might learn to optimise for power. At the same time, we&amp;rsquo;re likely to develop more agentic AI, that is, AI capable of pursuing independent goals and with more advanced planning capabilities. Now the punchline is that such an AI might view humans as obstructions to pursuing its goals. Humans can modify the learning algorithm, or try switching off the AI - things which would prevent the AI from minimising the loss function. Stuart Russell put it neatly: &amp;ldquo;You can&amp;rsquo;t fetch the coffee if you&amp;rsquo;re dead&amp;rdquo;. So, the argument goes, the AI might try to disempower humanity.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The argument about power-seeking AI is quite subtle, so I&amp;rsquo;ll elaborate a bit. I think the keyword here is &amp;ldquo;agency&amp;rdquo;. History is full of examples of goal-oriented men with strong persuasion skills who made a great deal of harm, without necessarily wanting to exterminate all of humanity. These people knew how to pursue their goals and were good at strategic thinking. These people were doers, or, if you will, very &amp;ldquo;agentic&amp;rdquo;. Endowed with AI-like capabilities, these men would probably have caused much greater damage.&lt;/p&gt;
&lt;p&gt;Of course, there&amp;rsquo;s much more to be said about each topic. But broadly speaking, I think most risks fall into either one of the above categories. For a more fine-grained taxonomy, see &lt;a href=&#34;https://www.lesswrong.com/posts/9dNxz2kjNvPtiZjxj/risks-from-ai-overview-summary&#34;&gt;this article&lt;/a&gt;. Finally, if this essay seems a bit doom-laden, remember that there are plenty of things we can do to eliminate or mitigate some of these risks. If we take adequate measures, I believe we can make AI &amp;ldquo;go well&amp;rdquo; with very high probability - something like 90%. Just take a moment to imagine what that would be like.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Isaia Gisler for feedback on an earlier version of this text.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Useful thought experiments</title>
      <link>http://localhost:1313/useful-thought-experiments/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/useful-thought-experiments/</guid>
      <description>&lt;p&gt;Philosophers love thought experiments. Thought experiments are hypothetical scenarios meant to tease out our intuitions about an argument or theory. For example, here&amp;rsquo;s a classic thought experiment, due to Robert Nozick:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life&amp;rsquo;s experiences?&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Many thought experiments seem kind of cooked up, so it&amp;rsquo;s easy to believe thought experiments have no practical use. However, one of my key takeaways from &lt;em&gt;The Scout Mindset&lt;/em&gt; by Julia Galef was that thought experiments aren&amp;rsquo;t just diversion for people with too much spare time. In fact, she argues, certain thought experiments can help us think more clearly about decisions we face in everyday life&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. In this essay, I&amp;rsquo;ll go over three interesting thought experiments from her book, and then describe two personal faves.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The Outsider Test&lt;/strong&gt;: This all comes down to having an outsider&amp;rsquo;s perspective, as if one were calling a friend. How would an outsider evaluate the situation? For example, say John Doe has been given two job offers: one at company X, the other at company Y. Company X will look better on his CV, but he&amp;rsquo;s unlikely to enjoy the day-to-day tasks. In contrast, the job at company Y, although not quite as prestigious, seems more fun. Here, an outsider may say something like &amp;ldquo;If prestige weren&amp;rsquo;t a consideration, which option would you pick?&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Conformity Test&lt;/strong&gt;: This is a good one. We&amp;rsquo;re often quick in adopting the beliefs of people we respect. And this is usually a good thing: life is to short to overthink everything, and we&amp;rsquo;ve got to form opinions somehow. (For fans of &lt;em&gt;Thinking, Fast and Slow&lt;/em&gt;, this is System 1 in action.) However, when it comes to more delicate subjects, this mental short-cut might fail. In the Conformity Test, Julia Galef asks you to imagine that people no longer hold your view. (To all contrarians out there, just imagine that the people in your community suddenly become just as everyone else.) There&amp;rsquo;s a particularly interesting spin-off here: what if one of the main proponents of your view, perhaps the person who helped shape your beliefs about the subject, would change their mind? I think the EA/rationalist community provides a good use case. What if Will MacAskill would say he was completely mistaken about longtermism, rejecting the idea altogether? Or if Eliezer Yudowsky would declare that AI after all isn&amp;rsquo;t that big of a threat?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The Status Quo Bias Test&lt;/strong&gt;: The underlying idea here is that humans have a bias towards the status quo. If you were to start from scratch, would you actively choose your current situation? For example, imagine a medical student who realises halfway through second year of med school that medicine isn&amp;rsquo;t for her. Although she cannot imagine herself as a doctor, she&amp;rsquo;s still hesitant to switch subjects. Here the Status Quo Bias Test might come in handy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;After reading &lt;em&gt;The Scout Mindset&lt;/em&gt;, I soon realised that some of the advice I&amp;rsquo;ve received over the years can be rephrased as thought experiments. Here are two such thought experiments which I&amp;rsquo;ve found particularly useful:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Worst Case Scenario&lt;/strong&gt;: This just involves asking oneself about the worst-case scenario. Is it really that bad? If yes, well, then you know. At least your fear isn&amp;rsquo;t  some sort of vague, scary illusion. And if not, good!&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast forward a decade&lt;/strong&gt;: In ten years from now, which decision is one more likely to regret? Humans are famously bad at long-term planning. We&amp;rsquo;ll often fail to take the route of action with benefits in a distant future. (Hence climate change and the fact that most adults don&amp;rsquo;t get enough sleep.) So it might be a good idea doing some kind of Outsider test, where the outsider is one&amp;rsquo;s future self.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some of the above thought experiments might sound familiar. Perhaps you&amp;rsquo;ve already used some of them yourself. After all, these seem like obvious tricks for seeing this for what they are. But perhaps it&amp;rsquo;s helpful having names for these tricks. It&amp;rsquo;s a bit like building a toolkit for better decision-making. I&amp;rsquo;ve applied something like Worst Case Scenario a bunch of times, but only after spending a couple of days of dwelling on the issue in a very unproductive way. Thinking in terms of thought experiments would have spared me a lot of headache.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;Nozick, Robert, and Thomas Nagel. &lt;em&gt;Anarchy, state, and utopia&lt;/em&gt;. Vol. 5038. New York: Basic books, 1974.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;Galef, Julia. &lt;em&gt;The Scout Mindset: Why some people see things clearly and others don&amp;rsquo;t&lt;/em&gt;. Penguin, 2021.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    
    
    <item>
      <title>Hunting dependencies</title>
      <link>http://localhost:1313/hunting-dependencies/</link>
      <pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/hunting-dependencies/</guid>
      <description>&lt;p&gt;One of the benefits of attending lectures is that lecturers tend to give some really good unsolicited advice every now and then. Last semester, a professor of ours digressed to talk about the importance of identifying the key ingredients of a result. He&amp;rsquo;d just concluded a rather long proof, and was about to clean the blackboard as he said that the result was elementary. See, you only need this one lemma from point-set topology (admittedly a bit niche, but easy to prove), and then the definition of the Fourier transform. Put that way, sure, maybe it&amp;rsquo;s elementary. Explicitly writing down the dependencies of an idea, he said, was a good exercise.&lt;/p&gt;
&lt;h3 id=&#34;an-example&#34;&gt;An example&lt;/h3&gt;
&lt;p&gt;I tried doing this a couple of times for definitions, theorem statements and proofs. At first, it felt a bit silly. Once I finished writing down the main components of a result, it seemed trivial. I overdid it at first, writing down dependencies even for minor lemmas. But for more complicated theorems or involved definitions, it proved quite useful.&lt;/p&gt;
&lt;p&gt;Now for a concrete example. Suppose we&amp;rsquo;re trying to understand martingales. Martingales can be thought of as sequences of random variables representing fair games: if we&amp;rsquo;re given the value of the $n$:th random variable, we expect the value of the $(n+1)$:th random variable to stay the same. There&amp;rsquo;s no predictable up- or downward trend. Here&amp;rsquo;s the definition from &lt;a href=&#34;https://link.springer.com/book/10.1007/978-3-031-14205-5&#34;&gt;Le Gall&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Let $(X_n)_{n \in \mathbb{Z}_+}$ be an adapted, real-valued random process, such that $E(|X_n|) &amp;lt; \infty$ for every $n \in \mathbb{Z}_+$. We say that the process $(X_n)_{n \in \mathbb{Z}_+}$ is a martingale if, for every $n \in \mathbb{Z}_+$, $$E(X_{n+1}|\mathcal{F}_n) = X_n.$$&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;First, we need some terminology related to random processes, understanding what&amp;rsquo;s meant by an &amp;ldquo;adapted process&amp;rdquo; and a &amp;ldquo;filtration&amp;rdquo;. Apart from that, we need a solid grasp of conditional expectations. The definition of a conditional expectation with respect to a $\sigma$-algebra, as well as the underlying intuition. And that&amp;rsquo;s about it.&lt;/p&gt;
&lt;h3 id=&#34;should-i-bother&#34;&gt;Should I bother?&lt;/h3&gt;
&lt;p&gt;If you want to learn something thoroughly, then yes. Tracking down dependencies makes you engage more with the material. Learning a concept isn&amp;rsquo;t just a matter of being able to regurgitate the contents of the lecture notes - it requires you to build your own mental model of what&amp;rsquo;s going on. As I see it, the purpose of exercises, quizzes or review questions is to make us think more carefully about a given topic. Otherwise, because humans (or at least maths students) are lazy, chances are we&amp;rsquo;ll go through the material too quickly. Tracking down dependencies is a bit like doing more problems, in that it prompts us to revisit the material.&lt;/p&gt;
&lt;p&gt;Another benefit of nailing down dependencies is that it makes the concept seem relatively simple. Some results can seem quite daunting at first. But working out the dependencies can make the concept seem deceptively simple - almost to the point where you&amp;rsquo;re struck with the curse of knowledge. Moreover, if I struggle to understand an idea but am clear about the dependencies, I know what to do: I&amp;rsquo;ll just read up on each of the topics involved. In this way, the dependencies translate into an a checklist for my learning process.&lt;/p&gt;
&lt;p&gt;Lastly, I found it satisfying seeing how different notions tied into one another. I also put it all into one mindmap which, apart from having a high aesthetic value, gave me the big picture of the subject.&lt;/p&gt;
</description>
    </item>
    
    
    
    
    
    
    
    
    
    
  </channel>
</rss>
