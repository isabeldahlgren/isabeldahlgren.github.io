---
title: "LLMs and the English Language"
date: 2025-12-14
tags: ["ai"]
draft: false
---

Many LLMs have a 'thinking mode', also called 'reasoning mode'. Activating thinking mode changes how the model structures its generation: it generates and evaluates more intermediate outputs before its final answer. So, in exchange for more tokens and longer response times, you get a more 'thoughtful' answer. Thinking mode works phenomenally well, so the temptation to use LLMs for thinking can sometimes be irresistible. However, if I want a genuinely thoughtful answer -- if I'm writing for mental clarity -- I'll hardly use LLMs at all.

### LLMs can 'think'...
Here I'll focus on critical thinking, which, in its broadest sense, is defined as careful, goal-directed thinking[^ennis]. This involves things like analysing arguments, identifying relevant information, questioning well-perceived wisdom, and, finally, drawing sound conclusions.

[^ennis]: At least according to the [Stanford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/critical-thinking/). There's a myriad of more specific definitions, though. This [article](https://philpapers.org/rec/ENNDAT) lists 14 philosophical definitions and three dictionary definitions.

To me it seems like critical thinking skills fall into two categories, which I'll call 'wide' and 'deep' thinking. Wide thinking is open-ended and explorative, and aims to gather information; deep thinking is detail-oriented and precise, and churns information into conclusions. Deep thinking is the extraction and evaluation of premises, almost like symbol-free mathematics.

LLMs are very useful for wide thinking tasks. Having been trained on the entire Internet, they know mind-blowing amounts of information, making them invaluable for literature reviews. When self-studying a new topic, I usually begin by consulting an LLM to get a high-level overview -- this is the efficient variant of reading the Wikipedia introduction.

And these days, LLMs are also pretty useful for deep thinking. State-of-the-art LLMs already achieve 90% accuracy on benchmarks like GPQA (PhD-level science questions) and MMLU-Pro (problem-solving and knowledge across different subjects). They're also terrific problem solvers: GPT-5.2 solved all tasks at this year's AIME, while a version of Gemini achieved gold-medal standards at this year's IMO[^obj].

[^obj]: It's still faster for me to typeset proofs myself: if I know the argument inside out, I might as well knock it out myself. However, if I had more money to burn on advanced models and spent an afternoon perfecting a set of prompt templates, using LLMs as TeX slaves would likely save me time.

In short, LLMs can think both widely and deeply, outputting answers reflecting strong critical thinking skills.

### ...and so can you
Nevertheless, when I'm writing to understand, rather than to produce an end product for someone else, I barely use LLMs[^myself]. I consult LLMs for literature reviews and gladly read the AI generated overviews of search results on Google, but the rest I do myself[^hygiene].

[^myself]: And obviously no LLMs for personal writing (essays, emails to friends, etc.). 
[^hygiene]: This is a matter of what I call 'LLM hygiene'.

Indeed, the other obvious use cases of LLMs for writing involve outsourcing thinking: I'm responsible for creating outlines, drafting paragraphs and formulating individual sentences -- yes, even formulating individual sentences, or else I'm not saying exactly what I mean to say.

This is much like doing the routine checks and exercises for the reader when reading a piece of mathematical writing. To get a gears-level understanding, as is often required, you should work out all the details on a separate piece of paper. Of course, this is rather time-consuming, so I'll readily use LLMs for routine writing tasks, like emails to colleagues and motivation letters.

In *Politics and the English Language* (1946), his attack on vague political writing, Orwell argues that the use of ready-made phrases leads to imprecise thinking:

> You can shirk it [the pain of thinking for yourself] by simply throwing your mind open and letting the ready-made phrases come crowding in. They will construct your sentences for you – even think your thoughts for you, to a certain extent – and at need they will perform the important service of partially concealing your meaning even from yourself.

I suspect he's right. And today LLMs can give you ready-made essays and research papers. There have recently been many papers on deceitful behaviour in LLMs[^papers], but we can be deceived in many ways.

[^papers]: See [here](https://www.anthropic.com/research/alignment-faking), [here](https://openai.com/index/detecting-and-reducing-scheming-in-ai-models/) and [here](https://www.anthropic.com/research/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training).
