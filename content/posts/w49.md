---
title: "My LLM stack"
date: 2026-01-25
tags: ["learning", "rationality", "ai"]
draft: false
---

Today's AI is phenomenally capable. Models like GPT-5.2 and Claude Opus 4.5 have [expert-level subject knowledge](https://epoch.ai/benchmarks/gpqa-diamond) in most STEM fields, and they can autonomously complete tasks taking [almost a full work day](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/). And these days, there are plenty of powerful scaffolds built around base models -- take Claude Cowork, for example.

So you have a lot of power at your fingertips in early 2026. Whatever tasks an AI can solve with your oversight, you can solve too. Many ordinary people can solve the same kinds of problems as certified therapists, experienced architects or ML PhD students with reasonable effort.

It's well worth learning how to use LLMs efficiently, then.

In fact, this we're told all the time, and Demis Hassabis eloquently made the point at the [seminar at the World Economic Forum](https://www.youtube.com/watch?v=NnVW9epLlTM) this week[^others]. Because 'new year, new me', I thought I'd listen.

[^others]: For example, the same point was also made by [Benjamin Todd](https://80000hours.org/agi/guide/skills-ai-makes-valuable/).

## Using LLMs efficiently
Using LLMs efficiently seems to involve two things: first, identifying good use cases for AI; second, using AI to implement the solution.

Step two, execution, is normally just some kind of prompt engineering -- a skill I'd expect to become less important in the future: producing user-friendly products is largely about eliminating the need for sophisticated prompt engineering. Step one is harder: it requires creativity and attention to failure modes in one's everyday life.

To become better at step one, I'll catalogue the ways in which I use LLMs. For further inspiration, I recommend browsing through the links listed by Gavin Leech in his [post on LLM usage](https://www.gleech.org/llms#see-also).

Anyway, here goes.

## Tried-and-tested use cases
- I have a low barrier for asking LLMs 'dumb' questions regarding individual proof steps. Similarly, I frequently use LLMs as sanity checkers, writing a sentence summarising my understanding of a topic and having an LLM give feedback.
- LLMs are excellent for explaining terminology in plain, simple language. Two caveats, though: for looking up words in foreign languages, I strongly prefer ordinary dictionaries, like those of [NE](https://www.ne.se); I'm also skeptical of using LLMs for definitions.
- I sometimes have LLMs lecture me on specific topics in mathematics. This is particularly useful when you're self-studying rather than following a course with peers -- e.g. when you're doing a semester paper. Concretely, this looks something like dumping relevant papers, textbook chapters and lecture notes into NotebookLM and asking for a 3-page PDF summary focusing on key intuitions.
- Of course, I rely heavily on coding agents, Claude Code being my favourite. Claude can handle most programming-related tasks today -- even things like slurm management[^timelines].
- Routine email writing, like finding a time to meet.
- Transcription of my favourite *In Our Time* episodes.
- Just as Andy Masley, I also use AI for [clearing ugh fields](https://andymasley.substack.com/p/how-i-use-ai?open=false#Â§clearing-ugh-fields), like household chores. It's not that I need AI for declaring taxes; however, it lowers the activation energy for the task. Or, to cite another example in this category, I used AI to repair my desktop lamp the other day.
- Python scripting. Python scripts can save you a lot of time, and coding agents can whip up scripts in minutes. For example, I have scripts for creating Anki cards, for web scraping and for merging markdown files.

[^timelines]: It's easy to see why programmers have notoriously short AGI timelines.

## Experimental use cases
- I'm experimenting with using AIs to combat planning fallacy. I recently passed a project proposal through Claude, who categorically said that I was committing planning fallacy[^models]. After some back and forth with the LLM, I came away with a far better project proposal. To extend this point, perhaps I could have an AI coach me in some areas of my life?
- I'm considering taking LLM input for some major life decisions, e.g. career choices. 

[^models]: Interestingly, I fed other AI models the same prompt (GPT, Gemini and Perplexity) -- but I only received real pushback from Claude. And I want feedback that stings a bit.

## Conclusion
As is evident from my examples, today's AI is powerful enough to be useful in almost any domain of life.

I'll continue exploring novel AI use cases -- not just because I expect this to improve my quality of life, but also because I'm curious to learn the limits of how much AI can do for ordinary people.
