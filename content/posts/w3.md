---
title: 'Thought experiments for normal people'
date: 2025-03-09
tags: ["rationality", "philosophy"]
---

Philosophers love thought experiments. Thought experiments are hypothetical scenarios meant to tease out our intuitions about an argument or theory. For example, here's a classic thought experiment, due to Robert Nozick:

> Suppose there were an experience machine that would give you any experience you desired. Superduper neuropsychologists could stimulate your brain so that you would think and feel you were writing a great novel, or making a friend, or reading an interesting book. All the time you would be floating in a tank, with electrodes attached to your brain. Should you plug into this machine for life, preprogramming your life's experiences? [^1]

Many thought experiments seem kind of cooked up, so it's easy to believe thought experiments have no practical use. However, one of my key takeaways from *The Scout Mindset* by Julia Galef was that thought experiments aren't just diversion for people with too much spare time. In fact, she argues, certain thought experiments can help us think more clearly about decisions we face in everyday life[^2]. In this essay, I'll go over three interesting thought experiments from her book, and then describe two personal faves.

- **The Outsider Test**: This all comes down to having an outsider's perspective, as if one were calling a friend. How would an outsider evaluate the situation? For example, say John Doe has been given two job offers: one at company X, the other at company Y. Company X will look better on his CV, but he's unlikely to enjoy the day-to-day tasks. In contrast, the job at company Y, although not quite as prestigious, seems more fun. Here, an outsider may say something like "If prestige weren't a consideration, which option would you pick?"
- **The Conformity Test**: This is a good one. We're often quick in adopting the beliefs of people we respect. And this is usually a good thing: life is to short to overthink everything, and we've got to form opinions somehow. (For fans of *Thinking, Fast and Slow*, this is System 1 in action.) However, when it comes to more delicate subjects, this mental short-cut might fail. In the Conformity Test, Julia Galef asks you to imagine that people no longer hold your view. (To all contrarians out there, just imagine that the people in your community suddenly become just as everyone else.) There's a particularly interesting spin-off here: what if one of the main proponents of your view, perhaps the person who helped shape your beliefs about the subject, would change their mind? I think the EA/rationalist community provides a good use case. What if Will MacAskill would say he was completely mistaken about longtermism, rejecting the idea altogether? Or if Eliezer Yudowsky would declare that AI after all isn't that big of a threat?
- **The Status Quo Bias Test**: The underlying idea here is that humans have a bias towards the status quo. If you were to start from scratch, would you actively choose your current situation? For example, imagine a medical student who realises halfway through second year of med school that medicine isn't for her. Although she cannot imagine herself as a doctor, she's still hesitant to switch subjects. Here the Status Quo Bias Test might come in handy.

After reading *The Scout Mindset*, I soon realised that some of the advice I've received over the years can be rephrased as thought experiments. Here are two such thought experiments which I've found particularly useful:

- **Worst Case Scenario**: This just involves asking oneself about the worst-case scenario. Is it really that bad? If yes, well, then you know. At least your fear isn't  some sort of vague, scary illusion. And if not, good!
- **Fast forward a decade**: In ten years from now, which decision is one more likely to regret? Humans are famously bad at long-term planning. We'll often fail to take the route of action with benefits in a distant future. (Hence climate change and the fact that most adults don't get enough sleep.) So it might be a good idea doing some kind of Outsider test, where the outsider is one's future self.

Some of the above thought experiments might sound familiar. Perhaps you've already used some of them yourself. After all, these seem like obvious tricks for seeing this for what they are. But perhaps it's helpful having names for these tricks. It's a bit like building a toolkit for better decision-making. I've applied something like Worst Case Scenario a bunch of times, but only after spending a couple of days of dwelling on the issue in a very unproductive way. Thinking in terms of thought experiments would have spared me a lot of headache.

[^1]: Nozick, Robert, and Thomas Nagel. *Anarchy, state, and utopia*. Vol. 5038. New York: Basic books, 1974.
[^2]: Galef, Julia. *The scout mindset: Why some people see things clearly and others don't*. Penguin, 2021.
